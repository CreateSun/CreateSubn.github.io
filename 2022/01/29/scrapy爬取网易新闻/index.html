<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="æ°¸è¿œç›¸ä¿¡ç¾å¥½çš„äº‹æƒ…å³å°†å‘ç”Ÿ">
    <meta name="keyword" content="">
    <link rel="shortcut icon" href="/img/favicon.ico">
    <title>
        
            scrapyæ¡†æ¶çˆ¬å–ç½‘æ˜“æ–°é—» - ç§å¤ªé˜³
                
    </title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/aircloud.css">

        
<link rel="stylesheet" href="/css/gitment.css">

            <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
            <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
            <!-- ga & ba script hoook -->
            <script></script>
<meta name="generator" content="Hexo 5.4.1"></head>

    <body>

        <div class="site-nav-toggle" id="site-nav-toggle">
            <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
        </div>

        <div class="index-about">
            <i> å´åµšå†è½ä»äººç¬‘ï¼Œæ¶Ÿæ¼ªå¾®æ¼¾ä¼´ç–ç‹‚ </i>
        </div>

        <div class="index-container">
            
                <div class="index-left">
                    <div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar radius">
            <img src="/img/12138.png" />
        </div>
        <div class="name">
            <i>Create Sun</i>
        </div>
        <ul class="list-inline text-center" style="padding-bottom: 1rem;">
            
                    
                        <li style="background: #06f;">
                            <a target="_blank" href="https://www.zhihu.com/people/la-la-la-chong-tai-yang-40">
                                <span class="fa-stack fa-lg">
                                     <i class="iconfont icon-zhihu"></i>
                                </span>
                            </a>
                        </li>
                        

                            

                                    

                                            
                                                <li style="background: #6e5494;">
                                                    <a target="_blank" href="https://github.com/CreateSun">
                                                        <span class="fa-stack fa-lg">
                                    <i class="iconfont icon-github"></i>
                                </span>
                                                    </a>
                                                </li>
                                                

                                                    

        </ul>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                        <a href="/">
                            <i class="iconfont icon-shouye1"></i>
                            <span>ä¸»é¡µ</span>
                        </a>
            </li>
            <li >
                        <a href="/tags">
                            <i class="iconfont icon-biaoqian1"></i>
                            <span>æ ‡ç­¾</span>
                        </a>
            </li>
            <li >
                        <a href="/archives">
                            <i class="iconfont icon-guidang2"></i>
                            <span>å­˜æ¡£</span>
                        </a>
            </li>
            <li >
                        <a href="/about/">
                            <i class="iconfont icon-guanyu2"></i>
                            <span>å…³äº</span>
                        </a>
            </li>
            
                <li>
                    <a id="search">
                        <i class="iconfont icon-sousuo1"></i>
                        <span>æœç´¢</span>
                    </a>
                </li>
                
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#scrapy%E7%88%AC%E5%8F%96%E7%BD%91%E6%98%93%E6%96%B0%E9%97%BB"><span class="toc-text">scrapyçˆ¬å–ç½‘æ˜“æ–°é—»</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E6%93%8D%E4%BD%9C"><span class="toc-text">åˆå§‹åŒ–æ“ä½œ</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E7%88%AC%E8%99%AB-news-py"><span class="toc-text">ç¼–å†™çˆ¬è™«(news.py)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#items-py"><span class="toc-text">items.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%AD%E9%97%B4%E4%BB%B6middleware-py"><span class="toc-text">ä¸­é—´ä»¶middleware.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%A1%E9%81%93pipelines-py"><span class="toc-text">ç®¡é“pipelines.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AEsettings-py"><span class="toc-text">é¡¹ç›®é…ç½®settings.py</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#UA%E4%BC%AA%E8%A3%85%E4%B8%8E%E4%BB%A3%E7%90%86IP"><span class="toc-text">UAä¼ªè£…ä¸ä»£ç†IP</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E%E8%B0%83%E8%AF%95main-py"><span class="toc-text">å…³äºè°ƒè¯•main.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E7%BB%88%E7%BB%93%E6%9E%9C"><span class="toc-text">æœ€ç»ˆç»“æœ</span></a></li></ol></li></ol>
</div>
            
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input" />
            <span id="begin-search">æœç´¢</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>
                        <div class="index-about-mobile">
                            <i> å´åµšå†è½ä»äººç¬‘ï¼Œæ¶Ÿæ¼ªå¾®æ¼¾ä¼´ç–ç‹‚ </i>
                        </div>
                </div>
                
                    <div class="index-middle">
                        <!-- Main Content -->
                        


<div class="post-container">
    <div class="post-title">
        scrapyæ¡†æ¶çˆ¬å–ç½‘æ˜“æ–°é—»
    </div>

    <div class="post-meta">
        <span class="attr">å‘å¸ƒäºï¼š<span>2022-01-29 12:27:45</span></span>
        
        <span class="attr">æ ‡ç­¾ï¼š/
        
        <a class="tag" href="/tags/#scrapy" title="scrapy">scrapy</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#çˆ¬è™«" title="çˆ¬è™«">çˆ¬è™«</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#ç½‘æ˜“æ–°é—»" title="ç½‘æ˜“æ–°é—»">ç½‘æ˜“æ–°é—»</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">è®¿é—®ï¼š<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h2 id="scrapyçˆ¬å–ç½‘æ˜“æ–°é—»"><a href="#scrapyçˆ¬å–ç½‘æ˜“æ–°é—»" class="headerlink" title="scrapyçˆ¬å–ç½‘æ˜“æ–°é—»"></a>scrapyçˆ¬å–ç½‘æ˜“æ–°é—»</h2><blockquote>
<p>ä½¿ç”¨scrapyçˆ¬å–ç½‘æ˜“æ–°é—»çš„<strong>å›½å†…</strong>ã€<strong>å›½é™…</strong>ã€<strong>èˆªç©º</strong>ä¸‰ä¸ªæ¿å—çš„æ–°é—»æ•°æ®å­˜å‚¨åœ¨csvä¸­</p>
</blockquote>
<h3 id="åˆå§‹åŒ–æ“ä½œ"><a href="#åˆå§‹åŒ–æ“ä½œ" class="headerlink" title="åˆå§‹åŒ–æ“ä½œ"></a>åˆå§‹åŒ–æ“ä½œ</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject wangyiPro # æ–°å»ºé¡¹ç›®</span><br><span class="line">cd wangyiPro</span><br><span class="line">scrapy genspider news # åˆ›å»ºçˆ¬è™«</span><br></pre></td></tr></table></figure>
<h3 id="ç¼–å†™çˆ¬è™«-news-py"><a href="#ç¼–å†™çˆ¬è™«-news-py" class="headerlink" title="ç¼–å†™çˆ¬è™«(news.py)"></a>ç¼–å†™çˆ¬è™«(news.py)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> Chrome, ChromeOptions</span><br><span class="line"><span class="keyword">from</span> wangyiPro.items <span class="keyword">import</span> WangyiproItem</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NewsSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;news&#x27;</span></span><br><span class="line">    <span class="comment"># allowed_domains = [&#x27;www.xxx.com&#x27;]</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://news.163.com/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        çˆ¬è™«åˆå§‹åŒ–é˜¶æ®µåˆ›å»ºseleniumæ— å¤´æµè§ˆå™¨å®ä¾‹ç”¨äºè·å–åŠ¨æ€åŠ è½½çš„æ•°æ®</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        options = ChromeOptions()</span><br><span class="line">        options.add_experimental_option(<span class="string">&quot;excludeSwitches&quot;</span>,[<span class="string">&#x27;enable-automation&#x27;</span>])</span><br><span class="line">        <span class="comment"># options.add_argument(&#x27;--headless&#x27;)  è¿™ä¸¤ä¸ªæ˜¯æ— å¤´æµè§ˆå™¨çš„é€‰é¡¹</span></span><br><span class="line">        <span class="comment"># options.add_argument(&#x27;--disable-gpu&#x27;)</span></span><br><span class="line">        self.bro = Chrome(executable_path=<span class="string">&#x27;D:\\Project\\python\\scrapy-test\\5.åŠ¨æ€åŠ è½½æ•°æ®å¤„ç†\\chromedriver.exe&#x27;</span>,</span><br><span class="line">                          chrome_options=options)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># è§£æäº”å¤§æ¿å—å¯¹åº”è¯¦æƒ…é¡µçš„url</span></span><br><span class="line">    section_urls = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># parseç”¨äºè§£æç½‘æ˜“æ–°é—»çš„é¦–é¡µå¯¼èˆªæ çš„å¯¹åº”æ¿å—url</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        li_list = response.xpath(<span class="string">&#x27;//*[@id=&quot;index2016_wrap&quot;]/div[3]/div[2]/div[2]/div[2]/div/ul/li&#x27;</span>)</span><br><span class="line">        <span class="comment"># with open(&#x27;page.html&#x27;, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;) as fp:</span></span><br><span class="line">        <span class="comment">#     fp.write(response.text)</span></span><br><span class="line">        index_list = [<span class="number">3</span>, <span class="number">6</span>]</span><br><span class="line">        <span class="comment"># index_list = [2]</span></span><br><span class="line">        <span class="comment"># æ¿å—url</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> index_list:</span><br><span class="line">            name = li_list[index].xpath(<span class="string">&#x27;./a/text()&#x27;</span>).extract_first()</span><br><span class="line">            url = li_list[index].xpath(<span class="string">&#x27;./a/@href&#x27;</span>).extract_first()</span><br><span class="line">            item = &#123;</span><br><span class="line">                <span class="string">&quot;url&quot;</span>: url,</span><br><span class="line">                <span class="string">&quot;name&quot;</span>: name</span><br><span class="line">            &#125;</span><br><span class="line">            self.section_urls.append(item)</span><br><span class="line">        <span class="comment"># ä¾æ¬¡å¯¹æ¯ä¸ªæ¿å—å¯¹åº”çš„é¡µé¢è¿›è¡Œè¯·æ±‚</span></span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> self.section_urls:</span><br><span class="line">            <span class="comment"># print(url)</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=item[<span class="string">&#x27;url&#x27;</span>], callback=self.parse_section,</span><br><span class="line">                                 meta=&#123;<span class="string">&quot;url&quot;</span>: item[<span class="string">&#x27;url&#x27;</span>], <span class="string">&quot;category&quot;</span>: item[<span class="string">&#x27;name&#x27;</span>]&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># è§£ææ–°é—»æ ‡é¢˜å’Œè¯¦æƒ…é¡µurl</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_section</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./page.html&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            fp.write(response.text) <span class="comment"># ç”¨äºå‚¨å­˜é¡µé¢ä¾¿äºè°ƒè¯•</span></span><br><span class="line">        div_list = response.xpath(<span class="string">&#x27;//div[@class=&quot;ndi_main&quot;]/div&#x27;</span>)</span><br><span class="line">        category = response.meta[<span class="string">&#x27;category&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(div_list[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">for</span> div <span class="keyword">in</span> div_list:</span><br><span class="line">            title = div.xpath(<span class="string">&#x27;./div//h3/a/text()&#x27;</span>).extract_first()</span><br><span class="line">            detail_url = div.xpath(<span class="string">&#x27;./div//h3/a//@href&#x27;</span>).extract_first()</span><br><span class="line">            <span class="built_in">print</span>(title, detail_url)</span><br><span class="line">            item = WangyiproItem()</span><br><span class="line">            item[<span class="string">&#x27;title&#x27;</span>] = title</span><br><span class="line">            item[<span class="string">&#x27;category&#x27;</span>] = category</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=detail_url, callback=self.parse_detail, meta=&#123;<span class="string">&quot;item&quot;</span>: item&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># è§£ææ–°é—»æ•°æ®</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_detail</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            è¿™ä¸€éƒ¨åˆ†æ˜¯å¯¹æ–°é—»çš„å†…å®¹ã€å‘å¸ƒæ—¶é—´ã€æ¥æºåšè§£æ</span></span><br><span class="line"><span class="string">            å†…å®¹è·å–åè¿›è¡Œæ•°æ®æ¸…æ™°ï¼Œå»æ‰ç©ºè¡Œã€åˆ¶è¡¨ç¬¦ç­‰å¤šä½™å†…å®¹</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        content = response.xpath(<span class="string">&#x27;//*[@id=&quot;content&quot;]/div[2]&#x27;</span>).extract()</span><br><span class="line">        content = <span class="string">&#x27;&#x27;</span>.join(content)</span><br><span class="line">        content = re.sub(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>, content)</span><br><span class="line">        content = re.sub(<span class="string">&#x27;\s&#x27;</span>, <span class="string">&#x27;&#x27;</span>, content)</span><br><span class="line">        content = re.sub(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>, content)</span><br><span class="line">        item = response.meta[<span class="string">&#x27;item&#x27;</span>]</span><br><span class="line">        item[<span class="string">&#x27;content&#x27;</span>] = content</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            å‘å¸ƒæ—¶é—´çš„åŸå§‹æ ¼å¼æ˜¯&quot;\n         2022-01-22 12:02:20 æ¥æº:&quot;,ä½¿ç”¨å‡½æ•°å¯¹æ—¶é—´éƒ¨åˆ†è¿›è¡Œæå–</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        timeline = response.xpath(<span class="string">&#x27;//div[@class=&quot;post_info&quot;]/text()&#x27;</span>).extract_first()</span><br><span class="line">        timeline = timeline.split(<span class="string">&#x27;æ¥æº&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">        timeline = re.findall(pattern=<span class="string">r&#x27;20?.* ?.*:[0-9]&#123;2&#125;&#x27;</span>, string=timeline)[<span class="number">0</span>]</span><br><span class="line">        item[<span class="string">&#x27;timeline&#x27;</span>] = timeline</span><br><span class="line">        item[<span class="string">&#x27;origin&#x27;</span>] = response.xpath(<span class="string">&#x27;//*[@id=&quot;container&quot;]/div[1]/div[2]/a/text()&#x27;</span>).extract_first()</span><br><span class="line">        <span class="comment"># print(item)</span></span><br><span class="line">        <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">closed</span>(<span class="params">spider, reason</span>):</span></span><br><span class="line">        spider.bro.quit()</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h3 id="items-py"><a href="#items-py" class="headerlink" title="items.py"></a>items.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WangyiproItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment"># æ ‡é¢˜ã€å†…å®¹ã€æ¥æºã€å‘å¸ƒæ—¶é—´ã€åˆ†ç±»</span></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    content = scrapy.Field()</span><br><span class="line">    origin = scrapy.Field()</span><br><span class="line">    timeline = scrapy.Field()</span><br><span class="line">    category = scrapy.Field()</span><br></pre></td></tr></table></figure>

<h3 id="ä¸­é—´ä»¶middleware-py"><a href="#ä¸­é—´ä»¶middleware-py" class="headerlink" title="ä¸­é—´ä»¶middleware.py"></a>ä¸­é—´ä»¶middleware.py</h3><blockquote>
<p>ä¸­é—´ä»¶éƒ¨åˆ†ä¸»è¦ç”¨äºå¤„ç†æ–°é—»æ¿å—çš„æ–°é—»åˆ—è¡¨éƒ¨åˆ†æ˜¯åŠ¨æ€åŠ è½½å‡ºæ¥çš„ï¼Œæ‰€ä»¥åœ¨è¿™é‡Œä½¿ç”¨<code>selenium</code>å°†è·å–åˆ°çš„åŠ¨æ€åŠ è½½æ•°æ®æ›¿æ¢åŸå…ˆä¸‹è½½å™¨è·å–çš„æ•°æ®ï¼Œç„¶åå‘é€ç»™å¼•æ“å¤„ç†</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define here the models for your spider middleware</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> signals</span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> HtmlResponse</span><br><span class="line"></span><br><span class="line"><span class="comment"># useful for handling different item types with a single interface</span></span><br><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> is_item, ItemAdapter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WangyiproDownloaderMiddleware</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="comment"># Not all methods need to be defined. If a method is not defined,</span></span><br><span class="line">    <span class="comment"># scrapy acts as if the downloader middleware does not modify the</span></span><br><span class="line">    <span class="comment"># passed objects.</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">        <span class="comment"># Called for each request that goes through the downloader</span></span><br><span class="line">        <span class="comment"># middleware.</span></span><br><span class="line">        <span class="comment"># print(&#x27;request middleware&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Must either:</span></span><br><span class="line">        <span class="comment"># - return None: continue processing this request</span></span><br><span class="line">        <span class="comment"># - or return a Response object</span></span><br><span class="line">        <span class="comment"># - or return a Request object</span></span><br><span class="line">        <span class="comment"># - or raise IgnoreRequest: process_exception() methods of</span></span><br><span class="line">        <span class="comment">#   installed downloader middleware will be called</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#  æ‹¦æˆªæ¿å—è¯¦æƒ…é¡µå“åº”å¯¹è±¡ï¼Œä¿®æ”¹ä¸ºç¬¦åˆéœ€æ±‚çš„å¯¹è±¡</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_response</span>(<span class="params">self, request, response, spider</span>):</span></span><br><span class="line">        <span class="comment">#  è·å–åœ¨çˆ¬è™«ä¸­å®šä¹‰çš„æµè§ˆå™¨å¯¹è±¡</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;å¼€å§‹æ‹¦æˆª...&#x27;</span>)</span><br><span class="line">        bro = spider.bro</span><br><span class="line">        urls = []</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> spider.section_urls:</span><br><span class="line">            urls.append(url[<span class="string">&#x27;url&#x27;</span>])</span><br><span class="line">        <span class="comment"># Called with the response returned from the downloader.</span></span><br><span class="line">        <span class="comment">#  ç­›é€‰å¯¹åº”çš„å“åº”å¯¹è±¡</span></span><br><span class="line">        <span class="keyword">if</span> request.url <span class="keyword">in</span> urls:</span><br><span class="line">            <span class="comment"># response æ¿å—è¯¦æƒ…é¡µå“åº”å¯¹è±¡</span></span><br><span class="line">            <span class="comment"># å®ä¾‹åŒ–æ–°çš„å“åº”å¯¹è±¡ï¼ŒåŒ…å«åŠ¨æ€åŠ è½½çš„æ•°æ®</span></span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">                å¦‚ä½•è·å–åŠ¨æ€åŠ è½½çš„å“åº”æ•°æ®ï¼Ÿ</span></span><br><span class="line"><span class="string">                selenium</span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span></span><br><span class="line">            bro.get(url=request.url)</span><br><span class="line">            bro.implicitly_wait(<span class="number">30</span>)  <span class="comment"># éšå½¢ç­‰å¾…æœ€é•¿30s</span></span><br><span class="line">            <span class="comment"># time.sleep(4)</span></span><br><span class="line">            page_text = bro.page_source <span class="comment"># è·å–åŠ¨æ€åŠ è½½çš„æ–°é—»æ•°æ®</span></span><br><span class="line">            new_res = HtmlResponse(url=request.url, body=page_text, encoding=<span class="string">&#x27;utf-8&#x27;</span>, request=request)</span><br><span class="line">            <span class="keyword">return</span> new_res</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Middleware no filter:&#x27;</span>, request.url)</span><br><span class="line">            <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span></span><br><span class="line">        <span class="comment"># Called when a download handler or a process_request()</span></span><br><span class="line">        <span class="comment"># (from other downloader middleware) raises an exception.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Must either:</span></span><br><span class="line">        <span class="comment"># - return None: continue processing this exception</span></span><br><span class="line">        <span class="comment"># - return a Response object: stops process_exception() chain</span></span><br><span class="line">        <span class="comment"># - return a Request object: stops process_exception() chain</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="ç®¡é“pipelines-py"><a href="#ç®¡é“pipelines-py" class="headerlink" title="ç®¡é“pipelines.py"></a>ç®¡é“pipelines.py</h3><blockquote>
<p>ç”¨äºæŒä¹…åŒ–å­˜å‚¨</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don&#x27;t forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># useful for handling different item types with a single interface</span></span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> ItemAdapter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WangyiproPipeline</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨å°±æ–°å»ºæ–‡ä»¶</span></span><br><span class="line">        <span class="comment"># è¿™é‡Œå‚è€ƒäº†https://www.cnblogs.com/shawone/p/10228912.html</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;./news.csv&#x27;</span>):</span><br><span class="line">            <span class="comment"># æ‰“å¼€æ–‡ä»¶ï¼ŒæŒ‡å®šæ–¹å¼ä¸ºå†™ï¼Œåˆ©ç”¨ç¬¬3ä¸ªå‚æ•°æŠŠcsvå†™æ•°æ®æ—¶äº§ç”Ÿçš„ç©ºè¡Œæ¶ˆé™¤</span></span><br><span class="line">            self.f = <span class="built_in">open</span>(<span class="string">&quot;news.csv&quot;</span>, <span class="string">&quot;a&quot;</span>, newline=<span class="string">&quot;&quot;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">            <span class="comment"># è®¾ç½®æ–‡ä»¶ç¬¬ä¸€è¡Œçš„å­—æ®µåï¼Œæ³¨æ„è¦è·Ÿspiderä¼ è¿‡æ¥çš„å­—å…¸keyåç§°ç›¸åŒ</span></span><br><span class="line">            self.fieldnames = [<span class="string">&quot;title&quot;</span>, <span class="string">&quot;content&quot;</span>, <span class="string">&quot;origin&quot;</span>, <span class="string">&quot;timeline&quot;</span>, <span class="string">&quot;category&quot;</span>]</span><br><span class="line">            <span class="comment"># æŒ‡å®šæ–‡ä»¶çš„å†™å…¥æ–¹å¼ä¸ºcsvå­—å…¸å†™å…¥ï¼Œå‚æ•°1ä¸ºæŒ‡å®šå…·ä½“æ–‡ä»¶ï¼Œå‚æ•°2ä¸ºæŒ‡å®šå­—æ®µå</span></span><br><span class="line">            self.writer = csv.DictWriter(self.f, fieldnames=self.fieldnames)</span><br><span class="line">            <span class="comment"># å†™å…¥ç¬¬ä¸€è¡Œå­—æ®µåï¼Œå› ä¸ºåªè¦å†™å…¥ä¸€æ¬¡ï¼Œæ‰€ä»¥æ–‡ä»¶æ”¾åœ¨__init__é‡Œé¢</span></span><br><span class="line">            self.writer.writeheader()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.f = <span class="built_in">open</span>(<span class="string">&quot;news.csv&quot;</span>, <span class="string">&quot;a&quot;</span>, newline=<span class="string">&quot;&quot;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">            self.fieldnames = [<span class="string">&quot;title&quot;</span>, <span class="string">&quot;content&quot;</span>, <span class="string">&quot;origin&quot;</span>, <span class="string">&quot;timeline&quot;</span>, <span class="string">&quot;category&quot;</span>]</span><br><span class="line">            self.writer = csv.DictWriter(self.f, fieldnames=self.fieldnames)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        é‡å†™çˆ¶ç±»æ–¹æ³•</span></span><br><span class="line"><span class="string">        è¯¥ä»…ä»…åœ¨çˆ¬è™«å¼€å§‹æ—¶è°ƒç”¨ä¸€æ¬¡</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        self.writer.writerow(item)</span><br><span class="line">        <span class="keyword">return</span> item  <span class="comment"># ä¼ é€’ç»™ä¸‹ä¸€ä¸ªæ‰§è¡Œçš„ç®¡é“ç±»</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;ç»“æŸçˆ¬è™«...&#x27;</span>)</span><br><span class="line">        self.f.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="é¡¹ç›®é…ç½®settings-py"><a href="#é¡¹ç›®é…ç½®settings-py" class="headerlink" title="é¡¹ç›®é…ç½®settings.py"></a>é¡¹ç›®é…ç½®settings.py</h3><blockquote>
<p>è¿™æ˜¯å‘æ¯”è¾ƒå¤šçš„ä¸€éƒ¨åˆ†</p>
</blockquote>
<h4 id="UAä¼ªè£…ä¸ä»£ç†IP"><a href="#UAä¼ªè£…ä¸ä»£ç†IP" class="headerlink" title="UAä¼ªè£…ä¸ä»£ç†IP"></a>UAä¼ªè£…ä¸ä»£ç†IP</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç”±äºç½‘æ˜“æ²¡æœ‰å¤ªå¤æ‚çš„æ ¡éªŒï¼Œæ‰€æœ‰æˆ‘çš„å…¨éƒ¨è¯·æ±‚ä½¿ç”¨çš„ä¸€æ ·çš„è¯·æ±‚å¤´</span></span><br><span class="line"><span class="comment"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span></span><br><span class="line">USER_AGENT = <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36&#x27;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>å¦å¤–ä»£ç†IPå¯ä»¥åœ¨ä¸­é—´ä»¶ä¸­çš„<code>downloader</code>ç±»ä¸­çš„<code>process_exception</code>å‡½æ•°ä¸­åšåˆ¤æ–­å¹¶è®¾ç½®ä»£ç†IP</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ‹¦æˆªå‘ç”Ÿå¼‚å¸¸çš„è¯·æ±‚</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span></span><br><span class="line">        <span class="comment"># Called when a download handler or a process_request()</span></span><br><span class="line">        <span class="comment"># (from other downloader middleware) raises an exception.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#  ä»£ç†</span></span><br><span class="line">        <span class="keyword">if</span> request.split(<span class="string">&#x27;:&#x27;</span>)[<span class="number">0</span>]==<span class="string">&#x27;http&#x27;</span>:</span><br><span class="line">            request.meta[<span class="string">&#x27;proxy&#x27;</span>] = <span class="string">&#x27;http://&#x27;</span>+ random.choice(self.proxy_http)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            request.meta[<span class="string">&#x27;proxy&#x27;</span>] = <span class="string">&#x27;http://&#x27;</span>+ random.choice(self.proxy_https)</span><br><span class="line">        <span class="comment"># Must either:</span></span><br><span class="line">        <span class="comment"># - return None: continue processing this exception</span></span><br><span class="line">        <span class="comment"># - return a Response object: stops process_exception() chain</span></span><br><span class="line">        <span class="comment"># - return a Request object: stops process_exception() chain</span></span><br><span class="line">        <span class="keyword">return</span> request</span><br></pre></td></tr></table></figure>
<blockquote>
<p>æœ€åå°±æ˜¯ä¸€äº›å¸¸è§é…ç½®</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span></span><br><span class="line">LOG_LEVEL = <span class="string">&#x27;ERROR&#x27;</span></span><br><span class="line"><span class="comment"># Enable or disable downloader middlewares</span></span><br><span class="line"><span class="comment"># è¿™é‡Œæœ‰ä¸ªå¾ˆå‘çš„åœ°æ–¹æ˜¯å…³äºä¸­é—´ä»¶ï¼Œä¸‹è½½ä¸­é—´ä»¶å’Œçˆ¬è™«ä¸­é—´ä»¶çš„é…ç½®æ˜¯åœ¨ä¸¤ä¸ªä¸åŒçš„åœ°æ–¹ï¼Œæˆ‘ä»¬åªéœ€è¦å¼€å¯ä¸‹è½½ä¸­é—´ä»¶å°±å¯ä»¥äº†ã€‚ç¬¬ä¸€æ¬¡ä½¿ç”¨çš„æ—¶å€™æ²¡æœ‰çœ‹æ¸…å¼€å¯çš„æ˜¯SPIDER_MIDDLEWARESï¼Œè¿˜ç‰¹æ„æŠŠWangyiproSpiderrMiddlewareæ¢æˆWangyiproDownloaderMiddlewareå› æ­¤èµ°äº†å¾ˆå¤šå¼¯è·¯ï¼Œå¯¼è‡´ä¸­é—´ä»¶è°ƒè¯•äº†å¾ˆä¹…éƒ½ä¸èµ·ä½œç”¨ï¼Œæˆ‘è¿˜ä»¥ä¸ºæˆ‘ç”µè„‘åäº†ã€‚</span></span><br><span class="line"></span><br><span class="line">SPIDER_MIDDLEWARES = &#123;</span><br><span class="line"><span class="comment">#   &#x27;wangyiPro.middlewares.WangyiproSpiderrMiddleware&#x27;: 543,</span></span><br><span class="line">   <span class="string">&#x27;wangyiPro.middlewares.WangyiproDownloaderMiddleware&#x27;</span>: <span class="number">543</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">   <span class="string">&#x27;wangyiPro.middlewares.WangyiproDownloaderMiddleware&#x27;</span>: <span class="number">543</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># Configure item pipelines</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;wangyiPro.pipelines.WangyiproPipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="å…³äºè°ƒè¯•main-py"><a href="#å…³äºè°ƒè¯•main-py" class="headerlink" title="å…³äºè°ƒè¯•main.py"></a>å…³äºè°ƒè¯•main.py</h3><blockquote>
<p>èµ·åˆè¿è¡Œçˆ¬è™«éƒ½æ˜¯åœ¨æ§åˆ¶å°ä¸­ç”¨<code>scrapy</code>å‘½ä»¤ï¼Œä½†æ˜¯è¿™æ ·å°±æ— æ³•è®©IDEä¸­çš„æ–­ç‚¹ç”Ÿæ•ˆä»è€Œæ— æ³•è°ƒè¯•ï¼Œåæ¥å‚è€ƒäº†<a target="_blank" rel="noopener" href="https://www.cnblogs.com/weixuqin/p/9074448.html">https://www.cnblogs.com/weixuqin/p/9074448.html</a>, åœ¨é¡¹ç›®çš„æ ¹ç›®å½•åˆ›å»º<code>main.py</code>ï¼Œå†™å…¥ä»¥ä¸‹å†…å®¹åå³é”®<code>debug</code>å¼€å¯äº†è°ƒè¯•åŠŸèƒ½</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#-*- coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy.cmdline <span class="keyword">import</span> execute</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment">#æ·»åŠ å½“å‰é¡¹ç›®çš„ç»å¯¹åœ°å€</span></span><br><span class="line">sys.path.append(os.path.dirname(os.path.abspath(__file__)))</span><br><span class="line"><span class="comment">#æ‰§è¡Œ scrapy å†…ç½®çš„å‡½æ•°æ–¹æ³•executeï¼Œ  ä½¿ç”¨ crawl çˆ¬å–å¹¶è°ƒè¯•ï¼Œæœ€åä¸€ä¸ªå‚æ•°news æ˜¯æˆ‘çš„çˆ¬è™«æ–‡ä»¶å</span></span><br><span class="line">execute([<span class="string">&#x27;scrapy&#x27;</span>, <span class="string">&#x27;crawl&#x27;</span>, <span class="string">&#x27;news&#x27;</span>])</span><br></pre></td></tr></table></figure>

<h3 id="æœ€ç»ˆç»“æœ"><a href="#æœ€ç»ˆç»“æœ" class="headerlink" title="æœ€ç»ˆç»“æœ"></a>æœ€ç»ˆç»“æœ</h3><p><img src="scrapy_news.png" alt="é¢„è§ˆ"></p>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

                    </div>
        </div>

        <footer class="footer" style="color: #555;">

    
            <p>
                <span id="busuanzi_container_site_pv"><span id="busuanzi_value_site_pv"></span>&nbsp;ğŸ‘€</span>|
                <span id="busuanzi_container_site_uv"><span id="busuanzi_value_site_uv"></span>&nbsp;ğŸ¯</span>
            </p>
            <p style="line-height: 1.5rem;">
                Powered by <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a> | Theme <a target="_blank" rel="noopener" href="https://github.com/aircloud/hexo-theme-aircloud">Hexo-AirCloud</a>

            </p>
            <p style="line-height: 1.5rem;">
                æ™‹ICPå¤‡19014491å· &copy; 2019-
                2022 Created By Create Sun ğŸŒ¤ï¸
            </p>
            <p></p>
</footer>

    </body>

    <script>
        // We expose some of the variables needed by the front end
        window.hexo_search_path = "search.json"
        window.hexo_root = "/"
        window.isPost = "true"
    </script>
    <script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
    
<script src="/js/index.js"></script>

        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        
                    

                            

</html>