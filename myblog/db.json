{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/landscape/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/js/script.js","path":"js/script.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/images/banner.jpg","path":"css/images/banner.jpg","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"source/img/12138.png","path":"img/12138.png","modified":1,"renderable":0},{"_id":"source/img/favicon.ico","path":"img/favicon.ico","modified":1,"renderable":0},{"_id":"source/images/12138.jpg","path":"images/12138.jpg","modified":1,"renderable":0},{"_id":"source/webPage/BingDwenDwen/index.html","path":"webPage/BingDwenDwen/index.html","modified":1,"renderable":0},{"_id":"source/webPage/MissJiang/index.html","path":"webPage/MissJiang/index.html","modified":1,"renderable":0},{"_id":"source/webPage/MissJiang/script.js","path":"webPage/MissJiang/script.js","modified":1,"renderable":0},{"_id":"source/webPage/MissJiang/style.css","path":"webPage/MissJiang/style.css","modified":1,"renderable":0},{"_id":"source/webPage/galaxy-battle/battle.jpg","path":"webPage/galaxy-battle/battle.jpg","modified":1,"renderable":0},{"_id":"source/webPage/galaxy-battle/bg3.jpg","path":"webPage/galaxy-battle/bg3.jpg","modified":1,"renderable":0},{"_id":"source/webPage/galaxy-battle/cover.png","path":"webPage/galaxy-battle/cover.png","modified":1,"renderable":0},{"_id":"source/webPage/galaxy-battle/index.html","path":"webPage/galaxy-battle/index.html","modified":1,"renderable":0},{"_id":"source/webPage/galaxy-battle/legends-1.jpeg","path":"webPage/galaxy-battle/legends-1.jpeg","modified":1,"renderable":0},{"_id":"source/webPage/galaxy-battle/legends-1.jpg","path":"webPage/galaxy-battle/legends-1.jpg","modified":1,"renderable":0},{"_id":"source/webPage/galaxy-battle/legends-2.jpg","path":"webPage/galaxy-battle/legends-2.jpg","modified":1,"renderable":0},{"_id":"source/webPage/galaxy-battle/modkaisa.png","path":"webPage/galaxy-battle/modkaisa.png","modified":1,"renderable":0},{"_id":"source/webPage/galaxy-battle/video.mp4","path":"webPage/galaxy-battle/video.mp4","modified":1,"renderable":0},{"_id":"source/webPage/galaxy-battle/zlas.png","path":"webPage/galaxy-battle/zlas.png","modified":1,"renderable":0},{"_id":"source/webPage/webStudyDemo/vue-bind/index.html","path":"webPage/webStudyDemo/vue-bind/index.html","modified":1,"renderable":0},{"_id":"source/webPage/webStudyDemo/vue-bind/vue.js","path":"webPage/webStudyDemo/vue-bind/vue.js","modified":1,"renderable":0}],"Cache":[{"_id":"source/404.md","hash":"558ca5a5b3bfd1c0a2cd06abece3514efce232b3","modified":1698832242361},{"_id":"source/CNAME","hash":"bc04c84d1baefaf8868c23d87c1b7b7b469df58d","modified":1698832242361},{"_id":"source/_posts/My-first-post.md","hash":"b8a838f222677af570a418bfd6f8429c1652e849","modified":1698832242362},{"_id":"source/_posts/2022年度总结.md","hash":"dbe0a942dccab62a1cf72a249a165a2ba2c54d5e","modified":1698832242362},{"_id":"source/_posts/scrapy框架学习笔记.md","hash":"7fc4a751b06e7c15c230983438b0effcdb29ee09","modified":1698832242362},{"_id":"source/_posts/2022年中记录.md","hash":"29e7f586b37ea0a7ca27fe07e122aa5dbd3f5564","modified":1698832242362},{"_id":"source/_posts/scrapy爬取网易新闻.md","hash":"cf235e94c0301b0e95a665b342e05a7d793825ad","modified":1698832242362},{"_id":"source/_posts/selenium模拟12306登录.md","hash":"3de32ccfa9170d6794baa0f5b885b60fa8e42ffa","modified":1698832242362},{"_id":"source/_posts/vue-双向数据绑定.md","hash":"c7d57aac8981c99ef357dae5bfac867af5d1595e","modified":1698832242362},{"_id":"source/_posts/我喜欢过两个女孩，一个是你，另一个也是你.md","hash":"9e1eeb46a73ae145d4bad9feedb65c29f980e71e","modified":1698832242362},{"_id":"source/_posts/洗牌算法.md","hash":"c5f8e2ca820f42e9e9539dbe2cc44c9d30b2627d","modified":1698832242362},{"_id":"source/_posts/临江仙·夜饮东坡醒复醉.md","hash":"665696140eb011398f2416d6df0052b952ddb8c3","modified":1698832242362},{"_id":"source/_posts/浮世三千.md","hash":"a03e2263e5463b519e05d1163452f4e5630b441d","modified":1698832242362},{"_id":"source/_posts/石凳.md","hash":"564093bd3bc06d7d5915b4f9a3285e54727c6f20","modified":1698832242363},{"_id":"source/_posts/罗老师百大发言.md","hash":"a8dfaa6111e48b477abe959136e4174a50cf8aa6","modified":1698832242363},{"_id":"source/_posts/老男孩.md","hash":"b2daf2c6413e1d44dd86d6bd908a66a3fec10c03","modified":1698832242363},{"_id":"source/_posts/裤子.md","hash":"8bdca7a9d780c164b2b7183f2e657d27cecbd4f7","modified":1698832242363},{"_id":"source/about/index.md","hash":"7bbe4371dfaf5aaab2fc97f72e5901ab6d8c21e7","modified":1698832242363},{"_id":"source/archives/index.md","hash":"f70d2e69ea5b8d2fa427f9abe7f337edac9b29b5","modified":1698832242363},{"_id":"source/img/favicon.ico","hash":"55d95b119c5073d0062dcbd6c4ec303aaf269878","modified":1698832242364},{"_id":"source/tags/index.md","hash":"bd16f05d546c4c48d80c8bef0b4465f8b79338d5","modified":1698832242364},{"_id":"source/webPage/BingDwenDwen/index.html","hash":"ef20c87d54b06c839b75f17db4e7463f2048e2ea","modified":1698832242365},{"_id":"source/webPage/MissJiang/index.html","hash":"fa829e5c63a4c9b56b2d83643f217be17e15bac4","modified":1698832242365},{"_id":"source/webPage/MissJiang/style.css","hash":"bfde118ea9de8641906ff3ec4c2798a8076611f3","modified":1698832242365},{"_id":"source/webPage/MissJiang/script.js","hash":"7f3bef562c182d993d5dd1d3e5f4f7973c0c1bfc","modified":1698832242365},{"_id":"source/webPage/galaxy-battle/battle.jpg","hash":"3216fe8c751decfbf5ebd5dff1f400736c58df6a","modified":1698832242365},{"_id":"source/webPage/galaxy-battle/legends-2.jpg","hash":"9c2579e189537df46cde6e94353613b91f616364","modified":1698832242371},{"_id":"source/webPage/galaxy-battle/index.html","hash":"999f5d155aaf6afb5a3ab8ddff3e690c81182973","modified":1698832242370},{"_id":"source/webPage/galaxy-battle/legends-1.jpeg","hash":"81d992c0845c6a7dce015b72589cde0716a25220","modified":1698832242371},{"_id":"source/webPage/galaxy-battle/legends-1.jpg","hash":"b62750e76465095ff570471847726825b9cb50d7","modified":1698832242371},{"_id":"source/webPage/webStudyDemo/vue-bind/index.html","hash":"6e6eca4ce9b93d61652f2bbf209745e5d4bf926f","modified":1698832242411},{"_id":"source/webPage/webStudyDemo/vue-bind/vue.js","hash":"ac7dc8d8195cca5f41140446df6d1527e1104b96","modified":1698832242411},{"_id":"source/images/12138.jpg","hash":"b09fc3e51d9e132323e781896b16e5f406892922","modified":1698832242364},{"_id":"source/webPage/galaxy-battle/modkaisa.png","hash":"867e7e6b7c696f03bf5bd63f3eb3cdad19f09ca5","modified":1698832242372},{"_id":"source/webPage/galaxy-battle/zlas.png","hash":"b1911b0e2816fb4b308bd246c56dc37dbc03a5d1","modified":1698832242410},{"_id":"themes/landscape/.npmignore","hash":"58d26d4b5f2f94c2d02a4e4a448088e4a2527c77","modified":1698832242418},{"_id":"themes/landscape/Gruntfile.js","hash":"71adaeaac1f3cc56e36c49d549b8d8a72235c9b9","modified":1698832242418},{"_id":"themes/landscape/package.json","hash":"544f21a0b2c7034998b36ae94dba6e3e0f39f228","modified":1698832242423},{"_id":"themes/landscape/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1698832242419},{"_id":"themes/landscape/README.md","hash":"37fae88639ef60d63bd0de22314d7cc4c5d94b07","modified":1698832242419},{"_id":"themes/landscape/languages/de.yml","hash":"3ebf0775abbee928c8d7bda943c191d166ded0d3","modified":1698832242419},{"_id":"themes/landscape/_config.yml","hash":"79ac6b9ed6a4de5a21ea53fc3f5a3de92e2475ff","modified":1698832242419},{"_id":"themes/landscape/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1698832242419},{"_id":"themes/landscape/languages/ja.yml","hash":"a73e1b9c80fd6e930e2628b393bfe3fb716a21a9","modified":1698832242419},{"_id":"themes/landscape/languages/fr.yml","hash":"415e1c580ced8e4ce20b3b0aeedc3610341c76fb","modified":1698832242419},{"_id":"themes/landscape/languages/es.yml","hash":"76edb1171b86532ef12cfd15f5f2c1ac3949f061","modified":1698832242419},{"_id":"themes/landscape/languages/ko.yml","hash":"881d6a0a101706e0452af81c580218e0bfddd9cf","modified":1698832242419},{"_id":"themes/landscape/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1698832242419},{"_id":"themes/landscape/languages/pt.yml","hash":"57d07b75d434fbfc33b0ddb543021cb5f53318a8","modified":1698832242420},{"_id":"themes/landscape/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1698832242420},{"_id":"themes/landscape/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1698832242420},{"_id":"themes/landscape/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1698832242420},{"_id":"themes/landscape/languages/zh-CN.yml","hash":"ca40697097ab0b3672a80b455d3f4081292d1eed","modified":1698832242420},{"_id":"themes/landscape/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1698832242423},{"_id":"themes/landscape/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1698832242423},{"_id":"themes/landscape/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1698832242423},{"_id":"themes/landscape/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1698832242423},{"_id":"themes/landscape/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1698832242423},{"_id":"themes/landscape/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1698832242423},{"_id":"themes/landscape/layout/layout.ejs","hash":"f155824ca6130080bb057fa3e868a743c69c4cf5","modified":1698832242423},{"_id":"themes/landscape/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1698832242423},{"_id":"themes/landscape/layout/_partial/after-footer.ejs","hash":"d0d753d39038284d52b10e5075979cc97db9cd20","modified":1698832242420},{"_id":"themes/landscape/layout/_partial/archive-post.ejs","hash":"c7a71425a946d05414c069ec91811b5c09a92c47","modified":1698832242420},{"_id":"themes/landscape/layout/_partial/archive.ejs","hash":"950ddd91db8718153b329b96dc14439ab8463ba5","modified":1698832242420},{"_id":"themes/landscape/layout/_partial/footer.ejs","hash":"93518893cf91287e797ebac543c560e2a63b8d0e","modified":1698832242421},{"_id":"themes/landscape/layout/_partial/article.ejs","hash":"c4c835615d96a950d51fa2c3b5d64d0596534fed","modified":1698832242421},{"_id":"themes/landscape/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1698832242421},{"_id":"themes/landscape/layout/_partial/gauges-analytics.ejs","hash":"aad6312ac197d6c5aaf2104ac863d7eba46b772a","modified":1698832242421},{"_id":"themes/landscape/layout/_partial/head.ejs","hash":"5abf77aec957d9445fc71a8310252f0013c84578","modified":1698832242421},{"_id":"themes/landscape/layout/_partial/header.ejs","hash":"7e749050be126eadbc42decfbea75124ae430413","modified":1698832242421},{"_id":"themes/landscape/layout/_partial/mobile-nav.ejs","hash":"e952a532dfc583930a666b9d4479c32d4a84b44e","modified":1698832242421},{"_id":"themes/landscape/layout/_widget/category.ejs","hash":"dd1e5af3c6af3f5d6c85dfd5ca1766faed6a0b05","modified":1698832242422},{"_id":"themes/landscape/layout/_partial/sidebar.ejs","hash":"930da35cc2d447a92e5ee8f835735e6fd2232469","modified":1698832242422},{"_id":"themes/landscape/layout/_widget/archive.ejs","hash":"beb4a86fcc82a9bdda9289b59db5a1988918bec3","modified":1698832242422},{"_id":"themes/landscape/layout/_widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1698832242422},{"_id":"themes/landscape/layout/_widget/tagcloud.ejs","hash":"b4a2079101643f63993dcdb32925c9b071763b46","modified":1698832242422},{"_id":"themes/landscape/layout/_widget/recent_posts.ejs","hash":"0d4f064733f8b9e45c0ce131fe4a689d570c883a","modified":1698832242422},{"_id":"themes/landscape/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1698832242424},{"_id":"themes/landscape/source/css/_variables.styl","hash":"628e307579ea46b5928424313993f17b8d729e92","modified":1698832242425},{"_id":"themes/landscape/source/css/style.styl","hash":"a70d9c44dac348d742702f6ba87e5bb3084d65db","modified":1698832242429},{"_id":"themes/landscape/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1698832242429},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1698832242429},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1698832242429},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1698832242429},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1698832242430},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1698832242429},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1698832242430},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1698832242429},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1698832242430},{"_id":"themes/landscape/source/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1698832242430},{"_id":"themes/landscape/layout/_partial/post/category.ejs","hash":"c6bcd0e04271ffca81da25bcff5adf3d46f02fc0","modified":1698832242421},{"_id":"themes/landscape/layout/_partial/post/date.ejs","hash":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1698832242421},{"_id":"themes/landscape/layout/_partial/post/gallery.ejs","hash":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1698832242422},{"_id":"themes/landscape/layout/_partial/post/nav.ejs","hash":"16a904de7bceccbb36b4267565f2215704db2880","modified":1698832242422},{"_id":"themes/landscape/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1698832242422},{"_id":"themes/landscape/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1698832242422},{"_id":"themes/landscape/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1698832242425},{"_id":"themes/landscape/source/css/_partial/archive.styl","hash":"db15f5677dc68f1730e82190bab69c24611ca292","modified":1698832242424},{"_id":"themes/landscape/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1698832242425},{"_id":"themes/landscape/source/css/_partial/comment.styl","hash":"79d280d8d203abb3bd933ca9b8e38c78ec684987","modified":1698832242424},{"_id":"themes/landscape/source/css/_partial/article.styl","hash":"10685f8787a79f79c9a26c2f943253450c498e3e","modified":1698832242424},{"_id":"themes/landscape/source/css/_partial/mobile.styl","hash":"a399cf9e1e1cec3e4269066e2948d7ae5854d745","modified":1698832242424},{"_id":"themes/landscape/source/css/_partial/highlight.styl","hash":"bf4e7be1968dad495b04e83c95eac14c4d0ad7c0","modified":1698832242424},{"_id":"themes/landscape/source/css/_partial/footer.styl","hash":"e35a060b8512031048919709a8e7b1ec0e40bc1b","modified":1698832242424},{"_id":"themes/landscape/source/css/_partial/header.styl","hash":"85ab11e082f4dd86dde72bed653d57ec5381f30c","modified":1698832242424},{"_id":"themes/landscape/source/css/_partial/sidebar-aside.styl","hash":"890349df5145abf46ce7712010c89237900b3713","modified":1698832242424},{"_id":"themes/landscape/source/css/_partial/sidebar.styl","hash":"404ec059dc674a48b9ab89cd83f258dec4dcb24d","modified":1698832242425},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1698832242426},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1698832242426},{"_id":"themes/landscape/source/css/_partial/sidebar-bottom.styl","hash":"8fd4f30d319542babfd31f087ddbac550f000a8a","modified":1698832242425},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1698832242427},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1698832242429},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1698832242429},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1698832242430},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1698832242430},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1698832242430},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1698832242429},{"_id":"source/webPage/galaxy-battle/bg3.jpg","hash":"2eefc7b7c47204d9fb043f24fbbda5c9622a7e1c","modified":1698832242367},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1698832242427},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1698832242427},{"_id":"themes/landscape/source/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1698832242428},{"_id":"source/img/12138.png","hash":"5d47a71fe31e73e6be317f74fabe40859a7171a1","modified":1698832242364},{"_id":"source/webPage/galaxy-battle/cover.png","hash":"70ccf95224ea7eb54f22fbc37c27e69e5954ce89","modified":1698832242370},{"_id":"source/webPage/galaxy-battle/video.mp4","hash":"1d4e33082206637b43a5090f176b3d495743b7a5","modified":1698832242409},{"_id":"public/search.json","hash":"28bc11940238d4644a9d0f29c68fcd3e108cf49f","modified":1698832332295},{"_id":"public/404.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/archives/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/about/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/2022/06/29/2022年中记录/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/2022/05/05/vue-双向数据绑定/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/2022/02/02/2022年度总结/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/2022/01/30/罗老师百大发言/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/2022/01/29/scrapy框架学习笔记/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/2022/01/29/scrapy爬取网易新闻/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/2022/01/28/selenium模拟12306登录/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/2022/01/26/临江仙·夜饮东坡醒复醉/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/2021/12/29/洗牌算法/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/2020/08/05/我喜欢过两个女孩，一个是你，另一个也是你/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/2020/07/27/石凳/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/2020/07/25/浮世三千/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/2020/07/25/老男孩/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/2020/05/27/裤子/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/2020/04/05/My-first-post/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/archives/page/2/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/archives/2020/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/archives/2020/04/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/archives/2020/05/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/archives/2020/07/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/archives/2020/08/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/archives/2021/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/archives/2021/12/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/archives/2022/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/archives/2022/01/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/archives/2022/05/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/archives/2022/02/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/archives/2022/06/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/categories/categories/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/categories/学习/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/categories/日常/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/categories/前端/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/categories/随笔/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/page/2/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/Heart/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/Soul/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/人生/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/日常/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/scrapy/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/爬虫/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/python/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/框架/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/网易新闻/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/selenium/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/前端/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/vue/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/诗词/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/算法/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/洗牌算法/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/tags/heart/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1698832332295},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1698832332295},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1698832332295},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1698832332295},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1698832332295},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1698832332295},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1698832332295},{"_id":"public/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1698832332295},{"_id":"public/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1698832332295},{"_id":"public/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1698832332295},{"_id":"public/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1698832332295},{"_id":"public/CNAME","hash":"bc04c84d1baefaf8868c23d87c1b7b7b469df58d","modified":1698832332295},{"_id":"public/webPage/BingDwenDwen/index.html","hash":"ef20c87d54b06c839b75f17db4e7463f2048e2ea","modified":1698832332295},{"_id":"public/webPage/MissJiang/index.html","hash":"fa829e5c63a4c9b56b2d83643f217be17e15bac4","modified":1698832332295},{"_id":"public/webPage/MissJiang/script.js","hash":"7f3bef562c182d993d5dd1d3e5f4f7973c0c1bfc","modified":1698832332295},{"_id":"public/img/favicon.ico","hash":"55d95b119c5073d0062dcbd6c4ec303aaf269878","modified":1698832332295},{"_id":"public/webPage/MissJiang/style.css","hash":"bfde118ea9de8641906ff3ec4c2798a8076611f3","modified":1698832332295},{"_id":"public/webPage/galaxy-battle/battle.jpg","hash":"3216fe8c751decfbf5ebd5dff1f400736c58df6a","modified":1698832332295},{"_id":"public/webPage/galaxy-battle/index.html","hash":"999f5d155aaf6afb5a3ab8ddff3e690c81182973","modified":1698832332295},{"_id":"public/webPage/galaxy-battle/legends-1.jpeg","hash":"81d992c0845c6a7dce015b72589cde0716a25220","modified":1698832332295},{"_id":"public/webPage/galaxy-battle/legends-1.jpg","hash":"b62750e76465095ff570471847726825b9cb50d7","modified":1698832332295},{"_id":"public/webPage/galaxy-battle/legends-2.jpg","hash":"9c2579e189537df46cde6e94353613b91f616364","modified":1698832332295},{"_id":"public/webPage/webStudyDemo/vue-bind/vue.js","hash":"ac7dc8d8195cca5f41140446df6d1527e1104b96","modified":1698832332295},{"_id":"public/webPage/webStudyDemo/vue-bind/index.html","hash":"6e6eca4ce9b93d61652f2bbf209745e5d4bf926f","modified":1698832332295},{"_id":"public/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1698832332295},{"_id":"public/images/12138.jpg","hash":"b09fc3e51d9e132323e781896b16e5f406892922","modified":1698832332295},{"_id":"public/webPage/galaxy-battle/modkaisa.png","hash":"867e7e6b7c696f03bf5bd63f3eb3cdad19f09ca5","modified":1698832332295},{"_id":"public/webPage/galaxy-battle/zlas.png","hash":"b1911b0e2816fb4b308bd246c56dc37dbc03a5d1","modified":1698832332295},{"_id":"public/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1698832332295},{"_id":"public/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1698832332295},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1698832332295},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1698832332295},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1698832332295},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1698832332295},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1698832332295},{"_id":"public/css/style.css","hash":"5f8dadd37d0052c557061018fe6f568f64fced9b","modified":1698832332295},{"_id":"public/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1698832332295},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1698832332295},{"_id":"public/webPage/galaxy-battle/bg3.jpg","hash":"2eefc7b7c47204d9fb043f24fbbda5c9622a7e1c","modified":1698832332295},{"_id":"public/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1698832332295},{"_id":"public/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1698832332295},{"_id":"public/img/12138.png","hash":"5d47a71fe31e73e6be317f74fabe40859a7171a1","modified":1698832332295},{"_id":"public/webPage/galaxy-battle/cover.png","hash":"70ccf95224ea7eb54f22fbc37c27e69e5954ce89","modified":1698832332295},{"_id":"public/webPage/galaxy-battle/video.mp4","hash":"1d4e33082206637b43a5090f176b3d495743b7a5","modified":1698832332295}],"Category":[{"name":"categories","_id":"clofkwp1h0004qxgi0yeyfblh"},{"name":"日常","_id":"clofkwp1k000bqxgi69h42vme"},{"name":"学习","_id":"clofkwp1l000gqxgi7xiuhpd5"},{"name":"前端","_id":"clofkwp1o000rqxgi3obpaomt"},{"name":"随笔","_id":"clofkwp1o000yqxgi3i6i7bd7"}],"Data":[],"Page":[{"layout":"404","description":"你来到了没有知识的荒原 :(","header-img":"img/404-bg.jpg","_content":"","source":"404.md","raw":"---\nlayout: 404\ndescription: \"你来到了没有知识的荒原 :(\"\nheader-img: \"img/404-bg.jpg\"\n---","date":"2023-11-01T09:50:42.361Z","updated":"2023-11-01T09:50:42.361Z","path":"404.html","title":"","comments":1,"_id":"clofkwp1e0000qxgi2mn73my3","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"archives","date":"2022-01-26T01:14:04.000Z","_content":"","source":"archives/index.md","raw":"---\ntitle: archives\ndate: 2022-01-26 01:14:04\n---\n","updated":"2023-11-01T09:50:42.363Z","path":"archives/index.html","comments":1,"layout":"page","_id":"clofkwp1g0002qxgi3bmn5xcb","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"About","date":"2022-01-26T01:13:41.000Z","_content":"\n> 欢迎来到我的主页o(*￣▽￣*)ブ","source":"about/index.md","raw":"---\ntitle: About\ndate: 2022-01-26 01:13:41\n---\n\n> 欢迎来到我的主页o(*￣▽￣*)ブ","updated":"2023-11-01T09:50:42.363Z","path":"about/index.html","comments":1,"layout":"page","_id":"clofkwp1i0006qxgihmls1hxw","content":"<blockquote>\n<p>欢迎来到我的主页o(<em>￣▽￣</em>)ブ</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>欢迎来到我的主页o(<em>￣▽￣</em>)ブ</p>\n</blockquote>\n"},{"layout":"tags","title":"tags","date":"2022-01-25T22:53:38.000Z","_content":"","source":"tags/index.md","raw":"---\nlayout: tags\ntitle: tags\ndate: 2022-01-25 22:53:38\n---\n","updated":"2023-11-01T09:50:42.364Z","path":"tags/index.html","comments":1,"_id":"clofkwp1j0008qxgib5q32b29","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"2022年中记录","date":"2022-06-28T21:13:14.000Z","updated":"2022-06-28T21:13:14.000Z","toc":true,"cover":"/images/12138.jpg","_content":"&emsp;&emsp;不知不觉又是半年过去了，这或许是这四年以来最轻松的一段时光，前些天和朋友聚在一起的时候就在感慨，似乎从去年12月回家的时候就已经有了毕业的气氛，没想到现在真的要毕业了。\n> &emsp;&emsp;“时光的河入海流 终于我们分头走 没有哪个港口 是永远的停留”\n&emsp;&emsp;实话实说自己对成绩早有预兆，从查到分数的那一天早上就对自己上岸不报太多的希望，只是觉得不能这么早就妄下定论，家人也劝我不要轻易放弃任何一个希望。纠结地等待了两周，我果然还是没有进复试。眼看一志愿已经没有了希望，只好抓紧时间准备调剂，调剂结束以后彻底结束了考研的幻想，尽管一战失败，但是当时的我似乎很有信心二战上岸，或许是我确实也没有别的更好的选择，只好用“二战一定会上岸”这样的话语来宽慰自己也宽慰了家人，但是此后的一个月里\n<!-- more -->\nbody\n","source":"_posts/2022年中记录.md","raw":"---\ntitle: 2022年中记录\ndate: 2022-06-28 21:13:14\nupdated: 2022-06-28 21:13:14\ncategories: categories\ntags: [Heart, Soul, 人生]\ntoc: true\ncover: /images/12138.jpg\n---\n&emsp;&emsp;不知不觉又是半年过去了，这或许是这四年以来最轻松的一段时光，前些天和朋友聚在一起的时候就在感慨，似乎从去年12月回家的时候就已经有了毕业的气氛，没想到现在真的要毕业了。\n> &emsp;&emsp;“时光的河入海流 终于我们分头走 没有哪个港口 是永远的停留”\n&emsp;&emsp;实话实说自己对成绩早有预兆，从查到分数的那一天早上就对自己上岸不报太多的希望，只是觉得不能这么早就妄下定论，家人也劝我不要轻易放弃任何一个希望。纠结地等待了两周，我果然还是没有进复试。眼看一志愿已经没有了希望，只好抓紧时间准备调剂，调剂结束以后彻底结束了考研的幻想，尽管一战失败，但是当时的我似乎很有信心二战上岸，或许是我确实也没有别的更好的选择，只好用“二战一定会上岸”这样的话语来宽慰自己也宽慰了家人，但是此后的一个月里\n<!-- more -->\nbody\n","slug":"2022年中记录","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"clofkwp1f0001qxgia10maxyb","content":"<p>&emsp;&emsp;不知不觉又是半年过去了，这或许是这四年以来最轻松的一段时光，前些天和朋友聚在一起的时候就在感慨，似乎从去年12月回家的时候就已经有了毕业的气氛，没想到现在真的要毕业了。</p>\n<blockquote>\n<p>&emsp;&emsp;“时光的河入海流 终于我们分头走 没有哪个港口 是永远的停留”<br>&emsp;&emsp;实话实说自己对成绩早有预兆，从查到分数的那一天早上就对自己上岸不报太多的希望，只是觉得不能这么早就妄下定论，家人也劝我不要轻易放弃任何一个希望。纠结地等待了两周，我果然还是没有进复试。眼看一志愿已经没有了希望，只好抓紧时间准备调剂，调剂结束以后彻底结束了考研的幻想，尽管一战失败，但是当时的我似乎很有信心二战上岸，或许是我确实也没有别的更好的选择，只好用“二战一定会上岸”这样的话语来宽慰自己也宽慰了家人，但是此后的一个月里</p>\n</blockquote>\n<span id=\"more\"></span>\n<p>body</p>\n","site":{"data":{}},"excerpt":"<p>&emsp;&emsp;不知不觉又是半年过去了，这或许是这四年以来最轻松的一段时光，前些天和朋友聚在一起的时候就在感慨，似乎从去年12月回家的时候就已经有了毕业的气氛，没想到现在真的要毕业了。</p>\n<blockquote>\n<p>&emsp;&emsp;“时光的河入海流 终于我们分头走 没有哪个港口 是永远的停留”<br>&emsp;&emsp;实话实说自己对成绩早有预兆，从查到分数的那一天早上就对自己上岸不报太多的希望，只是觉得不能这么早就妄下定论，家人也劝我不要轻易放弃任何一个希望。纠结地等待了两周，我果然还是没有进复试。眼看一志愿已经没有了希望，只好抓紧时间准备调剂，调剂结束以后彻底结束了考研的幻想，尽管一战失败，但是当时的我似乎很有信心二战上岸，或许是我确实也没有别的更好的选择，只好用“二战一定会上岸”这样的话语来宽慰自己也宽慰了家人，但是此后的一个月里</p>\n</blockquote>","more":"<p>body</p>"},{"title":"2022新年愿望，和女孩子说话不脸红","date":"2022-02-01T22:15:41.000Z","updated":"2022-02-07T11:42:00.000Z","toc":true,"cover":"/images/12138.jpg","_content":"\n&emsp;&emsp;下午去溜了好一会，从2点一直在街上溜达到下午5点多，走一会歇一会和朋友聊了很久，回家的路上越发地感觉应该写一点什么来整理一下我这一年以来的经历。其实这篇博客是除夕的晚上创建的，但是那晚什么都没写，也不知道该从哪里写起就睡觉去了，今晚打了一晚上的游戏，也打算写个开头就去睡觉了。\n`2022-02-05 23:57:00`\n\n---\n> &emsp;&emsp;有些人总会像流星一样在那些平淡的日子里一闪而过，有幸能亲眼看到她的消逝，在我的心中留下一道永不会消逝的光芒,点缀着我的天空，照亮着我脚下的路。\n\n&emsp;&emsp;昨晚偶然和一位许久没有联系的朋友聊了几句，说来奇怪，明明当初认识她的时候几乎无话不谈，现在却不知道怎么开口。细细算来，我们认识已经3年有余，她从高三到大三，我从大一到大四，她变成了学姐，我也变成了老学姐。时间有些长，以至于想起曾经做过的一些傻事现在只觉得意味深长。她告诉我这三年她过得很不错，打了比赛拿了奖，拿了奖学金，过了六级，预备党员，暑假到机关单位实习，不过还是抱怨“好累”，我相信她说的“累”是真的。她又问道我有没有收到什么上市公司的“橄榄枝”，我笑着说我去年一直在准备考研的事情根本没来得及投简历。看着她细数大学拿到的荣誉，我也在问自己这四年收获了些什么？四六级、省赛银奖、“碰瓷”可以勉强算上的国赛铜奖、在同行面前能勉强算是入门的专业技术、外人听起来很牛其实算不上什么的校企实践经历。这些零零碎碎的经历拼凑起来我的大学四年，最后几乎丝毫没有犹豫地选择了考研，如今坐在家里等待生死未卜的考试成绩。\n&emsp;&emsp;谈起考研，其实说不上什么远大的理想，就是希望能有个更好的平台和更好的文凭能够让我学到更多的知识，能够支撑着我亲手建造起属于自己的生活。有车有房，没有那么大的压力，希望朋友们也都能通过自己的努力过上好生活，偶尔和他们出去走一走逛一逛。更多的时间是和另一半待在一起，我们一起生活，宁静的下午我们慵懒地靠在一起聊着我们的过去和未来。如果能为集体，为社会做出一些贡献我当然是非常乐意的，只是就我个人的愿望而言，家庭和睦，物质生活富足就已经实我的梦中情生活了。关于以后留在什么地方工作，做什么样的工作，我有过一些考虑。如果能考上硕士，毕业后去大厂待几年如果薪水够我在当地买房那就选择定居，或者大厂不好混，那就靠着这张硕士文凭去做一名高校的老师，选择安稳的生活。如果很不幸我没有考上硕士，那就根据成绩的好坏判断是否还要二战的必要以及决定二战考哪里。说实话每次一想到自己很可能是没有希望考上的都会禁不住打一个寒颤，以后的打算摆在面前让我不寒而栗。可是现实是总归要面对的，读研，二战，工作，总要做出选择。\n> &emsp;&emsp;分手不是那么容易就能走得出来的。\n\n&emsp;&emsp;这句话是我说的，或许也只是对我自己有效果。这次比上次带给我的冲击力要强上许多，可能是因为这件事情本身就比以往的要复杂许多。即便是快半年过去了，深夜也常感到孤独，晚上经常会梦到我们彼此解开了心结，冰释前嫌重归于好，或者梦到我们一拍两散，永不联系。我一直在感叹我这不平凡的经历，让我越发地确信我应该不会是一个平庸之辈。“平凡而不平庸”，我会平凡地活着，但我无法接收平庸的生活。昨晚出去跑了几公里，突然间的一瞬间感受到了一股前所未有的释然，最后冲刺的时候感受到了那种心无旁骛一心往前冲的感觉，我相信慢慢地肯定会走出来的。事业也好，爱情也罢，我绝不会逆来顺受，不会随波逐流，我要分析自己的问题，改正自己的错误，认识自己的软肋，找到自己的道路。毕竟每个人的追求都不同，只要敢于勇敢追求自己想要的生活，就是生活的勇者。\n\n<p style=\"font-family: 楷体;text-align:center;\">心怀期待的人还在等待</p>\n<p style=\"font-family: 楷体;text-align:center\">攒满失望的人早已离开</p>\n<p style=\"font-family: 楷体;text-align:center\">仍然自由自我 永远高唱我歌</p>\n<p style=\"font-family: 楷体;text-align:center\">走遍千里</p>\n\n<script>console.log(\"永远年轻，\\n永远热泪盈眶\")</script>\n","source":"_posts/2022年度总结.md","raw":"---\ntitle: 2022新年愿望，和女孩子说话不脸红\ndate: 2022-02-01 22:15:41\nupdated: 2022-02-07 11:42:00\ncategories: 日常\ntags: [Heart]\ntoc: true\ncover: /images/12138.jpg\n---\n\n&emsp;&emsp;下午去溜了好一会，从2点一直在街上溜达到下午5点多，走一会歇一会和朋友聊了很久，回家的路上越发地感觉应该写一点什么来整理一下我这一年以来的经历。其实这篇博客是除夕的晚上创建的，但是那晚什么都没写，也不知道该从哪里写起就睡觉去了，今晚打了一晚上的游戏，也打算写个开头就去睡觉了。\n`2022-02-05 23:57:00`\n\n---\n> &emsp;&emsp;有些人总会像流星一样在那些平淡的日子里一闪而过，有幸能亲眼看到她的消逝，在我的心中留下一道永不会消逝的光芒,点缀着我的天空，照亮着我脚下的路。\n\n&emsp;&emsp;昨晚偶然和一位许久没有联系的朋友聊了几句，说来奇怪，明明当初认识她的时候几乎无话不谈，现在却不知道怎么开口。细细算来，我们认识已经3年有余，她从高三到大三，我从大一到大四，她变成了学姐，我也变成了老学姐。时间有些长，以至于想起曾经做过的一些傻事现在只觉得意味深长。她告诉我这三年她过得很不错，打了比赛拿了奖，拿了奖学金，过了六级，预备党员，暑假到机关单位实习，不过还是抱怨“好累”，我相信她说的“累”是真的。她又问道我有没有收到什么上市公司的“橄榄枝”，我笑着说我去年一直在准备考研的事情根本没来得及投简历。看着她细数大学拿到的荣誉，我也在问自己这四年收获了些什么？四六级、省赛银奖、“碰瓷”可以勉强算上的国赛铜奖、在同行面前能勉强算是入门的专业技术、外人听起来很牛其实算不上什么的校企实践经历。这些零零碎碎的经历拼凑起来我的大学四年，最后几乎丝毫没有犹豫地选择了考研，如今坐在家里等待生死未卜的考试成绩。\n&emsp;&emsp;谈起考研，其实说不上什么远大的理想，就是希望能有个更好的平台和更好的文凭能够让我学到更多的知识，能够支撑着我亲手建造起属于自己的生活。有车有房，没有那么大的压力，希望朋友们也都能通过自己的努力过上好生活，偶尔和他们出去走一走逛一逛。更多的时间是和另一半待在一起，我们一起生活，宁静的下午我们慵懒地靠在一起聊着我们的过去和未来。如果能为集体，为社会做出一些贡献我当然是非常乐意的，只是就我个人的愿望而言，家庭和睦，物质生活富足就已经实我的梦中情生活了。关于以后留在什么地方工作，做什么样的工作，我有过一些考虑。如果能考上硕士，毕业后去大厂待几年如果薪水够我在当地买房那就选择定居，或者大厂不好混，那就靠着这张硕士文凭去做一名高校的老师，选择安稳的生活。如果很不幸我没有考上硕士，那就根据成绩的好坏判断是否还要二战的必要以及决定二战考哪里。说实话每次一想到自己很可能是没有希望考上的都会禁不住打一个寒颤，以后的打算摆在面前让我不寒而栗。可是现实是总归要面对的，读研，二战，工作，总要做出选择。\n> &emsp;&emsp;分手不是那么容易就能走得出来的。\n\n&emsp;&emsp;这句话是我说的，或许也只是对我自己有效果。这次比上次带给我的冲击力要强上许多，可能是因为这件事情本身就比以往的要复杂许多。即便是快半年过去了，深夜也常感到孤独，晚上经常会梦到我们彼此解开了心结，冰释前嫌重归于好，或者梦到我们一拍两散，永不联系。我一直在感叹我这不平凡的经历，让我越发地确信我应该不会是一个平庸之辈。“平凡而不平庸”，我会平凡地活着，但我无法接收平庸的生活。昨晚出去跑了几公里，突然间的一瞬间感受到了一股前所未有的释然，最后冲刺的时候感受到了那种心无旁骛一心往前冲的感觉，我相信慢慢地肯定会走出来的。事业也好，爱情也罢，我绝不会逆来顺受，不会随波逐流，我要分析自己的问题，改正自己的错误，认识自己的软肋，找到自己的道路。毕竟每个人的追求都不同，只要敢于勇敢追求自己想要的生活，就是生活的勇者。\n\n<p style=\"font-family: 楷体;text-align:center;\">心怀期待的人还在等待</p>\n<p style=\"font-family: 楷体;text-align:center\">攒满失望的人早已离开</p>\n<p style=\"font-family: 楷体;text-align:center\">仍然自由自我 永远高唱我歌</p>\n<p style=\"font-family: 楷体;text-align:center\">走遍千里</p>\n\n<script>console.log(\"永远年轻，\\n永远热泪盈眶\")</script>\n","slug":"2022年度总结","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"clofkwp1h0003qxgi78si0gsl","content":"<p>&emsp;&emsp;下午去溜了好一会，从2点一直在街上溜达到下午5点多，走一会歇一会和朋友聊了很久，回家的路上越发地感觉应该写一点什么来整理一下我这一年以来的经历。其实这篇博客是除夕的晚上创建的，但是那晚什么都没写，也不知道该从哪里写起就睡觉去了，今晚打了一晚上的游戏，也打算写个开头就去睡觉了。<br><code>2022-02-05 23:57:00</code></p>\n<hr>\n<blockquote>\n<p>&emsp;&emsp;有些人总会像流星一样在那些平淡的日子里一闪而过，有幸能亲眼看到她的消逝，在我的心中留下一道永不会消逝的光芒,点缀着我的天空，照亮着我脚下的路。</p>\n</blockquote>\n<p>&emsp;&emsp;昨晚偶然和一位许久没有联系的朋友聊了几句，说来奇怪，明明当初认识她的时候几乎无话不谈，现在却不知道怎么开口。细细算来，我们认识已经3年有余，她从高三到大三，我从大一到大四，她变成了学姐，我也变成了老学姐。时间有些长，以至于想起曾经做过的一些傻事现在只觉得意味深长。她告诉我这三年她过得很不错，打了比赛拿了奖，拿了奖学金，过了六级，预备党员，暑假到机关单位实习，不过还是抱怨“好累”，我相信她说的“累”是真的。她又问道我有没有收到什么上市公司的“橄榄枝”，我笑着说我去年一直在准备考研的事情根本没来得及投简历。看着她细数大学拿到的荣誉，我也在问自己这四年收获了些什么？四六级、省赛银奖、“碰瓷”可以勉强算上的国赛铜奖、在同行面前能勉强算是入门的专业技术、外人听起来很牛其实算不上什么的校企实践经历。这些零零碎碎的经历拼凑起来我的大学四年，最后几乎丝毫没有犹豫地选择了考研，如今坐在家里等待生死未卜的考试成绩。<br>&emsp;&emsp;谈起考研，其实说不上什么远大的理想，就是希望能有个更好的平台和更好的文凭能够让我学到更多的知识，能够支撑着我亲手建造起属于自己的生活。有车有房，没有那么大的压力，希望朋友们也都能通过自己的努力过上好生活，偶尔和他们出去走一走逛一逛。更多的时间是和另一半待在一起，我们一起生活，宁静的下午我们慵懒地靠在一起聊着我们的过去和未来。如果能为集体，为社会做出一些贡献我当然是非常乐意的，只是就我个人的愿望而言，家庭和睦，物质生活富足就已经实我的梦中情生活了。关于以后留在什么地方工作，做什么样的工作，我有过一些考虑。如果能考上硕士，毕业后去大厂待几年如果薪水够我在当地买房那就选择定居，或者大厂不好混，那就靠着这张硕士文凭去做一名高校的老师，选择安稳的生活。如果很不幸我没有考上硕士，那就根据成绩的好坏判断是否还要二战的必要以及决定二战考哪里。说实话每次一想到自己很可能是没有希望考上的都会禁不住打一个寒颤，以后的打算摆在面前让我不寒而栗。可是现实是总归要面对的，读研，二战，工作，总要做出选择。</p>\n<blockquote>\n<p>&emsp;&emsp;分手不是那么容易就能走得出来的。</p>\n</blockquote>\n<p>&emsp;&emsp;这句话是我说的，或许也只是对我自己有效果。这次比上次带给我的冲击力要强上许多，可能是因为这件事情本身就比以往的要复杂许多。即便是快半年过去了，深夜也常感到孤独，晚上经常会梦到我们彼此解开了心结，冰释前嫌重归于好，或者梦到我们一拍两散，永不联系。我一直在感叹我这不平凡的经历，让我越发地确信我应该不会是一个平庸之辈。“平凡而不平庸”，我会平凡地活着，但我无法接收平庸的生活。昨晚出去跑了几公里，突然间的一瞬间感受到了一股前所未有的释然，最后冲刺的时候感受到了那种心无旁骛一心往前冲的感觉，我相信慢慢地肯定会走出来的。事业也好，爱情也罢，我绝不会逆来顺受，不会随波逐流，我要分析自己的问题，改正自己的错误，认识自己的软肋，找到自己的道路。毕竟每个人的追求都不同，只要敢于勇敢追求自己想要的生活，就是生活的勇者。</p>\n<p style=\"font-family: 楷体;text-align:center;\">心怀期待的人还在等待</p>\n<p style=\"font-family: 楷体;text-align:center\">攒满失望的人早已离开</p>\n<p style=\"font-family: 楷体;text-align:center\">仍然自由自我 永远高唱我歌</p>\n<p style=\"font-family: 楷体;text-align:center\">走遍千里</p>\n\n<script>console.log(\"永远年轻，\\n永远热泪盈眶\")</script>\n","site":{"data":{}},"excerpt":"","more":"<p>&emsp;&emsp;下午去溜了好一会，从2点一直在街上溜达到下午5点多，走一会歇一会和朋友聊了很久，回家的路上越发地感觉应该写一点什么来整理一下我这一年以来的经历。其实这篇博客是除夕的晚上创建的，但是那晚什么都没写，也不知道该从哪里写起就睡觉去了，今晚打了一晚上的游戏，也打算写个开头就去睡觉了。<br><code>2022-02-05 23:57:00</code></p>\n<hr>\n<blockquote>\n<p>&emsp;&emsp;有些人总会像流星一样在那些平淡的日子里一闪而过，有幸能亲眼看到她的消逝，在我的心中留下一道永不会消逝的光芒,点缀着我的天空，照亮着我脚下的路。</p>\n</blockquote>\n<p>&emsp;&emsp;昨晚偶然和一位许久没有联系的朋友聊了几句，说来奇怪，明明当初认识她的时候几乎无话不谈，现在却不知道怎么开口。细细算来，我们认识已经3年有余，她从高三到大三，我从大一到大四，她变成了学姐，我也变成了老学姐。时间有些长，以至于想起曾经做过的一些傻事现在只觉得意味深长。她告诉我这三年她过得很不错，打了比赛拿了奖，拿了奖学金，过了六级，预备党员，暑假到机关单位实习，不过还是抱怨“好累”，我相信她说的“累”是真的。她又问道我有没有收到什么上市公司的“橄榄枝”，我笑着说我去年一直在准备考研的事情根本没来得及投简历。看着她细数大学拿到的荣誉，我也在问自己这四年收获了些什么？四六级、省赛银奖、“碰瓷”可以勉强算上的国赛铜奖、在同行面前能勉强算是入门的专业技术、外人听起来很牛其实算不上什么的校企实践经历。这些零零碎碎的经历拼凑起来我的大学四年，最后几乎丝毫没有犹豫地选择了考研，如今坐在家里等待生死未卜的考试成绩。<br>&emsp;&emsp;谈起考研，其实说不上什么远大的理想，就是希望能有个更好的平台和更好的文凭能够让我学到更多的知识，能够支撑着我亲手建造起属于自己的生活。有车有房，没有那么大的压力，希望朋友们也都能通过自己的努力过上好生活，偶尔和他们出去走一走逛一逛。更多的时间是和另一半待在一起，我们一起生活，宁静的下午我们慵懒地靠在一起聊着我们的过去和未来。如果能为集体，为社会做出一些贡献我当然是非常乐意的，只是就我个人的愿望而言，家庭和睦，物质生活富足就已经实我的梦中情生活了。关于以后留在什么地方工作，做什么样的工作，我有过一些考虑。如果能考上硕士，毕业后去大厂待几年如果薪水够我在当地买房那就选择定居，或者大厂不好混，那就靠着这张硕士文凭去做一名高校的老师，选择安稳的生活。如果很不幸我没有考上硕士，那就根据成绩的好坏判断是否还要二战的必要以及决定二战考哪里。说实话每次一想到自己很可能是没有希望考上的都会禁不住打一个寒颤，以后的打算摆在面前让我不寒而栗。可是现实是总归要面对的，读研，二战，工作，总要做出选择。</p>\n<blockquote>\n<p>&emsp;&emsp;分手不是那么容易就能走得出来的。</p>\n</blockquote>\n<p>&emsp;&emsp;这句话是我说的，或许也只是对我自己有效果。这次比上次带给我的冲击力要强上许多，可能是因为这件事情本身就比以往的要复杂许多。即便是快半年过去了，深夜也常感到孤独，晚上经常会梦到我们彼此解开了心结，冰释前嫌重归于好，或者梦到我们一拍两散，永不联系。我一直在感叹我这不平凡的经历，让我越发地确信我应该不会是一个平庸之辈。“平凡而不平庸”，我会平凡地活着，但我无法接收平庸的生活。昨晚出去跑了几公里，突然间的一瞬间感受到了一股前所未有的释然，最后冲刺的时候感受到了那种心无旁骛一心往前冲的感觉，我相信慢慢地肯定会走出来的。事业也好，爱情也罢，我绝不会逆来顺受，不会随波逐流，我要分析自己的问题，改正自己的错误，认识自己的软肋，找到自己的道路。毕竟每个人的追求都不同，只要敢于勇敢追求自己想要的生活，就是生活的勇者。</p>\n<p style=\"font-family: 楷体;text-align:center;\">心怀期待的人还在等待</p>\n<p style=\"font-family: 楷体;text-align:center\">攒满失望的人早已离开</p>\n<p style=\"font-family: 楷体;text-align:center\">仍然自由自我 永远高唱我歌</p>\n<p style=\"font-family: 楷体;text-align:center\">走遍千里</p>\n\n<script>console.log(\"永远年轻，\\n永远热泪盈眶\")</script>\n"},{"title":"博客搭建完成","date":"2020-04-05T09:54:35.000Z","toc":true,"_content":"\n# 第一次博客\n\n## 纪念\n\n>  这是我的第一次博客，今天终于成功地用Hexo搭建起来一个个人博客。\n\n​\t最近在忙实验和项目， 事情还是不少的，下下来打算好好地复习一下功课，再研究点自己喜欢的小玩意。\n\n## 计划\n\n邻近五一了，5天时间，本来打算去找可爱的，但是她要和家人出去玩，所以五一假期应该会有许多的空余 时间了。这段时间也可以利用起来，完善一下最近想做的一些事情。\n\n+ **复习硬件和算法**\n+ **研究一下hexo，在github搭建一个完整的博客体系**\n+ 做点小手工 ， *这也是我一直以来非常想做的事情*\n+ 好久没有看英语了，得抓紧时间学英语\n+ 写一篇博客讲一讲自己搭建博客的经历\n+ 好好地看看数据库\n\n\n\n### 最后一条：**当然要和基友整一下大革命啦**！\n\n\n\n","source":"_posts/My-first-post.md","raw":"---\ntitle: 博客搭建完成\ndate: 2020-04-05 09:54:35\ntags: [日常]\ntoc: true\n---\n\n# 第一次博客\n\n## 纪念\n\n>  这是我的第一次博客，今天终于成功地用Hexo搭建起来一个个人博客。\n\n​\t最近在忙实验和项目， 事情还是不少的，下下来打算好好地复习一下功课，再研究点自己喜欢的小玩意。\n\n## 计划\n\n邻近五一了，5天时间，本来打算去找可爱的，但是她要和家人出去玩，所以五一假期应该会有许多的空余 时间了。这段时间也可以利用起来，完善一下最近想做的一些事情。\n\n+ **复习硬件和算法**\n+ **研究一下hexo，在github搭建一个完整的博客体系**\n+ 做点小手工 ， *这也是我一直以来非常想做的事情*\n+ 好久没有看英语了，得抓紧时间学英语\n+ 写一篇博客讲一讲自己搭建博客的经历\n+ 好好地看看数据库\n\n\n\n### 最后一条：**当然要和基友整一下大革命啦**！\n\n\n\n","slug":"My-first-post","published":1,"updated":"2023-11-01T09:50:42.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clofkwp1i0007qxgi7rtegwke","content":"<h1 id=\"第一次博客\"><a href=\"#第一次博客\" class=\"headerlink\" title=\"第一次博客\"></a>第一次博客</h1><h2 id=\"纪念\"><a href=\"#纪念\" class=\"headerlink\" title=\"纪念\"></a>纪念</h2><blockquote>\n<p> 这是我的第一次博客，今天终于成功地用Hexo搭建起来一个个人博客。</p>\n</blockquote>\n<p>​    最近在忙实验和项目， 事情还是不少的，下下来打算好好地复习一下功课，再研究点自己喜欢的小玩意。</p>\n<h2 id=\"计划\"><a href=\"#计划\" class=\"headerlink\" title=\"计划\"></a>计划</h2><p>邻近五一了，5天时间，本来打算去找可爱的，但是她要和家人出去玩，所以五一假期应该会有许多的空余 时间了。这段时间也可以利用起来，完善一下最近想做的一些事情。</p>\n<ul>\n<li><strong>复习硬件和算法</strong></li>\n<li><strong>研究一下hexo，在github搭建一个完整的博客体系</strong></li>\n<li>做点小手工 ， <em>这也是我一直以来非常想做的事情</em></li>\n<li>好久没有看英语了，得抓紧时间学英语</li>\n<li>写一篇博客讲一讲自己搭建博客的经历</li>\n<li>好好地看看数据库</li>\n</ul>\n<h3 id=\"最后一条：当然要和基友整一下大革命啦！\"><a href=\"#最后一条：当然要和基友整一下大革命啦！\" class=\"headerlink\" title=\"最后一条：当然要和基友整一下大革命啦！\"></a>最后一条：<strong>当然要和基友整一下大革命啦</strong>！</h3>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"第一次博客\"><a href=\"#第一次博客\" class=\"headerlink\" title=\"第一次博客\"></a>第一次博客</h1><h2 id=\"纪念\"><a href=\"#纪念\" class=\"headerlink\" title=\"纪念\"></a>纪念</h2><blockquote>\n<p> 这是我的第一次博客，今天终于成功地用Hexo搭建起来一个个人博客。</p>\n</blockquote>\n<p>​    最近在忙实验和项目， 事情还是不少的，下下来打算好好地复习一下功课，再研究点自己喜欢的小玩意。</p>\n<h2 id=\"计划\"><a href=\"#计划\" class=\"headerlink\" title=\"计划\"></a>计划</h2><p>邻近五一了，5天时间，本来打算去找可爱的，但是她要和家人出去玩，所以五一假期应该会有许多的空余 时间了。这段时间也可以利用起来，完善一下最近想做的一些事情。</p>\n<ul>\n<li><strong>复习硬件和算法</strong></li>\n<li><strong>研究一下hexo，在github搭建一个完整的博客体系</strong></li>\n<li>做点小手工 ， <em>这也是我一直以来非常想做的事情</em></li>\n<li>好久没有看英语了，得抓紧时间学英语</li>\n<li>写一篇博客讲一讲自己搭建博客的经历</li>\n<li>好好地看看数据库</li>\n</ul>\n<h3 id=\"最后一条：当然要和基友整一下大革命啦！\"><a href=\"#最后一条：当然要和基友整一下大革命啦！\" class=\"headerlink\" title=\"最后一条：当然要和基友整一下大革命啦！\"></a>最后一条：<strong>当然要和基友整一下大革命啦</strong>！</h3>"},{"title":"scrapy框架学习笔记","date":"2022-01-29T11:22:36.000Z","toc":true,"_content":"\n## scrapy框架\n- 什么是框架\n    集成了很多功能，并且具有很强的通用性的项目模板\n- 如何学习框架\n- 什么是scrapy\n    - 爬虫中封装好的“明星”框架，封装程度高，使用频率高\n    - 功能：\n        - 高性能持久化存储\n        - 异步数据下载\n        - 高性能数据解析\n        - 分布式\n    - 基本使用\n        - 环境安装\n            - mac、Linux: `pip install scrapy`\n            - windows:\n                - `pip install wheel`\n                - 下载安装twisted\n                - `pip install pywin32`\n                - `pip install scrapy`\n        - 创建工程：`scrapy startproject xxxPro`\n        - 执行工程：`scrapy crawl sipderName`\n- 数据解析\n    - `response.xpath()`\n    - `extract()`\n    - `extract_first()`\n- 持久化存储\n    - 基于终端指令：\n        - 要求：只可以将parse()方法的返回值存储到本地的文本文件中\n        - 步骤：将parse中需要存储的数据包装起来并作为返回值进入return\n        - 注意：持久化对应的文本文件类型只能是：json、csv、jl、jsonlines、marshal、pickle等\n        - 好处：简洁、高效、便捷\n        - 缺点：局限性强，数据只能存储为指定后缀的文本文件，且只能存储parse封装好的指定数据\n    - 基于管道：\n        - 编码流程：\n            - 数据解析\n            - 将解析的数据封装存储到item类型的对象\n- 手动发送请求\n    - `yield scrapy.Request(url, callback)`\n\n- 五大核心组件\n    - 引擎（接收数据流&触发事务）\n        - 引擎将请求对象发送给调度器的过滤器\n        - 从调度器的队列中获取请求对象并发送给下载器\n        - 将Response发送给Spider的parse\n        - 接受parse解析好的数据并发送给管道\n    - 爬虫类（Spider）\n        - 产生url，封装为请求对象发送给 引擎 ，并进行请求发送\n        - 调用parse进行数据解析并发送给引擎\n    - 管道\n        - 接收引擎发送的解析好的数据进行持久化存储\n    - 下载器\n        - 进行数据下载获取Response\n        - 提交Response至引擎\n    - 调度器\n        - 过滤器\n            对重复的请求对象进行去重，将去重后的请求对象发送到队列\n        - 队列\n    问题：引擎是如何触发事务的？\n        - 引擎通过接收到的不同数据流类型判断事务类型\n- 请求传参\n    - 使用场景：爬取解析的数据不在同一张页面中。（深度爬取）\n    - 需求：爬取Boss直聘岗位名称与岗位描述\n    \n- 图片数据爬取之ImagesPipeline\n    - 基于字符串和基于图片的区别\n        - 字符串： 只需要基于xpath进行解析且提交管道并进行持久化\n        - 图片： xpath解析出图片src的属性值，单独对图片地址发起请求获取图片二进制类型的数据\n    - ImagesPipeline:\n        - 只需要将img的src的属性值进行解析，提交到管道，管道就会对图片的src进行请求发送获取图片的二进制数据，且还会帮我们进行持久化存储\n        - 需求：爬取站长素材的高清图片\n        - 使用流程：\n            - 解析图片地址（懒加载）\n            - 将存储图片地址的item提交到指定的管道类\n            - 在管道文件中定制一个基于ImagesPipeline的管道类\n                - `get_media_request()`\n                - `file_path()`\n                - `item_completed()`\n            - 在配置文件中：\n                - 指定文件存储目录: `IMAGES_STORE = '[path]'`\n                - 指定开启的管道： 自定制的管道类\n        - 遇到的问题：\n            - item提交给管道后，管道不接收图片，死活没有反应: `INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)`\n            - LOG_LEVEL = 'DEBUG'后看到一条警告: \n    `WARNING: Disabled ImgsPipeline: ImagesPipeline requires installing Pillow 4.0.0 or later`于是就赶紧安装了Pillow, 问题得以解决\n              \n- 中间件\n    - 爬虫中间件\n    - 下载中间件\n        - 位置：引擎和下载器之间\n        - 功能：批量拦截整个工程中所有的请求和响应\n        - 拦截请求：\n            - 进行UA伪装（可以对指定的请求进行专门的UA伪装）\n            - 代理IP的设定\n        - 拦截响应：\n            - 篡改响应数据、对象\n            - 需求：爬取网易新闻数据（标题+内容）\n                1. 通过首页解析出五大板块对应详情页的URL（直接爬取）\n                2. 板块对应的新闻标题列表（动态加载）\n                3. 通过解析每一条新闻详情页URL，获取详情页源码解析出新闻内容（直接爬取）","source":"_posts/scrapy框架学习笔记.md","raw":"---\ntitle: scrapy框架学习笔记\ndate: 2022-01-29 11:22:36\ncategories: 学习\ntags: [scrapy, 爬虫, python, 框架]\ntoc: true\n---\n\n## scrapy框架\n- 什么是框架\n    集成了很多功能，并且具有很强的通用性的项目模板\n- 如何学习框架\n- 什么是scrapy\n    - 爬虫中封装好的“明星”框架，封装程度高，使用频率高\n    - 功能：\n        - 高性能持久化存储\n        - 异步数据下载\n        - 高性能数据解析\n        - 分布式\n    - 基本使用\n        - 环境安装\n            - mac、Linux: `pip install scrapy`\n            - windows:\n                - `pip install wheel`\n                - 下载安装twisted\n                - `pip install pywin32`\n                - `pip install scrapy`\n        - 创建工程：`scrapy startproject xxxPro`\n        - 执行工程：`scrapy crawl sipderName`\n- 数据解析\n    - `response.xpath()`\n    - `extract()`\n    - `extract_first()`\n- 持久化存储\n    - 基于终端指令：\n        - 要求：只可以将parse()方法的返回值存储到本地的文本文件中\n        - 步骤：将parse中需要存储的数据包装起来并作为返回值进入return\n        - 注意：持久化对应的文本文件类型只能是：json、csv、jl、jsonlines、marshal、pickle等\n        - 好处：简洁、高效、便捷\n        - 缺点：局限性强，数据只能存储为指定后缀的文本文件，且只能存储parse封装好的指定数据\n    - 基于管道：\n        - 编码流程：\n            - 数据解析\n            - 将解析的数据封装存储到item类型的对象\n- 手动发送请求\n    - `yield scrapy.Request(url, callback)`\n\n- 五大核心组件\n    - 引擎（接收数据流&触发事务）\n        - 引擎将请求对象发送给调度器的过滤器\n        - 从调度器的队列中获取请求对象并发送给下载器\n        - 将Response发送给Spider的parse\n        - 接受parse解析好的数据并发送给管道\n    - 爬虫类（Spider）\n        - 产生url，封装为请求对象发送给 引擎 ，并进行请求发送\n        - 调用parse进行数据解析并发送给引擎\n    - 管道\n        - 接收引擎发送的解析好的数据进行持久化存储\n    - 下载器\n        - 进行数据下载获取Response\n        - 提交Response至引擎\n    - 调度器\n        - 过滤器\n            对重复的请求对象进行去重，将去重后的请求对象发送到队列\n        - 队列\n    问题：引擎是如何触发事务的？\n        - 引擎通过接收到的不同数据流类型判断事务类型\n- 请求传参\n    - 使用场景：爬取解析的数据不在同一张页面中。（深度爬取）\n    - 需求：爬取Boss直聘岗位名称与岗位描述\n    \n- 图片数据爬取之ImagesPipeline\n    - 基于字符串和基于图片的区别\n        - 字符串： 只需要基于xpath进行解析且提交管道并进行持久化\n        - 图片： xpath解析出图片src的属性值，单独对图片地址发起请求获取图片二进制类型的数据\n    - ImagesPipeline:\n        - 只需要将img的src的属性值进行解析，提交到管道，管道就会对图片的src进行请求发送获取图片的二进制数据，且还会帮我们进行持久化存储\n        - 需求：爬取站长素材的高清图片\n        - 使用流程：\n            - 解析图片地址（懒加载）\n            - 将存储图片地址的item提交到指定的管道类\n            - 在管道文件中定制一个基于ImagesPipeline的管道类\n                - `get_media_request()`\n                - `file_path()`\n                - `item_completed()`\n            - 在配置文件中：\n                - 指定文件存储目录: `IMAGES_STORE = '[path]'`\n                - 指定开启的管道： 自定制的管道类\n        - 遇到的问题：\n            - item提交给管道后，管道不接收图片，死活没有反应: `INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)`\n            - LOG_LEVEL = 'DEBUG'后看到一条警告: \n    `WARNING: Disabled ImgsPipeline: ImagesPipeline requires installing Pillow 4.0.0 or later`于是就赶紧安装了Pillow, 问题得以解决\n              \n- 中间件\n    - 爬虫中间件\n    - 下载中间件\n        - 位置：引擎和下载器之间\n        - 功能：批量拦截整个工程中所有的请求和响应\n        - 拦截请求：\n            - 进行UA伪装（可以对指定的请求进行专门的UA伪装）\n            - 代理IP的设定\n        - 拦截响应：\n            - 篡改响应数据、对象\n            - 需求：爬取网易新闻数据（标题+内容）\n                1. 通过首页解析出五大板块对应详情页的URL（直接爬取）\n                2. 板块对应的新闻标题列表（动态加载）\n                3. 通过解析每一条新闻详情页URL，获取详情页源码解析出新闻内容（直接爬取）","slug":"scrapy框架学习笔记","published":1,"updated":"2023-11-01T09:50:42.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clofkwp1j0009qxgi8yax4vao","content":"<h2 id=\"scrapy框架\"><a href=\"#scrapy框架\" class=\"headerlink\" title=\"scrapy框架\"></a>scrapy框架</h2><ul>\n<li><p>什么是框架<br>  集成了很多功能，并且具有很强的通用性的项目模板</p>\n</li>\n<li><p>如何学习框架</p>\n</li>\n<li><p>什么是scrapy</p>\n<ul>\n<li>爬虫中封装好的“明星”框架，封装程度高，使用频率高</li>\n<li>功能：<ul>\n<li>高性能持久化存储</li>\n<li>异步数据下载</li>\n<li>高性能数据解析</li>\n<li>分布式</li>\n</ul>\n</li>\n<li>基本使用<ul>\n<li>环境安装<ul>\n<li>mac、Linux: <code>pip install scrapy</code></li>\n<li>windows:<ul>\n<li><code>pip install wheel</code></li>\n<li>下载安装twisted</li>\n<li><code>pip install pywin32</code></li>\n<li><code>pip install scrapy</code></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>创建工程：<code>scrapy startproject xxxPro</code></li>\n<li>执行工程：<code>scrapy crawl sipderName</code></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>数据解析</p>\n<ul>\n<li><code>response.xpath()</code></li>\n<li><code>extract()</code></li>\n<li><code>extract_first()</code></li>\n</ul>\n</li>\n<li><p>持久化存储</p>\n<ul>\n<li>基于终端指令：<ul>\n<li>要求：只可以将parse()方法的返回值存储到本地的文本文件中</li>\n<li>步骤：将parse中需要存储的数据包装起来并作为返回值进入return</li>\n<li>注意：持久化对应的文本文件类型只能是：json、csv、jl、jsonlines、marshal、pickle等</li>\n<li>好处：简洁、高效、便捷</li>\n<li>缺点：局限性强，数据只能存储为指定后缀的文本文件，且只能存储parse封装好的指定数据</li>\n</ul>\n</li>\n<li>基于管道：<ul>\n<li>编码流程：<ul>\n<li>数据解析</li>\n<li>将解析的数据封装存储到item类型的对象</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>手动发送请求</p>\n<ul>\n<li><code>yield scrapy.Request(url, callback)</code></li>\n</ul>\n</li>\n<li><p>五大核心组件</p>\n<ul>\n<li>引擎（接收数据流&amp;触发事务）<ul>\n<li>引擎将请求对象发送给调度器的过滤器</li>\n<li>从调度器的队列中获取请求对象并发送给下载器</li>\n<li>将Response发送给Spider的parse</li>\n<li>接受parse解析好的数据并发送给管道</li>\n</ul>\n</li>\n<li>爬虫类（Spider）<ul>\n<li>产生url，封装为请求对象发送给 引擎 ，并进行请求发送</li>\n<li>调用parse进行数据解析并发送给引擎</li>\n</ul>\n</li>\n<li>管道<ul>\n<li>接收引擎发送的解析好的数据进行持久化存储</li>\n</ul>\n</li>\n<li>下载器<ul>\n<li>进行数据下载获取Response</li>\n<li>提交Response至引擎</li>\n</ul>\n</li>\n<li>调度器<ul>\n<li>过滤器<br>  对重复的请求对象进行去重，将去重后的请求对象发送到队列</li>\n<li>队列<br>问题：引擎是如何触发事务的？</li>\n<li>引擎通过接收到的不同数据流类型判断事务类型</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>请求传参</p>\n<ul>\n<li>使用场景：爬取解析的数据不在同一张页面中。（深度爬取）</li>\n<li>需求：爬取Boss直聘岗位名称与岗位描述</li>\n</ul>\n</li>\n<li><p>图片数据爬取之ImagesPipeline</p>\n<ul>\n<li>基于字符串和基于图片的区别<ul>\n<li>字符串： 只需要基于xpath进行解析且提交管道并进行持久化</li>\n<li>图片： xpath解析出图片src的属性值，单独对图片地址发起请求获取图片二进制类型的数据</li>\n</ul>\n</li>\n<li>ImagesPipeline:<ul>\n<li>只需要将img的src的属性值进行解析，提交到管道，管道就会对图片的src进行请求发送获取图片的二进制数据，且还会帮我们进行持久化存储</li>\n<li>需求：爬取站长素材的高清图片</li>\n<li>使用流程：<ul>\n<li>解析图片地址（懒加载）</li>\n<li>将存储图片地址的item提交到指定的管道类</li>\n<li>在管道文件中定制一个基于ImagesPipeline的管道类<ul>\n<li><code>get_media_request()</code></li>\n<li><code>file_path()</code></li>\n<li><code>item_completed()</code></li>\n</ul>\n</li>\n<li>在配置文件中：<ul>\n<li>指定文件存储目录: <code>IMAGES_STORE = &#39;[path]&#39;</code></li>\n<li>指定开启的管道： 自定制的管道类</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>遇到的问题：<ul>\n<li>item提交给管道后，管道不接收图片，死活没有反应: <code>INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)</code></li>\n<li>LOG_LEVEL = ‘DEBUG’后看到一条警告:<br><code>WARNING: Disabled ImgsPipeline: ImagesPipeline requires installing Pillow 4.0.0 or later</code>于是就赶紧安装了Pillow, 问题得以解决</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>中间件</p>\n<ul>\n<li>爬虫中间件</li>\n<li>下载中间件<ul>\n<li>位置：引擎和下载器之间</li>\n<li>功能：批量拦截整个工程中所有的请求和响应</li>\n<li>拦截请求：<ul>\n<li>进行UA伪装（可以对指定的请求进行专门的UA伪装）</li>\n<li>代理IP的设定</li>\n</ul>\n</li>\n<li>拦截响应：<ul>\n<li>篡改响应数据、对象</li>\n<li>需求：爬取网易新闻数据（标题+内容）<ol>\n<li>通过首页解析出五大板块对应详情页的URL（直接爬取）</li>\n<li>板块对应的新闻标题列表（动态加载）</li>\n<li>通过解析每一条新闻详情页URL，获取详情页源码解析出新闻内容（直接爬取）</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"scrapy框架\"><a href=\"#scrapy框架\" class=\"headerlink\" title=\"scrapy框架\"></a>scrapy框架</h2><ul>\n<li><p>什么是框架<br>  集成了很多功能，并且具有很强的通用性的项目模板</p>\n</li>\n<li><p>如何学习框架</p>\n</li>\n<li><p>什么是scrapy</p>\n<ul>\n<li>爬虫中封装好的“明星”框架，封装程度高，使用频率高</li>\n<li>功能：<ul>\n<li>高性能持久化存储</li>\n<li>异步数据下载</li>\n<li>高性能数据解析</li>\n<li>分布式</li>\n</ul>\n</li>\n<li>基本使用<ul>\n<li>环境安装<ul>\n<li>mac、Linux: <code>pip install scrapy</code></li>\n<li>windows:<ul>\n<li><code>pip install wheel</code></li>\n<li>下载安装twisted</li>\n<li><code>pip install pywin32</code></li>\n<li><code>pip install scrapy</code></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>创建工程：<code>scrapy startproject xxxPro</code></li>\n<li>执行工程：<code>scrapy crawl sipderName</code></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>数据解析</p>\n<ul>\n<li><code>response.xpath()</code></li>\n<li><code>extract()</code></li>\n<li><code>extract_first()</code></li>\n</ul>\n</li>\n<li><p>持久化存储</p>\n<ul>\n<li>基于终端指令：<ul>\n<li>要求：只可以将parse()方法的返回值存储到本地的文本文件中</li>\n<li>步骤：将parse中需要存储的数据包装起来并作为返回值进入return</li>\n<li>注意：持久化对应的文本文件类型只能是：json、csv、jl、jsonlines、marshal、pickle等</li>\n<li>好处：简洁、高效、便捷</li>\n<li>缺点：局限性强，数据只能存储为指定后缀的文本文件，且只能存储parse封装好的指定数据</li>\n</ul>\n</li>\n<li>基于管道：<ul>\n<li>编码流程：<ul>\n<li>数据解析</li>\n<li>将解析的数据封装存储到item类型的对象</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>手动发送请求</p>\n<ul>\n<li><code>yield scrapy.Request(url, callback)</code></li>\n</ul>\n</li>\n<li><p>五大核心组件</p>\n<ul>\n<li>引擎（接收数据流&amp;触发事务）<ul>\n<li>引擎将请求对象发送给调度器的过滤器</li>\n<li>从调度器的队列中获取请求对象并发送给下载器</li>\n<li>将Response发送给Spider的parse</li>\n<li>接受parse解析好的数据并发送给管道</li>\n</ul>\n</li>\n<li>爬虫类（Spider）<ul>\n<li>产生url，封装为请求对象发送给 引擎 ，并进行请求发送</li>\n<li>调用parse进行数据解析并发送给引擎</li>\n</ul>\n</li>\n<li>管道<ul>\n<li>接收引擎发送的解析好的数据进行持久化存储</li>\n</ul>\n</li>\n<li>下载器<ul>\n<li>进行数据下载获取Response</li>\n<li>提交Response至引擎</li>\n</ul>\n</li>\n<li>调度器<ul>\n<li>过滤器<br>  对重复的请求对象进行去重，将去重后的请求对象发送到队列</li>\n<li>队列<br>问题：引擎是如何触发事务的？</li>\n<li>引擎通过接收到的不同数据流类型判断事务类型</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>请求传参</p>\n<ul>\n<li>使用场景：爬取解析的数据不在同一张页面中。（深度爬取）</li>\n<li>需求：爬取Boss直聘岗位名称与岗位描述</li>\n</ul>\n</li>\n<li><p>图片数据爬取之ImagesPipeline</p>\n<ul>\n<li>基于字符串和基于图片的区别<ul>\n<li>字符串： 只需要基于xpath进行解析且提交管道并进行持久化</li>\n<li>图片： xpath解析出图片src的属性值，单独对图片地址发起请求获取图片二进制类型的数据</li>\n</ul>\n</li>\n<li>ImagesPipeline:<ul>\n<li>只需要将img的src的属性值进行解析，提交到管道，管道就会对图片的src进行请求发送获取图片的二进制数据，且还会帮我们进行持久化存储</li>\n<li>需求：爬取站长素材的高清图片</li>\n<li>使用流程：<ul>\n<li>解析图片地址（懒加载）</li>\n<li>将存储图片地址的item提交到指定的管道类</li>\n<li>在管道文件中定制一个基于ImagesPipeline的管道类<ul>\n<li><code>get_media_request()</code></li>\n<li><code>file_path()</code></li>\n<li><code>item_completed()</code></li>\n</ul>\n</li>\n<li>在配置文件中：<ul>\n<li>指定文件存储目录: <code>IMAGES_STORE = &#39;[path]&#39;</code></li>\n<li>指定开启的管道： 自定制的管道类</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>遇到的问题：<ul>\n<li>item提交给管道后，管道不接收图片，死活没有反应: <code>INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)</code></li>\n<li>LOG_LEVEL = ‘DEBUG’后看到一条警告:<br><code>WARNING: Disabled ImgsPipeline: ImagesPipeline requires installing Pillow 4.0.0 or later</code>于是就赶紧安装了Pillow, 问题得以解决</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>中间件</p>\n<ul>\n<li>爬虫中间件</li>\n<li>下载中间件<ul>\n<li>位置：引擎和下载器之间</li>\n<li>功能：批量拦截整个工程中所有的请求和响应</li>\n<li>拦截请求：<ul>\n<li>进行UA伪装（可以对指定的请求进行专门的UA伪装）</li>\n<li>代理IP的设定</li>\n</ul>\n</li>\n<li>拦截响应：<ul>\n<li>篡改响应数据、对象</li>\n<li>需求：爬取网易新闻数据（标题+内容）<ol>\n<li>通过首页解析出五大板块对应详情页的URL（直接爬取）</li>\n<li>板块对应的新闻标题列表（动态加载）</li>\n<li>通过解析每一条新闻详情页URL，获取详情页源码解析出新闻内容（直接爬取）</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n"},{"title":"scrapy框架爬取网易新闻","date":"2022-01-29T12:22:12.000Z","toc":true,"_content":"\n\n## scrapy爬取网易新闻\n\n> 使用scrapy爬取网易新闻的**国内**、**国际**、**航空**三个板块的新闻数据存储在csv中\n\n### 初始化操作\n```shell\nscrapy startproject wangyiPro # 新建项目\ncd wangyiPro\nscrapy genspider news # 创建爬虫\n```\n### 编写爬虫(news.py)\n```python\nimport scrapy\nfrom selenium.webdriver import Chrome, ChromeOptions\nfrom wangyiPro.items import WangyiproItem\nimport re\n\n\nclass NewsSpider(scrapy.Spider):\n    name = 'news'\n    # allowed_domains = ['www.xxx.com']\n    start_urls = ['https://news.163.com/']\n\n    '''\n        爬虫初始化阶段创建selenium无头浏览器实例用于获取动态加载的数据\n    '''\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        options = ChromeOptions()\n        options.add_experimental_option(\"excludeSwitches\",['enable-automation'])\n        # options.add_argument('--headless')  这两个是无头浏览器的选项\n        # options.add_argument('--disable-gpu')\n        self.bro = Chrome(executable_path='D:\\\\Project\\\\python\\\\scrapy-test\\\\5.动态加载数据处理\\\\chromedriver.exe',\n                          chrome_options=options)\n\n    # 解析五大板块对应详情页的url\n    section_urls = []\n\n    # parse用于解析网易新闻的首页导航栏的对应板块url\n    def parse(self, response):\n        li_list = response.xpath('//*[@id=\"index2016_wrap\"]/div[3]/div[2]/div[2]/div[2]/div/ul/li')\n        # with open('page.html', 'w', encoding='utf-8') as fp:\n        #     fp.write(response.text)\n        index_list = [3, 6]\n        # index_list = [2]\n        # 板块url\n        for index in index_list:\n            name = li_list[index].xpath('./a/text()').extract_first()\n            url = li_list[index].xpath('./a/@href').extract_first()\n            item = {\n                \"url\": url,\n                \"name\": name\n            }\n            self.section_urls.append(item)\n        # 依次对每个板块对应的页面进行请求\n        for item in self.section_urls:\n            # print(url)\n            yield scrapy.Request(url=item['url'], callback=self.parse_section,\n                                 meta={\"url\": item['url'], \"category\": item['name']})\n\n    # 解析新闻标题和详情页url\n    def parse_section(self, response):\n        with open('./page.html', 'w', encoding='utf-8') as fp:\n            fp.write(response.text) # 用于储存页面便于调试\n        div_list = response.xpath('//div[@class=\"ndi_main\"]/div')\n        category = response.meta['category']\n        print(div_list[0])\n        for div in div_list:\n            title = div.xpath('./div//h3/a/text()').extract_first()\n            detail_url = div.xpath('./div//h3/a//@href').extract_first()\n            print(title, detail_url)\n            item = WangyiproItem()\n            item['title'] = title\n            item['category'] = category\n            yield scrapy.Request(url=detail_url, callback=self.parse_detail, meta={\"item\": item})\n\n    # 解析新闻数据\n    def parse_detail(self, response):\n        '''\n            这一部分是对新闻的内容、发布时间、来源做解析\n            内容获取后进行数据清晰，去掉空行、制表符等多余内容\n        '''\n        content = response.xpath('//*[@id=\"content\"]/div[2]').extract()\n        content = ''.join(content)\n        content = re.sub('\\n', '', content)\n        content = re.sub('\\s', '', content)\n        content = re.sub(' ', '', content)\n        item = response.meta['item']\n        item['content'] = content\n        '''\n            发布时间的原始格式是\"\\n         2022-01-22 12:02:20 来源:\",使用函数对时间部分进行提取\n        '''\n        timeline = response.xpath('//div[@class=\"post_info\"]/text()').extract_first()\n        timeline = timeline.split('来源')[0]\n        timeline = re.findall(pattern=r'20?.* ?.*:[0-9]{2}', string=timeline)[0]\n        item['timeline'] = timeline\n        item['origin'] = response.xpath('//*[@id=\"container\"]/div[1]/div[2]/a/text()').extract_first()\n        # print(item)\n        yield item\n\n    def closed(spider, reason):\n        spider.bro.quit()\n        pass\n```\n\n### items.py\n```python\nimport scrapy\n\n\nclass WangyiproItem(scrapy.Item):\n    # 标题、内容、来源、发布时间、分类\n    title = scrapy.Field()\n    content = scrapy.Field()\n    origin = scrapy.Field()\n    timeline = scrapy.Field()\n    category = scrapy.Field()\n```\n\n### 中间件middleware.py\n> 中间件部分主要用于处理新闻板块的新闻列表部分是动态加载出来的，所以在这里使用`selenium`将获取到的动态加载数据替换原先下载器获取的数据，然后发送给引擎处理\n```python\n# Define here the models for your spider middleware\n\nimport time\n\nfrom scrapy import signals\nfrom scrapy.http import HtmlResponse\n\n# useful for handling different item types with a single interface\nfrom itemadapter import is_item, ItemAdapter\n\n\nclass WangyiproDownloaderMiddleware(object):\n    # Not all methods need to be defined. If a method is not defined,\n    # scrapy acts as if the downloader middleware does not modify the\n    # passed objects.\n\n    def process_request(self, request, spider):\n        # Called for each request that goes through the downloader\n        # middleware.\n        # print('request middleware')\n\n        # Must either:\n        # - return None: continue processing this request\n        # - or return a Response object\n        # - or return a Request object\n        # - or raise IgnoreRequest: process_exception() methods of\n        #   installed downloader middleware will be called\n        return None\n\n    #  拦截板块详情页响应对象，修改为符合需求的对象\n    def process_response(self, request, response, spider):\n        #  获取在爬虫中定义的浏览器对象\n        print('开始拦截...')\n        bro = spider.bro\n        urls = []\n        for url in spider.section_urls:\n            urls.append(url['url'])\n        # Called with the response returned from the downloader.\n        #  筛选对应的响应对象\n        if request.url in urls:\n            # response 板块详情页响应对象\n            # 实例化新的响应对象，包含动态加载的数据\n            '''\n                如何获取动态加载的响应数据？\n                selenium\n            '''\n            bro.get(url=request.url)\n            bro.implicitly_wait(30)  # 隐形等待最长30s\n            # time.sleep(4)\n            page_text = bro.page_source # 获取动态加载的新闻数据\n            new_res = HtmlResponse(url=request.url, body=page_text, encoding='utf-8', request=request)\n            return new_res\n        else:\n            print('Middleware no filter:', request.url)\n            return response\n\n    def process_exception(self, request, exception, spider):\n        # Called when a download handler or a process_request()\n        # (from other downloader middleware) raises an exception.\n\n        # Must either:\n        # - return None: continue processing this exception\n        # - return a Response object: stops process_exception() chain\n        # - return a Request object: stops process_exception() chain\n        return None\n\n```\n### 管道pipelines.py\n> 用于持久化存储\n```python\n# Define your item pipelines here\n#\n# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html\n\n\n# useful for handling different item types with a single interface\nimport csv\nimport os\n\nfrom itemadapter import ItemAdapter\n\n\nclass WangyiproPipeline:\n    def __init__(self):\n        # 如果文件不存在就新建文件\n        # 这里参考了https://www.cnblogs.com/shawone/p/10228912.html\n        if not os.path.exists('./news.csv'):\n            # 打开文件，指定方式为写，利用第3个参数把csv写数据时产生的空行消除\n            self.f = open(\"news.csv\", \"a\", newline=\"\", encoding='utf-8')\n            # 设置文件第一行的字段名，注意要跟spider传过来的字典key名称相同\n            self.fieldnames = [\"title\", \"content\", \"origin\", \"timeline\", \"category\"]\n            # 指定文件的写入方式为csv字典写入，参数1为指定具体文件，参数2为指定字段名\n            self.writer = csv.DictWriter(self.f, fieldnames=self.fieldnames)\n            # 写入第一行字段名，因为只要写入一次，所以文件放在__init__里面\n            self.writer.writeheader()\n        else:\n            self.f = open(\"news.csv\", \"a\", newline=\"\", encoding='utf-8')\n            self.fieldnames = [\"title\", \"content\", \"origin\", \"timeline\", \"category\"]\n            self.writer = csv.DictWriter(self.f, fieldnames=self.fieldnames)\n    '''\n        重写父类方法\n        该仅仅在爬虫开始时调用一次\n    '''\n    def open_spider(self, spider):\n        pass\n\n    def process_item(self, item, spider):\n        self.writer.writerow(item)\n        return item  # 传递给下一个执行的管道类\n\n    def close_spider(self, spider):\n        print('结束爬虫...')\n        self.f.close()\n\n```\n### 项目配置settings.py\n> 这是坑比较多的一部分\n#### UA伪装与代理IP\n```python\n# 由于网易没有太复杂的校验，所有我的全部请求使用的一样的请求头\n# Crawl responsibly by identifying yourself (and your website) on the user-agent\nUSER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36'\n```\n> 另外代理IP可以在中间件中的`downloader`类中的`process_exception`函数中做判断并设置代理IP\n```python\n# 拦截发生异常的请求\n    def process_exception(self, request, exception, spider):\n        # Called when a download handler or a process_request()\n        # (from other downloader middleware) raises an exception.\n\n        #  代理\n        if request.split(':')[0]=='http':\n            request.meta['proxy'] = 'http://'+ random.choice(self.proxy_http)\n        else:\n            request.meta['proxy'] = 'http://'+ random.choice(self.proxy_https)\n        # Must either:\n        # - return None: continue processing this exception\n        # - return a Response object: stops process_exception() chain\n        # - return a Request object: stops process_exception() chain\n        return request\n```\n> 最后就是一些常见配置\n```python\n# Obey robots.txt rules\nROBOTSTXT_OBEY = False\nLOG_LEVEL = 'ERROR'\n# Enable or disable downloader middlewares\n# 这里有个很坑的地方是关于中间件，下载中间件和爬虫中间件的配置是在两个不同的地方，我们只需要开启下载中间件就可以了。第一次使用的时候没有看清开启的是SPIDER_MIDDLEWARES，还特意把WangyiproSpiderrMiddleware换成WangyiproDownloaderMiddleware因此走了很多弯路，导致中间件调试了很久都不起作用，我还以为我电脑坏了。\n\nSPIDER_MIDDLEWARES = {\n#   'wangyiPro.middlewares.WangyiproSpiderrMiddleware': 543,\n   'wangyiPro.middlewares.WangyiproDownloaderMiddleware': 543,\n}\n\nDOWNLOADER_MIDDLEWARES = {\n   'wangyiPro.middlewares.WangyiproDownloaderMiddleware': 543,\n}\n# Configure item pipelines\nITEM_PIPELINES = {\n   'wangyiPro.pipelines.WangyiproPipeline': 300,\n}\n\n```\n\n### 关于调试main.py\n&emsp;&emsp;起初运行爬虫都是在控制台中用`scrapy`命令，但是这样就无法让IDE中的断点生效从而无法调试，后来参考了`https://www.cnblogs.com/weixuqin/p/9074448.html`, 在项目的根目录创建`main.py`，写入以下内容后右键`debug`开启了调试功能\n```python\n#!/usr/bin/env python\n#-*- coding:utf-8 -*-\n\nfrom scrapy.cmdline import execute\nimport os\nimport sys\n\n#添加当前项目的绝对地址\nsys.path.append(os.path.dirname(os.path.abspath(__file__)))\n#执行 scrapy 内置的函数方法execute，  使用 crawl 爬取并调试，最后一个参数news 是我的爬虫文件名\nexecute(['scrapy', 'crawl', 'news'])\n```\n\n### 最终结果\n![预览](https://s2.loli.net/2022/01/29/c2eTmrxBCO3KYqV.png)","source":"_posts/scrapy爬取网易新闻.md","raw":"---\ntitle: scrapy框架爬取网易新闻\ndate: 2022-01-29 12:22:12\ncategories: 学习\ntags: [scrapy,爬虫,网易新闻]\ntoc: true\n---\n\n\n## scrapy爬取网易新闻\n\n> 使用scrapy爬取网易新闻的**国内**、**国际**、**航空**三个板块的新闻数据存储在csv中\n\n### 初始化操作\n```shell\nscrapy startproject wangyiPro # 新建项目\ncd wangyiPro\nscrapy genspider news # 创建爬虫\n```\n### 编写爬虫(news.py)\n```python\nimport scrapy\nfrom selenium.webdriver import Chrome, ChromeOptions\nfrom wangyiPro.items import WangyiproItem\nimport re\n\n\nclass NewsSpider(scrapy.Spider):\n    name = 'news'\n    # allowed_domains = ['www.xxx.com']\n    start_urls = ['https://news.163.com/']\n\n    '''\n        爬虫初始化阶段创建selenium无头浏览器实例用于获取动态加载的数据\n    '''\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        options = ChromeOptions()\n        options.add_experimental_option(\"excludeSwitches\",['enable-automation'])\n        # options.add_argument('--headless')  这两个是无头浏览器的选项\n        # options.add_argument('--disable-gpu')\n        self.bro = Chrome(executable_path='D:\\\\Project\\\\python\\\\scrapy-test\\\\5.动态加载数据处理\\\\chromedriver.exe',\n                          chrome_options=options)\n\n    # 解析五大板块对应详情页的url\n    section_urls = []\n\n    # parse用于解析网易新闻的首页导航栏的对应板块url\n    def parse(self, response):\n        li_list = response.xpath('//*[@id=\"index2016_wrap\"]/div[3]/div[2]/div[2]/div[2]/div/ul/li')\n        # with open('page.html', 'w', encoding='utf-8') as fp:\n        #     fp.write(response.text)\n        index_list = [3, 6]\n        # index_list = [2]\n        # 板块url\n        for index in index_list:\n            name = li_list[index].xpath('./a/text()').extract_first()\n            url = li_list[index].xpath('./a/@href').extract_first()\n            item = {\n                \"url\": url,\n                \"name\": name\n            }\n            self.section_urls.append(item)\n        # 依次对每个板块对应的页面进行请求\n        for item in self.section_urls:\n            # print(url)\n            yield scrapy.Request(url=item['url'], callback=self.parse_section,\n                                 meta={\"url\": item['url'], \"category\": item['name']})\n\n    # 解析新闻标题和详情页url\n    def parse_section(self, response):\n        with open('./page.html', 'w', encoding='utf-8') as fp:\n            fp.write(response.text) # 用于储存页面便于调试\n        div_list = response.xpath('//div[@class=\"ndi_main\"]/div')\n        category = response.meta['category']\n        print(div_list[0])\n        for div in div_list:\n            title = div.xpath('./div//h3/a/text()').extract_first()\n            detail_url = div.xpath('./div//h3/a//@href').extract_first()\n            print(title, detail_url)\n            item = WangyiproItem()\n            item['title'] = title\n            item['category'] = category\n            yield scrapy.Request(url=detail_url, callback=self.parse_detail, meta={\"item\": item})\n\n    # 解析新闻数据\n    def parse_detail(self, response):\n        '''\n            这一部分是对新闻的内容、发布时间、来源做解析\n            内容获取后进行数据清晰，去掉空行、制表符等多余内容\n        '''\n        content = response.xpath('//*[@id=\"content\"]/div[2]').extract()\n        content = ''.join(content)\n        content = re.sub('\\n', '', content)\n        content = re.sub('\\s', '', content)\n        content = re.sub(' ', '', content)\n        item = response.meta['item']\n        item['content'] = content\n        '''\n            发布时间的原始格式是\"\\n         2022-01-22 12:02:20 来源:\",使用函数对时间部分进行提取\n        '''\n        timeline = response.xpath('//div[@class=\"post_info\"]/text()').extract_first()\n        timeline = timeline.split('来源')[0]\n        timeline = re.findall(pattern=r'20?.* ?.*:[0-9]{2}', string=timeline)[0]\n        item['timeline'] = timeline\n        item['origin'] = response.xpath('//*[@id=\"container\"]/div[1]/div[2]/a/text()').extract_first()\n        # print(item)\n        yield item\n\n    def closed(spider, reason):\n        spider.bro.quit()\n        pass\n```\n\n### items.py\n```python\nimport scrapy\n\n\nclass WangyiproItem(scrapy.Item):\n    # 标题、内容、来源、发布时间、分类\n    title = scrapy.Field()\n    content = scrapy.Field()\n    origin = scrapy.Field()\n    timeline = scrapy.Field()\n    category = scrapy.Field()\n```\n\n### 中间件middleware.py\n> 中间件部分主要用于处理新闻板块的新闻列表部分是动态加载出来的，所以在这里使用`selenium`将获取到的动态加载数据替换原先下载器获取的数据，然后发送给引擎处理\n```python\n# Define here the models for your spider middleware\n\nimport time\n\nfrom scrapy import signals\nfrom scrapy.http import HtmlResponse\n\n# useful for handling different item types with a single interface\nfrom itemadapter import is_item, ItemAdapter\n\n\nclass WangyiproDownloaderMiddleware(object):\n    # Not all methods need to be defined. If a method is not defined,\n    # scrapy acts as if the downloader middleware does not modify the\n    # passed objects.\n\n    def process_request(self, request, spider):\n        # Called for each request that goes through the downloader\n        # middleware.\n        # print('request middleware')\n\n        # Must either:\n        # - return None: continue processing this request\n        # - or return a Response object\n        # - or return a Request object\n        # - or raise IgnoreRequest: process_exception() methods of\n        #   installed downloader middleware will be called\n        return None\n\n    #  拦截板块详情页响应对象，修改为符合需求的对象\n    def process_response(self, request, response, spider):\n        #  获取在爬虫中定义的浏览器对象\n        print('开始拦截...')\n        bro = spider.bro\n        urls = []\n        for url in spider.section_urls:\n            urls.append(url['url'])\n        # Called with the response returned from the downloader.\n        #  筛选对应的响应对象\n        if request.url in urls:\n            # response 板块详情页响应对象\n            # 实例化新的响应对象，包含动态加载的数据\n            '''\n                如何获取动态加载的响应数据？\n                selenium\n            '''\n            bro.get(url=request.url)\n            bro.implicitly_wait(30)  # 隐形等待最长30s\n            # time.sleep(4)\n            page_text = bro.page_source # 获取动态加载的新闻数据\n            new_res = HtmlResponse(url=request.url, body=page_text, encoding='utf-8', request=request)\n            return new_res\n        else:\n            print('Middleware no filter:', request.url)\n            return response\n\n    def process_exception(self, request, exception, spider):\n        # Called when a download handler or a process_request()\n        # (from other downloader middleware) raises an exception.\n\n        # Must either:\n        # - return None: continue processing this exception\n        # - return a Response object: stops process_exception() chain\n        # - return a Request object: stops process_exception() chain\n        return None\n\n```\n### 管道pipelines.py\n> 用于持久化存储\n```python\n# Define your item pipelines here\n#\n# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html\n\n\n# useful for handling different item types with a single interface\nimport csv\nimport os\n\nfrom itemadapter import ItemAdapter\n\n\nclass WangyiproPipeline:\n    def __init__(self):\n        # 如果文件不存在就新建文件\n        # 这里参考了https://www.cnblogs.com/shawone/p/10228912.html\n        if not os.path.exists('./news.csv'):\n            # 打开文件，指定方式为写，利用第3个参数把csv写数据时产生的空行消除\n            self.f = open(\"news.csv\", \"a\", newline=\"\", encoding='utf-8')\n            # 设置文件第一行的字段名，注意要跟spider传过来的字典key名称相同\n            self.fieldnames = [\"title\", \"content\", \"origin\", \"timeline\", \"category\"]\n            # 指定文件的写入方式为csv字典写入，参数1为指定具体文件，参数2为指定字段名\n            self.writer = csv.DictWriter(self.f, fieldnames=self.fieldnames)\n            # 写入第一行字段名，因为只要写入一次，所以文件放在__init__里面\n            self.writer.writeheader()\n        else:\n            self.f = open(\"news.csv\", \"a\", newline=\"\", encoding='utf-8')\n            self.fieldnames = [\"title\", \"content\", \"origin\", \"timeline\", \"category\"]\n            self.writer = csv.DictWriter(self.f, fieldnames=self.fieldnames)\n    '''\n        重写父类方法\n        该仅仅在爬虫开始时调用一次\n    '''\n    def open_spider(self, spider):\n        pass\n\n    def process_item(self, item, spider):\n        self.writer.writerow(item)\n        return item  # 传递给下一个执行的管道类\n\n    def close_spider(self, spider):\n        print('结束爬虫...')\n        self.f.close()\n\n```\n### 项目配置settings.py\n> 这是坑比较多的一部分\n#### UA伪装与代理IP\n```python\n# 由于网易没有太复杂的校验，所有我的全部请求使用的一样的请求头\n# Crawl responsibly by identifying yourself (and your website) on the user-agent\nUSER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36'\n```\n> 另外代理IP可以在中间件中的`downloader`类中的`process_exception`函数中做判断并设置代理IP\n```python\n# 拦截发生异常的请求\n    def process_exception(self, request, exception, spider):\n        # Called when a download handler or a process_request()\n        # (from other downloader middleware) raises an exception.\n\n        #  代理\n        if request.split(':')[0]=='http':\n            request.meta['proxy'] = 'http://'+ random.choice(self.proxy_http)\n        else:\n            request.meta['proxy'] = 'http://'+ random.choice(self.proxy_https)\n        # Must either:\n        # - return None: continue processing this exception\n        # - return a Response object: stops process_exception() chain\n        # - return a Request object: stops process_exception() chain\n        return request\n```\n> 最后就是一些常见配置\n```python\n# Obey robots.txt rules\nROBOTSTXT_OBEY = False\nLOG_LEVEL = 'ERROR'\n# Enable or disable downloader middlewares\n# 这里有个很坑的地方是关于中间件，下载中间件和爬虫中间件的配置是在两个不同的地方，我们只需要开启下载中间件就可以了。第一次使用的时候没有看清开启的是SPIDER_MIDDLEWARES，还特意把WangyiproSpiderrMiddleware换成WangyiproDownloaderMiddleware因此走了很多弯路，导致中间件调试了很久都不起作用，我还以为我电脑坏了。\n\nSPIDER_MIDDLEWARES = {\n#   'wangyiPro.middlewares.WangyiproSpiderrMiddleware': 543,\n   'wangyiPro.middlewares.WangyiproDownloaderMiddleware': 543,\n}\n\nDOWNLOADER_MIDDLEWARES = {\n   'wangyiPro.middlewares.WangyiproDownloaderMiddleware': 543,\n}\n# Configure item pipelines\nITEM_PIPELINES = {\n   'wangyiPro.pipelines.WangyiproPipeline': 300,\n}\n\n```\n\n### 关于调试main.py\n&emsp;&emsp;起初运行爬虫都是在控制台中用`scrapy`命令，但是这样就无法让IDE中的断点生效从而无法调试，后来参考了`https://www.cnblogs.com/weixuqin/p/9074448.html`, 在项目的根目录创建`main.py`，写入以下内容后右键`debug`开启了调试功能\n```python\n#!/usr/bin/env python\n#-*- coding:utf-8 -*-\n\nfrom scrapy.cmdline import execute\nimport os\nimport sys\n\n#添加当前项目的绝对地址\nsys.path.append(os.path.dirname(os.path.abspath(__file__)))\n#执行 scrapy 内置的函数方法execute，  使用 crawl 爬取并调试，最后一个参数news 是我的爬虫文件名\nexecute(['scrapy', 'crawl', 'news'])\n```\n\n### 最终结果\n![预览](https://s2.loli.net/2022/01/29/c2eTmrxBCO3KYqV.png)","slug":"scrapy爬取网易新闻","published":1,"updated":"2023-11-01T09:50:42.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clofkwp1j000aqxgifqqk7lj0","content":"<h2 id=\"scrapy爬取网易新闻\"><a href=\"#scrapy爬取网易新闻\" class=\"headerlink\" title=\"scrapy爬取网易新闻\"></a>scrapy爬取网易新闻</h2><blockquote>\n<p>使用scrapy爬取网易新闻的<strong>国内</strong>、<strong>国际</strong>、<strong>航空</strong>三个板块的新闻数据存储在csv中</p>\n</blockquote>\n<h3 id=\"初始化操作\"><a href=\"#初始化操作\" class=\"headerlink\" title=\"初始化操作\"></a>初始化操作</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scrapy startproject wangyiPro # 新建项目</span><br><span class=\"line\">cd wangyiPro</span><br><span class=\"line\">scrapy genspider news # 创建爬虫</span><br></pre></td></tr></table></figure>\n<h3 id=\"编写爬虫-news-py\"><a href=\"#编写爬虫-news-py\" class=\"headerlink\" title=\"编写爬虫(news.py)\"></a>编写爬虫(news.py)</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> scrapy</span><br><span class=\"line\"><span class=\"keyword\">from</span> selenium.webdriver <span class=\"keyword\">import</span> Chrome, ChromeOptions</span><br><span class=\"line\"><span class=\"keyword\">from</span> wangyiPro.items <span class=\"keyword\">import</span> WangyiproItem</span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">NewsSpider</span>(<span class=\"params\">scrapy.Spider</span>):</span></span><br><span class=\"line\">    name = <span class=\"string\">&#x27;news&#x27;</span></span><br><span class=\"line\">    <span class=\"comment\"># allowed_domains = [&#x27;www.xxx.com&#x27;]</span></span><br><span class=\"line\">    start_urls = [<span class=\"string\">&#x27;https://news.163.com/&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">        爬虫初始化阶段创建selenium无头浏览器实例用于获取动态加载的数据</span></span><br><span class=\"line\"><span class=\"string\">    &#x27;&#x27;&#x27;</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self, **kwargs</span>):</span></span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__(**kwargs)</span><br><span class=\"line\">        options = ChromeOptions()</span><br><span class=\"line\">        options.add_experimental_option(<span class=\"string\">&quot;excludeSwitches&quot;</span>,[<span class=\"string\">&#x27;enable-automation&#x27;</span>])</span><br><span class=\"line\">        <span class=\"comment\"># options.add_argument(&#x27;--headless&#x27;)  这两个是无头浏览器的选项</span></span><br><span class=\"line\">        <span class=\"comment\"># options.add_argument(&#x27;--disable-gpu&#x27;)</span></span><br><span class=\"line\">        self.bro = Chrome(executable_path=<span class=\"string\">&#x27;D:\\\\Project\\\\python\\\\scrapy-test\\\\5.动态加载数据处理\\\\chromedriver.exe&#x27;</span>,</span><br><span class=\"line\">                          chrome_options=options)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析五大板块对应详情页的url</span></span><br><span class=\"line\">    section_urls = []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># parse用于解析网易新闻的首页导航栏的对应板块url</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse</span>(<span class=\"params\">self, response</span>):</span></span><br><span class=\"line\">        li_list = response.xpath(<span class=\"string\">&#x27;//*[@id=&quot;index2016_wrap&quot;]/div[3]/div[2]/div[2]/div[2]/div/ul/li&#x27;</span>)</span><br><span class=\"line\">        <span class=\"comment\"># with open(&#x27;page.html&#x27;, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;) as fp:</span></span><br><span class=\"line\">        <span class=\"comment\">#     fp.write(response.text)</span></span><br><span class=\"line\">        index_list = [<span class=\"number\">3</span>, <span class=\"number\">6</span>]</span><br><span class=\"line\">        <span class=\"comment\"># index_list = [2]</span></span><br><span class=\"line\">        <span class=\"comment\"># 板块url</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> index <span class=\"keyword\">in</span> index_list:</span><br><span class=\"line\">            name = li_list[index].xpath(<span class=\"string\">&#x27;./a/text()&#x27;</span>).extract_first()</span><br><span class=\"line\">            url = li_list[index].xpath(<span class=\"string\">&#x27;./a/@href&#x27;</span>).extract_first()</span><br><span class=\"line\">            item = &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;url&quot;</span>: url,</span><br><span class=\"line\">                <span class=\"string\">&quot;name&quot;</span>: name</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            self.section_urls.append(item)</span><br><span class=\"line\">        <span class=\"comment\"># 依次对每个板块对应的页面进行请求</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> self.section_urls:</span><br><span class=\"line\">            <span class=\"comment\"># print(url)</span></span><br><span class=\"line\">            <span class=\"keyword\">yield</span> scrapy.Request(url=item[<span class=\"string\">&#x27;url&#x27;</span>], callback=self.parse_section,</span><br><span class=\"line\">                                 meta=&#123;<span class=\"string\">&quot;url&quot;</span>: item[<span class=\"string\">&#x27;url&#x27;</span>], <span class=\"string\">&quot;category&quot;</span>: item[<span class=\"string\">&#x27;name&#x27;</span>]&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析新闻标题和详情页url</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse_section</span>(<span class=\"params\">self, response</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;./page.html&#x27;</span>, <span class=\"string\">&#x27;w&#x27;</span>, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>) <span class=\"keyword\">as</span> fp:</span><br><span class=\"line\">            fp.write(response.text) <span class=\"comment\"># 用于储存页面便于调试</span></span><br><span class=\"line\">        div_list = response.xpath(<span class=\"string\">&#x27;//div[@class=&quot;ndi_main&quot;]/div&#x27;</span>)</span><br><span class=\"line\">        category = response.meta[<span class=\"string\">&#x27;category&#x27;</span>]</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(div_list[<span class=\"number\">0</span>])</span><br><span class=\"line\">        <span class=\"keyword\">for</span> div <span class=\"keyword\">in</span> div_list:</span><br><span class=\"line\">            title = div.xpath(<span class=\"string\">&#x27;./div//h3/a/text()&#x27;</span>).extract_first()</span><br><span class=\"line\">            detail_url = div.xpath(<span class=\"string\">&#x27;./div//h3/a//@href&#x27;</span>).extract_first()</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(title, detail_url)</span><br><span class=\"line\">            item = WangyiproItem()</span><br><span class=\"line\">            item[<span class=\"string\">&#x27;title&#x27;</span>] = title</span><br><span class=\"line\">            item[<span class=\"string\">&#x27;category&#x27;</span>] = category</span><br><span class=\"line\">            <span class=\"keyword\">yield</span> scrapy.Request(url=detail_url, callback=self.parse_detail, meta=&#123;<span class=\"string\">&quot;item&quot;</span>: item&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析新闻数据</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse_detail</span>(<span class=\"params\">self, response</span>):</span></span><br><span class=\"line\">        <span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">            这一部分是对新闻的内容、发布时间、来源做解析</span></span><br><span class=\"line\"><span class=\"string\">            内容获取后进行数据清晰，去掉空行、制表符等多余内容</span></span><br><span class=\"line\"><span class=\"string\">        &#x27;&#x27;&#x27;</span></span><br><span class=\"line\">        content = response.xpath(<span class=\"string\">&#x27;//*[@id=&quot;content&quot;]/div[2]&#x27;</span>).extract()</span><br><span class=\"line\">        content = <span class=\"string\">&#x27;&#x27;</span>.join(content)</span><br><span class=\"line\">        content = re.sub(<span class=\"string\">&#x27;\\n&#x27;</span>, <span class=\"string\">&#x27;&#x27;</span>, content)</span><br><span class=\"line\">        content = re.sub(<span class=\"string\">&#x27;\\s&#x27;</span>, <span class=\"string\">&#x27;&#x27;</span>, content)</span><br><span class=\"line\">        content = re.sub(<span class=\"string\">&#x27; &#x27;</span>, <span class=\"string\">&#x27;&#x27;</span>, content)</span><br><span class=\"line\">        item = response.meta[<span class=\"string\">&#x27;item&#x27;</span>]</span><br><span class=\"line\">        item[<span class=\"string\">&#x27;content&#x27;</span>] = content</span><br><span class=\"line\">        <span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">            发布时间的原始格式是&quot;\\n         2022-01-22 12:02:20 来源:&quot;,使用函数对时间部分进行提取</span></span><br><span class=\"line\"><span class=\"string\">        &#x27;&#x27;&#x27;</span></span><br><span class=\"line\">        timeline = response.xpath(<span class=\"string\">&#x27;//div[@class=&quot;post_info&quot;]/text()&#x27;</span>).extract_first()</span><br><span class=\"line\">        timeline = timeline.split(<span class=\"string\">&#x27;来源&#x27;</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">        timeline = re.findall(pattern=<span class=\"string\">r&#x27;20?.* ?.*:[0-9]&#123;2&#125;&#x27;</span>, string=timeline)[<span class=\"number\">0</span>]</span><br><span class=\"line\">        item[<span class=\"string\">&#x27;timeline&#x27;</span>] = timeline</span><br><span class=\"line\">        item[<span class=\"string\">&#x27;origin&#x27;</span>] = response.xpath(<span class=\"string\">&#x27;//*[@id=&quot;container&quot;]/div[1]/div[2]/a/text()&#x27;</span>).extract_first()</span><br><span class=\"line\">        <span class=\"comment\"># print(item)</span></span><br><span class=\"line\">        <span class=\"keyword\">yield</span> item</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">closed</span>(<span class=\"params\">spider, reason</span>):</span></span><br><span class=\"line\">        spider.bro.quit()</span><br><span class=\"line\">        <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"items-py\"><a href=\"#items-py\" class=\"headerlink\" title=\"items.py\"></a>items.py</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> scrapy</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WangyiproItem</span>(<span class=\"params\">scrapy.Item</span>):</span></span><br><span class=\"line\">    <span class=\"comment\"># 标题、内容、来源、发布时间、分类</span></span><br><span class=\"line\">    title = scrapy.Field()</span><br><span class=\"line\">    content = scrapy.Field()</span><br><span class=\"line\">    origin = scrapy.Field()</span><br><span class=\"line\">    timeline = scrapy.Field()</span><br><span class=\"line\">    category = scrapy.Field()</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"中间件middleware-py\"><a href=\"#中间件middleware-py\" class=\"headerlink\" title=\"中间件middleware.py\"></a>中间件middleware.py</h3><blockquote>\n<p>中间件部分主要用于处理新闻板块的新闻列表部分是动态加载出来的，所以在这里使用<code>selenium</code>将获取到的动态加载数据替换原先下载器获取的数据，然后发送给引擎处理</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Define here the models for your spider middleware</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> scrapy <span class=\"keyword\">import</span> signals</span><br><span class=\"line\"><span class=\"keyword\">from</span> scrapy.http <span class=\"keyword\">import</span> HtmlResponse</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># useful for handling different item types with a single interface</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> itemadapter <span class=\"keyword\">import</span> is_item, ItemAdapter</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WangyiproDownloaderMiddleware</span>(<span class=\"params\"><span class=\"built_in\">object</span></span>):</span></span><br><span class=\"line\">    <span class=\"comment\"># Not all methods need to be defined. If a method is not defined,</span></span><br><span class=\"line\">    <span class=\"comment\"># scrapy acts as if the downloader middleware does not modify the</span></span><br><span class=\"line\">    <span class=\"comment\"># passed objects.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_request</span>(<span class=\"params\">self, request, spider</span>):</span></span><br><span class=\"line\">        <span class=\"comment\"># Called for each request that goes through the downloader</span></span><br><span class=\"line\">        <span class=\"comment\"># middleware.</span></span><br><span class=\"line\">        <span class=\"comment\"># print(&#x27;request middleware&#x27;)</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Must either:</span></span><br><span class=\"line\">        <span class=\"comment\"># - return None: continue processing this request</span></span><br><span class=\"line\">        <span class=\"comment\"># - or return a Response object</span></span><br><span class=\"line\">        <span class=\"comment\"># - or return a Request object</span></span><br><span class=\"line\">        <span class=\"comment\"># - or raise IgnoreRequest: process_exception() methods of</span></span><br><span class=\"line\">        <span class=\"comment\">#   installed downloader middleware will be called</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#  拦截板块详情页响应对象，修改为符合需求的对象</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_response</span>(<span class=\"params\">self, request, response, spider</span>):</span></span><br><span class=\"line\">        <span class=\"comment\">#  获取在爬虫中定义的浏览器对象</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;开始拦截...&#x27;</span>)</span><br><span class=\"line\">        bro = spider.bro</span><br><span class=\"line\">        urls = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> url <span class=\"keyword\">in</span> spider.section_urls:</span><br><span class=\"line\">            urls.append(url[<span class=\"string\">&#x27;url&#x27;</span>])</span><br><span class=\"line\">        <span class=\"comment\"># Called with the response returned from the downloader.</span></span><br><span class=\"line\">        <span class=\"comment\">#  筛选对应的响应对象</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> request.url <span class=\"keyword\">in</span> urls:</span><br><span class=\"line\">            <span class=\"comment\"># response 板块详情页响应对象</span></span><br><span class=\"line\">            <span class=\"comment\"># 实例化新的响应对象，包含动态加载的数据</span></span><br><span class=\"line\">            <span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">                如何获取动态加载的响应数据？</span></span><br><span class=\"line\"><span class=\"string\">                selenium</span></span><br><span class=\"line\"><span class=\"string\">            &#x27;&#x27;&#x27;</span></span><br><span class=\"line\">            bro.get(url=request.url)</span><br><span class=\"line\">            bro.implicitly_wait(<span class=\"number\">30</span>)  <span class=\"comment\"># 隐形等待最长30s</span></span><br><span class=\"line\">            <span class=\"comment\"># time.sleep(4)</span></span><br><span class=\"line\">            page_text = bro.page_source <span class=\"comment\"># 获取动态加载的新闻数据</span></span><br><span class=\"line\">            new_res = HtmlResponse(url=request.url, body=page_text, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>, request=request)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> new_res</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Middleware no filter:&#x27;</span>, request.url)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> response</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_exception</span>(<span class=\"params\">self, request, exception, spider</span>):</span></span><br><span class=\"line\">        <span class=\"comment\"># Called when a download handler or a process_request()</span></span><br><span class=\"line\">        <span class=\"comment\"># (from other downloader middleware) raises an exception.</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Must either:</span></span><br><span class=\"line\">        <span class=\"comment\"># - return None: continue processing this exception</span></span><br><span class=\"line\">        <span class=\"comment\"># - return a Response object: stops process_exception() chain</span></span><br><span class=\"line\">        <span class=\"comment\"># - return a Request object: stops process_exception() chain</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h3 id=\"管道pipelines-py\"><a href=\"#管道pipelines-py\" class=\"headerlink\" title=\"管道pipelines.py\"></a>管道pipelines.py</h3><blockquote>\n<p>用于持久化存储</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Define your item pipelines here</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># Don&#x27;t forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class=\"line\"><span class=\"comment\"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># useful for handling different item types with a single interface</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> csv</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> itemadapter <span class=\"keyword\">import</span> ItemAdapter</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WangyiproPipeline</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self</span>):</span></span><br><span class=\"line\">        <span class=\"comment\"># 如果文件不存在就新建文件</span></span><br><span class=\"line\">        <span class=\"comment\"># 这里参考了https://www.cnblogs.com/shawone/p/10228912.html</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(<span class=\"string\">&#x27;./news.csv&#x27;</span>):</span><br><span class=\"line\">            <span class=\"comment\"># 打开文件，指定方式为写，利用第3个参数把csv写数据时产生的空行消除</span></span><br><span class=\"line\">            self.f = <span class=\"built_in\">open</span>(<span class=\"string\">&quot;news.csv&quot;</span>, <span class=\"string\">&quot;a&quot;</span>, newline=<span class=\"string\">&quot;&quot;</span>, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>)</span><br><span class=\"line\">            <span class=\"comment\"># 设置文件第一行的字段名，注意要跟spider传过来的字典key名称相同</span></span><br><span class=\"line\">            self.fieldnames = [<span class=\"string\">&quot;title&quot;</span>, <span class=\"string\">&quot;content&quot;</span>, <span class=\"string\">&quot;origin&quot;</span>, <span class=\"string\">&quot;timeline&quot;</span>, <span class=\"string\">&quot;category&quot;</span>]</span><br><span class=\"line\">            <span class=\"comment\"># 指定文件的写入方式为csv字典写入，参数1为指定具体文件，参数2为指定字段名</span></span><br><span class=\"line\">            self.writer = csv.DictWriter(self.f, fieldnames=self.fieldnames)</span><br><span class=\"line\">            <span class=\"comment\"># 写入第一行字段名，因为只要写入一次，所以文件放在__init__里面</span></span><br><span class=\"line\">            self.writer.writeheader()</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            self.f = <span class=\"built_in\">open</span>(<span class=\"string\">&quot;news.csv&quot;</span>, <span class=\"string\">&quot;a&quot;</span>, newline=<span class=\"string\">&quot;&quot;</span>, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>)</span><br><span class=\"line\">            self.fieldnames = [<span class=\"string\">&quot;title&quot;</span>, <span class=\"string\">&quot;content&quot;</span>, <span class=\"string\">&quot;origin&quot;</span>, <span class=\"string\">&quot;timeline&quot;</span>, <span class=\"string\">&quot;category&quot;</span>]</span><br><span class=\"line\">            self.writer = csv.DictWriter(self.f, fieldnames=self.fieldnames)</span><br><span class=\"line\">    <span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">        重写父类方法</span></span><br><span class=\"line\"><span class=\"string\">        该仅仅在爬虫开始时调用一次</span></span><br><span class=\"line\"><span class=\"string\">    &#x27;&#x27;&#x27;</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">open_spider</span>(<span class=\"params\">self, spider</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_item</span>(<span class=\"params\">self, item, spider</span>):</span></span><br><span class=\"line\">        self.writer.writerow(item)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> item  <span class=\"comment\"># 传递给下一个执行的管道类</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">close_spider</span>(<span class=\"params\">self, spider</span>):</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;结束爬虫...&#x27;</span>)</span><br><span class=\"line\">        self.f.close()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h3 id=\"项目配置settings-py\"><a href=\"#项目配置settings-py\" class=\"headerlink\" title=\"项目配置settings.py\"></a>项目配置settings.py</h3><blockquote>\n<p>这是坑比较多的一部分</p>\n</blockquote>\n<h4 id=\"UA伪装与代理IP\"><a href=\"#UA伪装与代理IP\" class=\"headerlink\" title=\"UA伪装与代理IP\"></a>UA伪装与代理IP</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 由于网易没有太复杂的校验，所有我的全部请求使用的一样的请求头</span></span><br><span class=\"line\"><span class=\"comment\"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span></span><br><span class=\"line\">USER_AGENT = <span class=\"string\">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36&#x27;</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>另外代理IP可以在中间件中的<code>downloader</code>类中的<code>process_exception</code>函数中做判断并设置代理IP</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 拦截发生异常的请求</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_exception</span>(<span class=\"params\">self, request, exception, spider</span>):</span></span><br><span class=\"line\">        <span class=\"comment\"># Called when a download handler or a process_request()</span></span><br><span class=\"line\">        <span class=\"comment\"># (from other downloader middleware) raises an exception.</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">#  代理</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> request.split(<span class=\"string\">&#x27;:&#x27;</span>)[<span class=\"number\">0</span>]==<span class=\"string\">&#x27;http&#x27;</span>:</span><br><span class=\"line\">            request.meta[<span class=\"string\">&#x27;proxy&#x27;</span>] = <span class=\"string\">&#x27;http://&#x27;</span>+ random.choice(self.proxy_http)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            request.meta[<span class=\"string\">&#x27;proxy&#x27;</span>] = <span class=\"string\">&#x27;http://&#x27;</span>+ random.choice(self.proxy_https)</span><br><span class=\"line\">        <span class=\"comment\"># Must either:</span></span><br><span class=\"line\">        <span class=\"comment\"># - return None: continue processing this exception</span></span><br><span class=\"line\">        <span class=\"comment\"># - return a Response object: stops process_exception() chain</span></span><br><span class=\"line\">        <span class=\"comment\"># - return a Request object: stops process_exception() chain</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> request</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>最后就是一些常见配置</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Obey robots.txt rules</span></span><br><span class=\"line\">ROBOTSTXT_OBEY = <span class=\"literal\">False</span></span><br><span class=\"line\">LOG_LEVEL = <span class=\"string\">&#x27;ERROR&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># Enable or disable downloader middlewares</span></span><br><span class=\"line\"><span class=\"comment\"># 这里有个很坑的地方是关于中间件，下载中间件和爬虫中间件的配置是在两个不同的地方，我们只需要开启下载中间件就可以了。第一次使用的时候没有看清开启的是SPIDER_MIDDLEWARES，还特意把WangyiproSpiderrMiddleware换成WangyiproDownloaderMiddleware因此走了很多弯路，导致中间件调试了很久都不起作用，我还以为我电脑坏了。</span></span><br><span class=\"line\"></span><br><span class=\"line\">SPIDER_MIDDLEWARES = &#123;</span><br><span class=\"line\"><span class=\"comment\">#   &#x27;wangyiPro.middlewares.WangyiproSpiderrMiddleware&#x27;: 543,</span></span><br><span class=\"line\">   <span class=\"string\">&#x27;wangyiPro.middlewares.WangyiproDownloaderMiddleware&#x27;</span>: <span class=\"number\">543</span>,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class=\"line\">   <span class=\"string\">&#x27;wangyiPro.middlewares.WangyiproDownloaderMiddleware&#x27;</span>: <span class=\"number\">543</span>,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\"># Configure item pipelines</span></span><br><span class=\"line\">ITEM_PIPELINES = &#123;</span><br><span class=\"line\">   <span class=\"string\">&#x27;wangyiPro.pipelines.WangyiproPipeline&#x27;</span>: <span class=\"number\">300</span>,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"关于调试main-py\"><a href=\"#关于调试main-py\" class=\"headerlink\" title=\"关于调试main.py\"></a>关于调试main.py</h3><p>&emsp;&emsp;起初运行爬虫都是在控制台中用<code>scrapy</code>命令，但是这样就无法让IDE中的断点生效从而无法调试，后来参考了<code>https://www.cnblogs.com/weixuqin/p/9074448.html</code>, 在项目的根目录创建<code>main.py</code>，写入以下内容后右键<code>debug</code>开启了调试功能</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/env python</span></span><br><span class=\"line\"><span class=\"comment\">#-*- coding:utf-8 -*-</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> scrapy.cmdline <span class=\"keyword\">import</span> execute</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#添加当前项目的绝对地址</span></span><br><span class=\"line\">sys.path.append(os.path.dirname(os.path.abspath(__file__)))</span><br><span class=\"line\"><span class=\"comment\">#执行 scrapy 内置的函数方法execute，  使用 crawl 爬取并调试，最后一个参数news 是我的爬虫文件名</span></span><br><span class=\"line\">execute([<span class=\"string\">&#x27;scrapy&#x27;</span>, <span class=\"string\">&#x27;crawl&#x27;</span>, <span class=\"string\">&#x27;news&#x27;</span>])</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"最终结果\"><a href=\"#最终结果\" class=\"headerlink\" title=\"最终结果\"></a>最终结果</h3><p><img src=\"https://s2.loli.net/2022/01/29/c2eTmrxBCO3KYqV.png\" alt=\"预览\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"scrapy爬取网易新闻\"><a href=\"#scrapy爬取网易新闻\" class=\"headerlink\" title=\"scrapy爬取网易新闻\"></a>scrapy爬取网易新闻</h2><blockquote>\n<p>使用scrapy爬取网易新闻的<strong>国内</strong>、<strong>国际</strong>、<strong>航空</strong>三个板块的新闻数据存储在csv中</p>\n</blockquote>\n<h3 id=\"初始化操作\"><a href=\"#初始化操作\" class=\"headerlink\" title=\"初始化操作\"></a>初始化操作</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scrapy startproject wangyiPro # 新建项目</span><br><span class=\"line\">cd wangyiPro</span><br><span class=\"line\">scrapy genspider news # 创建爬虫</span><br></pre></td></tr></table></figure>\n<h3 id=\"编写爬虫-news-py\"><a href=\"#编写爬虫-news-py\" class=\"headerlink\" title=\"编写爬虫(news.py)\"></a>编写爬虫(news.py)</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> scrapy</span><br><span class=\"line\"><span class=\"keyword\">from</span> selenium.webdriver <span class=\"keyword\">import</span> Chrome, ChromeOptions</span><br><span class=\"line\"><span class=\"keyword\">from</span> wangyiPro.items <span class=\"keyword\">import</span> WangyiproItem</span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">NewsSpider</span>(<span class=\"params\">scrapy.Spider</span>):</span></span><br><span class=\"line\">    name = <span class=\"string\">&#x27;news&#x27;</span></span><br><span class=\"line\">    <span class=\"comment\"># allowed_domains = [&#x27;www.xxx.com&#x27;]</span></span><br><span class=\"line\">    start_urls = [<span class=\"string\">&#x27;https://news.163.com/&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">        爬虫初始化阶段创建selenium无头浏览器实例用于获取动态加载的数据</span></span><br><span class=\"line\"><span class=\"string\">    &#x27;&#x27;&#x27;</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self, **kwargs</span>):</span></span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__(**kwargs)</span><br><span class=\"line\">        options = ChromeOptions()</span><br><span class=\"line\">        options.add_experimental_option(<span class=\"string\">&quot;excludeSwitches&quot;</span>,[<span class=\"string\">&#x27;enable-automation&#x27;</span>])</span><br><span class=\"line\">        <span class=\"comment\"># options.add_argument(&#x27;--headless&#x27;)  这两个是无头浏览器的选项</span></span><br><span class=\"line\">        <span class=\"comment\"># options.add_argument(&#x27;--disable-gpu&#x27;)</span></span><br><span class=\"line\">        self.bro = Chrome(executable_path=<span class=\"string\">&#x27;D:\\\\Project\\\\python\\\\scrapy-test\\\\5.动态加载数据处理\\\\chromedriver.exe&#x27;</span>,</span><br><span class=\"line\">                          chrome_options=options)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析五大板块对应详情页的url</span></span><br><span class=\"line\">    section_urls = []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># parse用于解析网易新闻的首页导航栏的对应板块url</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse</span>(<span class=\"params\">self, response</span>):</span></span><br><span class=\"line\">        li_list = response.xpath(<span class=\"string\">&#x27;//*[@id=&quot;index2016_wrap&quot;]/div[3]/div[2]/div[2]/div[2]/div/ul/li&#x27;</span>)</span><br><span class=\"line\">        <span class=\"comment\"># with open(&#x27;page.html&#x27;, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;) as fp:</span></span><br><span class=\"line\">        <span class=\"comment\">#     fp.write(response.text)</span></span><br><span class=\"line\">        index_list = [<span class=\"number\">3</span>, <span class=\"number\">6</span>]</span><br><span class=\"line\">        <span class=\"comment\"># index_list = [2]</span></span><br><span class=\"line\">        <span class=\"comment\"># 板块url</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> index <span class=\"keyword\">in</span> index_list:</span><br><span class=\"line\">            name = li_list[index].xpath(<span class=\"string\">&#x27;./a/text()&#x27;</span>).extract_first()</span><br><span class=\"line\">            url = li_list[index].xpath(<span class=\"string\">&#x27;./a/@href&#x27;</span>).extract_first()</span><br><span class=\"line\">            item = &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;url&quot;</span>: url,</span><br><span class=\"line\">                <span class=\"string\">&quot;name&quot;</span>: name</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            self.section_urls.append(item)</span><br><span class=\"line\">        <span class=\"comment\"># 依次对每个板块对应的页面进行请求</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> self.section_urls:</span><br><span class=\"line\">            <span class=\"comment\"># print(url)</span></span><br><span class=\"line\">            <span class=\"keyword\">yield</span> scrapy.Request(url=item[<span class=\"string\">&#x27;url&#x27;</span>], callback=self.parse_section,</span><br><span class=\"line\">                                 meta=&#123;<span class=\"string\">&quot;url&quot;</span>: item[<span class=\"string\">&#x27;url&#x27;</span>], <span class=\"string\">&quot;category&quot;</span>: item[<span class=\"string\">&#x27;name&#x27;</span>]&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析新闻标题和详情页url</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse_section</span>(<span class=\"params\">self, response</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;./page.html&#x27;</span>, <span class=\"string\">&#x27;w&#x27;</span>, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>) <span class=\"keyword\">as</span> fp:</span><br><span class=\"line\">            fp.write(response.text) <span class=\"comment\"># 用于储存页面便于调试</span></span><br><span class=\"line\">        div_list = response.xpath(<span class=\"string\">&#x27;//div[@class=&quot;ndi_main&quot;]/div&#x27;</span>)</span><br><span class=\"line\">        category = response.meta[<span class=\"string\">&#x27;category&#x27;</span>]</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(div_list[<span class=\"number\">0</span>])</span><br><span class=\"line\">        <span class=\"keyword\">for</span> div <span class=\"keyword\">in</span> div_list:</span><br><span class=\"line\">            title = div.xpath(<span class=\"string\">&#x27;./div//h3/a/text()&#x27;</span>).extract_first()</span><br><span class=\"line\">            detail_url = div.xpath(<span class=\"string\">&#x27;./div//h3/a//@href&#x27;</span>).extract_first()</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(title, detail_url)</span><br><span class=\"line\">            item = WangyiproItem()</span><br><span class=\"line\">            item[<span class=\"string\">&#x27;title&#x27;</span>] = title</span><br><span class=\"line\">            item[<span class=\"string\">&#x27;category&#x27;</span>] = category</span><br><span class=\"line\">            <span class=\"keyword\">yield</span> scrapy.Request(url=detail_url, callback=self.parse_detail, meta=&#123;<span class=\"string\">&quot;item&quot;</span>: item&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析新闻数据</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse_detail</span>(<span class=\"params\">self, response</span>):</span></span><br><span class=\"line\">        <span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">            这一部分是对新闻的内容、发布时间、来源做解析</span></span><br><span class=\"line\"><span class=\"string\">            内容获取后进行数据清晰，去掉空行、制表符等多余内容</span></span><br><span class=\"line\"><span class=\"string\">        &#x27;&#x27;&#x27;</span></span><br><span class=\"line\">        content = response.xpath(<span class=\"string\">&#x27;//*[@id=&quot;content&quot;]/div[2]&#x27;</span>).extract()</span><br><span class=\"line\">        content = <span class=\"string\">&#x27;&#x27;</span>.join(content)</span><br><span class=\"line\">        content = re.sub(<span class=\"string\">&#x27;\\n&#x27;</span>, <span class=\"string\">&#x27;&#x27;</span>, content)</span><br><span class=\"line\">        content = re.sub(<span class=\"string\">&#x27;\\s&#x27;</span>, <span class=\"string\">&#x27;&#x27;</span>, content)</span><br><span class=\"line\">        content = re.sub(<span class=\"string\">&#x27; &#x27;</span>, <span class=\"string\">&#x27;&#x27;</span>, content)</span><br><span class=\"line\">        item = response.meta[<span class=\"string\">&#x27;item&#x27;</span>]</span><br><span class=\"line\">        item[<span class=\"string\">&#x27;content&#x27;</span>] = content</span><br><span class=\"line\">        <span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">            发布时间的原始格式是&quot;\\n         2022-01-22 12:02:20 来源:&quot;,使用函数对时间部分进行提取</span></span><br><span class=\"line\"><span class=\"string\">        &#x27;&#x27;&#x27;</span></span><br><span class=\"line\">        timeline = response.xpath(<span class=\"string\">&#x27;//div[@class=&quot;post_info&quot;]/text()&#x27;</span>).extract_first()</span><br><span class=\"line\">        timeline = timeline.split(<span class=\"string\">&#x27;来源&#x27;</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">        timeline = re.findall(pattern=<span class=\"string\">r&#x27;20?.* ?.*:[0-9]&#123;2&#125;&#x27;</span>, string=timeline)[<span class=\"number\">0</span>]</span><br><span class=\"line\">        item[<span class=\"string\">&#x27;timeline&#x27;</span>] = timeline</span><br><span class=\"line\">        item[<span class=\"string\">&#x27;origin&#x27;</span>] = response.xpath(<span class=\"string\">&#x27;//*[@id=&quot;container&quot;]/div[1]/div[2]/a/text()&#x27;</span>).extract_first()</span><br><span class=\"line\">        <span class=\"comment\"># print(item)</span></span><br><span class=\"line\">        <span class=\"keyword\">yield</span> item</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">closed</span>(<span class=\"params\">spider, reason</span>):</span></span><br><span class=\"line\">        spider.bro.quit()</span><br><span class=\"line\">        <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"items-py\"><a href=\"#items-py\" class=\"headerlink\" title=\"items.py\"></a>items.py</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> scrapy</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WangyiproItem</span>(<span class=\"params\">scrapy.Item</span>):</span></span><br><span class=\"line\">    <span class=\"comment\"># 标题、内容、来源、发布时间、分类</span></span><br><span class=\"line\">    title = scrapy.Field()</span><br><span class=\"line\">    content = scrapy.Field()</span><br><span class=\"line\">    origin = scrapy.Field()</span><br><span class=\"line\">    timeline = scrapy.Field()</span><br><span class=\"line\">    category = scrapy.Field()</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"中间件middleware-py\"><a href=\"#中间件middleware-py\" class=\"headerlink\" title=\"中间件middleware.py\"></a>中间件middleware.py</h3><blockquote>\n<p>中间件部分主要用于处理新闻板块的新闻列表部分是动态加载出来的，所以在这里使用<code>selenium</code>将获取到的动态加载数据替换原先下载器获取的数据，然后发送给引擎处理</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Define here the models for your spider middleware</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> scrapy <span class=\"keyword\">import</span> signals</span><br><span class=\"line\"><span class=\"keyword\">from</span> scrapy.http <span class=\"keyword\">import</span> HtmlResponse</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># useful for handling different item types with a single interface</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> itemadapter <span class=\"keyword\">import</span> is_item, ItemAdapter</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WangyiproDownloaderMiddleware</span>(<span class=\"params\"><span class=\"built_in\">object</span></span>):</span></span><br><span class=\"line\">    <span class=\"comment\"># Not all methods need to be defined. If a method is not defined,</span></span><br><span class=\"line\">    <span class=\"comment\"># scrapy acts as if the downloader middleware does not modify the</span></span><br><span class=\"line\">    <span class=\"comment\"># passed objects.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_request</span>(<span class=\"params\">self, request, spider</span>):</span></span><br><span class=\"line\">        <span class=\"comment\"># Called for each request that goes through the downloader</span></span><br><span class=\"line\">        <span class=\"comment\"># middleware.</span></span><br><span class=\"line\">        <span class=\"comment\"># print(&#x27;request middleware&#x27;)</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Must either:</span></span><br><span class=\"line\">        <span class=\"comment\"># - return None: continue processing this request</span></span><br><span class=\"line\">        <span class=\"comment\"># - or return a Response object</span></span><br><span class=\"line\">        <span class=\"comment\"># - or return a Request object</span></span><br><span class=\"line\">        <span class=\"comment\"># - or raise IgnoreRequest: process_exception() methods of</span></span><br><span class=\"line\">        <span class=\"comment\">#   installed downloader middleware will be called</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#  拦截板块详情页响应对象，修改为符合需求的对象</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_response</span>(<span class=\"params\">self, request, response, spider</span>):</span></span><br><span class=\"line\">        <span class=\"comment\">#  获取在爬虫中定义的浏览器对象</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;开始拦截...&#x27;</span>)</span><br><span class=\"line\">        bro = spider.bro</span><br><span class=\"line\">        urls = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> url <span class=\"keyword\">in</span> spider.section_urls:</span><br><span class=\"line\">            urls.append(url[<span class=\"string\">&#x27;url&#x27;</span>])</span><br><span class=\"line\">        <span class=\"comment\"># Called with the response returned from the downloader.</span></span><br><span class=\"line\">        <span class=\"comment\">#  筛选对应的响应对象</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> request.url <span class=\"keyword\">in</span> urls:</span><br><span class=\"line\">            <span class=\"comment\"># response 板块详情页响应对象</span></span><br><span class=\"line\">            <span class=\"comment\"># 实例化新的响应对象，包含动态加载的数据</span></span><br><span class=\"line\">            <span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">                如何获取动态加载的响应数据？</span></span><br><span class=\"line\"><span class=\"string\">                selenium</span></span><br><span class=\"line\"><span class=\"string\">            &#x27;&#x27;&#x27;</span></span><br><span class=\"line\">            bro.get(url=request.url)</span><br><span class=\"line\">            bro.implicitly_wait(<span class=\"number\">30</span>)  <span class=\"comment\"># 隐形等待最长30s</span></span><br><span class=\"line\">            <span class=\"comment\"># time.sleep(4)</span></span><br><span class=\"line\">            page_text = bro.page_source <span class=\"comment\"># 获取动态加载的新闻数据</span></span><br><span class=\"line\">            new_res = HtmlResponse(url=request.url, body=page_text, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>, request=request)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> new_res</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Middleware no filter:&#x27;</span>, request.url)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> response</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_exception</span>(<span class=\"params\">self, request, exception, spider</span>):</span></span><br><span class=\"line\">        <span class=\"comment\"># Called when a download handler or a process_request()</span></span><br><span class=\"line\">        <span class=\"comment\"># (from other downloader middleware) raises an exception.</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Must either:</span></span><br><span class=\"line\">        <span class=\"comment\"># - return None: continue processing this exception</span></span><br><span class=\"line\">        <span class=\"comment\"># - return a Response object: stops process_exception() chain</span></span><br><span class=\"line\">        <span class=\"comment\"># - return a Request object: stops process_exception() chain</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h3 id=\"管道pipelines-py\"><a href=\"#管道pipelines-py\" class=\"headerlink\" title=\"管道pipelines.py\"></a>管道pipelines.py</h3><blockquote>\n<p>用于持久化存储</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Define your item pipelines here</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># Don&#x27;t forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class=\"line\"><span class=\"comment\"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># useful for handling different item types with a single interface</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> csv</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> itemadapter <span class=\"keyword\">import</span> ItemAdapter</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WangyiproPipeline</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self</span>):</span></span><br><span class=\"line\">        <span class=\"comment\"># 如果文件不存在就新建文件</span></span><br><span class=\"line\">        <span class=\"comment\"># 这里参考了https://www.cnblogs.com/shawone/p/10228912.html</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(<span class=\"string\">&#x27;./news.csv&#x27;</span>):</span><br><span class=\"line\">            <span class=\"comment\"># 打开文件，指定方式为写，利用第3个参数把csv写数据时产生的空行消除</span></span><br><span class=\"line\">            self.f = <span class=\"built_in\">open</span>(<span class=\"string\">&quot;news.csv&quot;</span>, <span class=\"string\">&quot;a&quot;</span>, newline=<span class=\"string\">&quot;&quot;</span>, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>)</span><br><span class=\"line\">            <span class=\"comment\"># 设置文件第一行的字段名，注意要跟spider传过来的字典key名称相同</span></span><br><span class=\"line\">            self.fieldnames = [<span class=\"string\">&quot;title&quot;</span>, <span class=\"string\">&quot;content&quot;</span>, <span class=\"string\">&quot;origin&quot;</span>, <span class=\"string\">&quot;timeline&quot;</span>, <span class=\"string\">&quot;category&quot;</span>]</span><br><span class=\"line\">            <span class=\"comment\"># 指定文件的写入方式为csv字典写入，参数1为指定具体文件，参数2为指定字段名</span></span><br><span class=\"line\">            self.writer = csv.DictWriter(self.f, fieldnames=self.fieldnames)</span><br><span class=\"line\">            <span class=\"comment\"># 写入第一行字段名，因为只要写入一次，所以文件放在__init__里面</span></span><br><span class=\"line\">            self.writer.writeheader()</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            self.f = <span class=\"built_in\">open</span>(<span class=\"string\">&quot;news.csv&quot;</span>, <span class=\"string\">&quot;a&quot;</span>, newline=<span class=\"string\">&quot;&quot;</span>, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>)</span><br><span class=\"line\">            self.fieldnames = [<span class=\"string\">&quot;title&quot;</span>, <span class=\"string\">&quot;content&quot;</span>, <span class=\"string\">&quot;origin&quot;</span>, <span class=\"string\">&quot;timeline&quot;</span>, <span class=\"string\">&quot;category&quot;</span>]</span><br><span class=\"line\">            self.writer = csv.DictWriter(self.f, fieldnames=self.fieldnames)</span><br><span class=\"line\">    <span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">        重写父类方法</span></span><br><span class=\"line\"><span class=\"string\">        该仅仅在爬虫开始时调用一次</span></span><br><span class=\"line\"><span class=\"string\">    &#x27;&#x27;&#x27;</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">open_spider</span>(<span class=\"params\">self, spider</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_item</span>(<span class=\"params\">self, item, spider</span>):</span></span><br><span class=\"line\">        self.writer.writerow(item)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> item  <span class=\"comment\"># 传递给下一个执行的管道类</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">close_spider</span>(<span class=\"params\">self, spider</span>):</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;结束爬虫...&#x27;</span>)</span><br><span class=\"line\">        self.f.close()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h3 id=\"项目配置settings-py\"><a href=\"#项目配置settings-py\" class=\"headerlink\" title=\"项目配置settings.py\"></a>项目配置settings.py</h3><blockquote>\n<p>这是坑比较多的一部分</p>\n</blockquote>\n<h4 id=\"UA伪装与代理IP\"><a href=\"#UA伪装与代理IP\" class=\"headerlink\" title=\"UA伪装与代理IP\"></a>UA伪装与代理IP</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 由于网易没有太复杂的校验，所有我的全部请求使用的一样的请求头</span></span><br><span class=\"line\"><span class=\"comment\"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span></span><br><span class=\"line\">USER_AGENT = <span class=\"string\">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36&#x27;</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>另外代理IP可以在中间件中的<code>downloader</code>类中的<code>process_exception</code>函数中做判断并设置代理IP</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 拦截发生异常的请求</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_exception</span>(<span class=\"params\">self, request, exception, spider</span>):</span></span><br><span class=\"line\">        <span class=\"comment\"># Called when a download handler or a process_request()</span></span><br><span class=\"line\">        <span class=\"comment\"># (from other downloader middleware) raises an exception.</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">#  代理</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> request.split(<span class=\"string\">&#x27;:&#x27;</span>)[<span class=\"number\">0</span>]==<span class=\"string\">&#x27;http&#x27;</span>:</span><br><span class=\"line\">            request.meta[<span class=\"string\">&#x27;proxy&#x27;</span>] = <span class=\"string\">&#x27;http://&#x27;</span>+ random.choice(self.proxy_http)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            request.meta[<span class=\"string\">&#x27;proxy&#x27;</span>] = <span class=\"string\">&#x27;http://&#x27;</span>+ random.choice(self.proxy_https)</span><br><span class=\"line\">        <span class=\"comment\"># Must either:</span></span><br><span class=\"line\">        <span class=\"comment\"># - return None: continue processing this exception</span></span><br><span class=\"line\">        <span class=\"comment\"># - return a Response object: stops process_exception() chain</span></span><br><span class=\"line\">        <span class=\"comment\"># - return a Request object: stops process_exception() chain</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> request</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>最后就是一些常见配置</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Obey robots.txt rules</span></span><br><span class=\"line\">ROBOTSTXT_OBEY = <span class=\"literal\">False</span></span><br><span class=\"line\">LOG_LEVEL = <span class=\"string\">&#x27;ERROR&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># Enable or disable downloader middlewares</span></span><br><span class=\"line\"><span class=\"comment\"># 这里有个很坑的地方是关于中间件，下载中间件和爬虫中间件的配置是在两个不同的地方，我们只需要开启下载中间件就可以了。第一次使用的时候没有看清开启的是SPIDER_MIDDLEWARES，还特意把WangyiproSpiderrMiddleware换成WangyiproDownloaderMiddleware因此走了很多弯路，导致中间件调试了很久都不起作用，我还以为我电脑坏了。</span></span><br><span class=\"line\"></span><br><span class=\"line\">SPIDER_MIDDLEWARES = &#123;</span><br><span class=\"line\"><span class=\"comment\">#   &#x27;wangyiPro.middlewares.WangyiproSpiderrMiddleware&#x27;: 543,</span></span><br><span class=\"line\">   <span class=\"string\">&#x27;wangyiPro.middlewares.WangyiproDownloaderMiddleware&#x27;</span>: <span class=\"number\">543</span>,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class=\"line\">   <span class=\"string\">&#x27;wangyiPro.middlewares.WangyiproDownloaderMiddleware&#x27;</span>: <span class=\"number\">543</span>,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\"># Configure item pipelines</span></span><br><span class=\"line\">ITEM_PIPELINES = &#123;</span><br><span class=\"line\">   <span class=\"string\">&#x27;wangyiPro.pipelines.WangyiproPipeline&#x27;</span>: <span class=\"number\">300</span>,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"关于调试main-py\"><a href=\"#关于调试main-py\" class=\"headerlink\" title=\"关于调试main.py\"></a>关于调试main.py</h3><p>&emsp;&emsp;起初运行爬虫都是在控制台中用<code>scrapy</code>命令，但是这样就无法让IDE中的断点生效从而无法调试，后来参考了<code>https://www.cnblogs.com/weixuqin/p/9074448.html</code>, 在项目的根目录创建<code>main.py</code>，写入以下内容后右键<code>debug</code>开启了调试功能</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/env python</span></span><br><span class=\"line\"><span class=\"comment\">#-*- coding:utf-8 -*-</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> scrapy.cmdline <span class=\"keyword\">import</span> execute</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#添加当前项目的绝对地址</span></span><br><span class=\"line\">sys.path.append(os.path.dirname(os.path.abspath(__file__)))</span><br><span class=\"line\"><span class=\"comment\">#执行 scrapy 内置的函数方法execute，  使用 crawl 爬取并调试，最后一个参数news 是我的爬虫文件名</span></span><br><span class=\"line\">execute([<span class=\"string\">&#x27;scrapy&#x27;</span>, <span class=\"string\">&#x27;crawl&#x27;</span>, <span class=\"string\">&#x27;news&#x27;</span>])</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"最终结果\"><a href=\"#最终结果\" class=\"headerlink\" title=\"最终结果\"></a>最终结果</h3><p><img src=\"https://s2.loli.net/2022/01/29/c2eTmrxBCO3KYqV.png\" alt=\"预览\"></p>\n"},{"title":"selenium模拟12306登录","date":"2022-01-27T16:12:49.000Z","toc":"topics","_content":"\n```python \nimport time\n\nfrom selenium import webdriver\nfrom lxml import etree\nfrom selenium.webdriver import ActionChains, ChromeOptions as Options\nfrom selenium.webdriver.common.by import By\njs = 'return window.navigator.webdriver'\n'''\n    实现无可视化界面\n'''\noptions = Options()\n# options.add_argument('--headless')\n# options.add_argument('--disable-gpu')\n'''\n    实现规避检测\n'''\noption_avoid = Options()\noption_avoid.add_experimental_option('excludeSwitches', ['enable-automation'])\noptions.add_experimental_option('useAutomationExtension', False)\nbro = webdriver.Chrome(chrome_options=options, options=option_avoid)\n# 12306会通过获取window.navigator.webdriver属性判断是否为模拟浏览器\n# 在加载阶段调用cdp(Chrome Devtool Protocol)抹掉该属性\nbro.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n  \"source\": \"\"\"\n    Object.defineProperty(navigator, 'webdriver', {\n      get: () => undefined\n    })\n  \"\"\"\n})\nbro.get('https://kyfw.12306.cn/otn/resources/login.html')\nusername_input = bro.find_element(By.ID, 'J-userName')\npassword_input = bro.find_element(By.ID, 'J-password')\nusername_input.send_keys('用户名xxxxx')\npassword_input.send_keys('密码xxxxx')\nlogin_btn = bro.find_element(By.ID, 'J-login')\nlogin_btn.click()\nslide_modal = bro.find_element(By.ID, 'modal')\nbro.execute_script('document.title =\"测试\"')\nbro.execute_script('document.body.appendChild(document.createElement(\\'div\\'))')\ntime.sleep(2)\nprint(bro.execute_script(js))\n\nwith open('./login.html', 'w', encoding='utf-8') as fp:\n    fp.write(bro.page_source)\nwhile True:\n    try:\n        action = webdriver.ActionChains(bro)  # 利用行为链，持续按住并拖拽\n        span = bro.find_element(By.ID, 'nc_1_n1z')  # 获取滑块\n        action.drag_and_drop_by_offset(span, 330, 0).perform()  # 按住并拖动 >300px即可，选用330绰绰有余\n        # action.click_and_hold(span).perform()\n        # action.move_by_offset(xoffset=300,yoffset=0).perform() 另一张拖动\n        action.release()  # 释放\n        print(bro.execute_script(js))\n        time.sleep(2)\n        a = bro.find_element(By.ID, 'nc_1_refresh1')  # 查找刷新按钮，如果没有说明登录成功，执行except跳出循环\n        a.click()  # 如果刚刚滑动失败，则点击刷新，重新滑动\n        time.sleep(4)\n    except Exception as e:\n        print(e)\n        break\n\n```","source":"_posts/selenium模拟12306登录.md","raw":"---\ntitle: selenium模拟12306登录\ndate: 2022-01-27 16:12:49\ntags: [selenium,python]\ntoc: topics\n---\n\n```python \nimport time\n\nfrom selenium import webdriver\nfrom lxml import etree\nfrom selenium.webdriver import ActionChains, ChromeOptions as Options\nfrom selenium.webdriver.common.by import By\njs = 'return window.navigator.webdriver'\n'''\n    实现无可视化界面\n'''\noptions = Options()\n# options.add_argument('--headless')\n# options.add_argument('--disable-gpu')\n'''\n    实现规避检测\n'''\noption_avoid = Options()\noption_avoid.add_experimental_option('excludeSwitches', ['enable-automation'])\noptions.add_experimental_option('useAutomationExtension', False)\nbro = webdriver.Chrome(chrome_options=options, options=option_avoid)\n# 12306会通过获取window.navigator.webdriver属性判断是否为模拟浏览器\n# 在加载阶段调用cdp(Chrome Devtool Protocol)抹掉该属性\nbro.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n  \"source\": \"\"\"\n    Object.defineProperty(navigator, 'webdriver', {\n      get: () => undefined\n    })\n  \"\"\"\n})\nbro.get('https://kyfw.12306.cn/otn/resources/login.html')\nusername_input = bro.find_element(By.ID, 'J-userName')\npassword_input = bro.find_element(By.ID, 'J-password')\nusername_input.send_keys('用户名xxxxx')\npassword_input.send_keys('密码xxxxx')\nlogin_btn = bro.find_element(By.ID, 'J-login')\nlogin_btn.click()\nslide_modal = bro.find_element(By.ID, 'modal')\nbro.execute_script('document.title =\"测试\"')\nbro.execute_script('document.body.appendChild(document.createElement(\\'div\\'))')\ntime.sleep(2)\nprint(bro.execute_script(js))\n\nwith open('./login.html', 'w', encoding='utf-8') as fp:\n    fp.write(bro.page_source)\nwhile True:\n    try:\n        action = webdriver.ActionChains(bro)  # 利用行为链，持续按住并拖拽\n        span = bro.find_element(By.ID, 'nc_1_n1z')  # 获取滑块\n        action.drag_and_drop_by_offset(span, 330, 0).perform()  # 按住并拖动 >300px即可，选用330绰绰有余\n        # action.click_and_hold(span).perform()\n        # action.move_by_offset(xoffset=300,yoffset=0).perform() 另一张拖动\n        action.release()  # 释放\n        print(bro.execute_script(js))\n        time.sleep(2)\n        a = bro.find_element(By.ID, 'nc_1_refresh1')  # 查找刷新按钮，如果没有说明登录成功，执行except跳出循环\n        a.click()  # 如果刚刚滑动失败，则点击刷新，重新滑动\n        time.sleep(4)\n    except Exception as e:\n        print(e)\n        break\n\n```","slug":"selenium模拟12306登录","published":1,"updated":"2023-11-01T09:50:42.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clofkwp1l000dqxgi0lim7l71","content":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> selenium <span class=\"keyword\">import</span> webdriver</span><br><span class=\"line\"><span class=\"keyword\">from</span> lxml <span class=\"keyword\">import</span> etree</span><br><span class=\"line\"><span class=\"keyword\">from</span> selenium.webdriver <span class=\"keyword\">import</span> ActionChains, ChromeOptions <span class=\"keyword\">as</span> Options</span><br><span class=\"line\"><span class=\"keyword\">from</span> selenium.webdriver.common.by <span class=\"keyword\">import</span> By</span><br><span class=\"line\">js = <span class=\"string\">&#x27;return window.navigator.webdriver&#x27;</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">    实现无可视化界面</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\">options = Options()</span><br><span class=\"line\"><span class=\"comment\"># options.add_argument(&#x27;--headless&#x27;)</span></span><br><span class=\"line\"><span class=\"comment\"># options.add_argument(&#x27;--disable-gpu&#x27;)</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">    实现规避检测</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\">option_avoid = Options()</span><br><span class=\"line\">option_avoid.add_experimental_option(<span class=\"string\">&#x27;excludeSwitches&#x27;</span>, [<span class=\"string\">&#x27;enable-automation&#x27;</span>])</span><br><span class=\"line\">options.add_experimental_option(<span class=\"string\">&#x27;useAutomationExtension&#x27;</span>, <span class=\"literal\">False</span>)</span><br><span class=\"line\">bro = webdriver.Chrome(chrome_options=options, options=option_avoid)</span><br><span class=\"line\"><span class=\"comment\"># 12306会通过获取window.navigator.webdriver属性判断是否为模拟浏览器</span></span><br><span class=\"line\"><span class=\"comment\"># 在加载阶段调用cdp(Chrome Devtool Protocol)抹掉该属性</span></span><br><span class=\"line\">bro.execute_cdp_cmd(<span class=\"string\">&quot;Page.addScriptToEvaluateOnNewDocument&quot;</span>, &#123;</span><br><span class=\"line\">  <span class=\"string\">&quot;source&quot;</span>: <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    Object.defineProperty(navigator, &#x27;webdriver&#x27;, &#123;</span></span><br><span class=\"line\"><span class=\"string\">      get: () =&gt; undefined</span></span><br><span class=\"line\"><span class=\"string\">    &#125;)</span></span><br><span class=\"line\"><span class=\"string\">  &quot;&quot;&quot;</span></span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">bro.get(<span class=\"string\">&#x27;https://kyfw.12306.cn/otn/resources/login.html&#x27;</span>)</span><br><span class=\"line\">username_input = bro.find_element(By.ID, <span class=\"string\">&#x27;J-userName&#x27;</span>)</span><br><span class=\"line\">password_input = bro.find_element(By.ID, <span class=\"string\">&#x27;J-password&#x27;</span>)</span><br><span class=\"line\">username_input.send_keys(<span class=\"string\">&#x27;用户名xxxxx&#x27;</span>)</span><br><span class=\"line\">password_input.send_keys(<span class=\"string\">&#x27;密码xxxxx&#x27;</span>)</span><br><span class=\"line\">login_btn = bro.find_element(By.ID, <span class=\"string\">&#x27;J-login&#x27;</span>)</span><br><span class=\"line\">login_btn.click()</span><br><span class=\"line\">slide_modal = bro.find_element(By.ID, <span class=\"string\">&#x27;modal&#x27;</span>)</span><br><span class=\"line\">bro.execute_script(<span class=\"string\">&#x27;document.title =&quot;测试&quot;&#x27;</span>)</span><br><span class=\"line\">bro.execute_script(<span class=\"string\">&#x27;document.body.appendChild(document.createElement(\\&#x27;div\\&#x27;))&#x27;</span>)</span><br><span class=\"line\">time.sleep(<span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(bro.execute_script(js))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;./login.html&#x27;</span>, <span class=\"string\">&#x27;w&#x27;</span>, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>) <span class=\"keyword\">as</span> fp:</span><br><span class=\"line\">    fp.write(bro.page_source)</span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        action = webdriver.ActionChains(bro)  <span class=\"comment\"># 利用行为链，持续按住并拖拽</span></span><br><span class=\"line\">        span = bro.find_element(By.ID, <span class=\"string\">&#x27;nc_1_n1z&#x27;</span>)  <span class=\"comment\"># 获取滑块</span></span><br><span class=\"line\">        action.drag_and_drop_by_offset(span, <span class=\"number\">330</span>, <span class=\"number\">0</span>).perform()  <span class=\"comment\"># 按住并拖动 &gt;300px即可，选用330绰绰有余</span></span><br><span class=\"line\">        <span class=\"comment\"># action.click_and_hold(span).perform()</span></span><br><span class=\"line\">        <span class=\"comment\"># action.move_by_offset(xoffset=300,yoffset=0).perform() 另一张拖动</span></span><br><span class=\"line\">        action.release()  <span class=\"comment\"># 释放</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(bro.execute_script(js))</span><br><span class=\"line\">        time.sleep(<span class=\"number\">2</span>)</span><br><span class=\"line\">        a = bro.find_element(By.ID, <span class=\"string\">&#x27;nc_1_refresh1&#x27;</span>)  <span class=\"comment\"># 查找刷新按钮，如果没有说明登录成功，执行except跳出循环</span></span><br><span class=\"line\">        a.click()  <span class=\"comment\"># 如果刚刚滑动失败，则点击刷新，重新滑动</span></span><br><span class=\"line\">        time.sleep(<span class=\"number\">4</span>)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(e)</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> selenium <span class=\"keyword\">import</span> webdriver</span><br><span class=\"line\"><span class=\"keyword\">from</span> lxml <span class=\"keyword\">import</span> etree</span><br><span class=\"line\"><span class=\"keyword\">from</span> selenium.webdriver <span class=\"keyword\">import</span> ActionChains, ChromeOptions <span class=\"keyword\">as</span> Options</span><br><span class=\"line\"><span class=\"keyword\">from</span> selenium.webdriver.common.by <span class=\"keyword\">import</span> By</span><br><span class=\"line\">js = <span class=\"string\">&#x27;return window.navigator.webdriver&#x27;</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">    实现无可视化界面</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\">options = Options()</span><br><span class=\"line\"><span class=\"comment\"># options.add_argument(&#x27;--headless&#x27;)</span></span><br><span class=\"line\"><span class=\"comment\"># options.add_argument(&#x27;--disable-gpu&#x27;)</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">    实现规避检测</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\">option_avoid = Options()</span><br><span class=\"line\">option_avoid.add_experimental_option(<span class=\"string\">&#x27;excludeSwitches&#x27;</span>, [<span class=\"string\">&#x27;enable-automation&#x27;</span>])</span><br><span class=\"line\">options.add_experimental_option(<span class=\"string\">&#x27;useAutomationExtension&#x27;</span>, <span class=\"literal\">False</span>)</span><br><span class=\"line\">bro = webdriver.Chrome(chrome_options=options, options=option_avoid)</span><br><span class=\"line\"><span class=\"comment\"># 12306会通过获取window.navigator.webdriver属性判断是否为模拟浏览器</span></span><br><span class=\"line\"><span class=\"comment\"># 在加载阶段调用cdp(Chrome Devtool Protocol)抹掉该属性</span></span><br><span class=\"line\">bro.execute_cdp_cmd(<span class=\"string\">&quot;Page.addScriptToEvaluateOnNewDocument&quot;</span>, &#123;</span><br><span class=\"line\">  <span class=\"string\">&quot;source&quot;</span>: <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    Object.defineProperty(navigator, &#x27;webdriver&#x27;, &#123;</span></span><br><span class=\"line\"><span class=\"string\">      get: () =&gt; undefined</span></span><br><span class=\"line\"><span class=\"string\">    &#125;)</span></span><br><span class=\"line\"><span class=\"string\">  &quot;&quot;&quot;</span></span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">bro.get(<span class=\"string\">&#x27;https://kyfw.12306.cn/otn/resources/login.html&#x27;</span>)</span><br><span class=\"line\">username_input = bro.find_element(By.ID, <span class=\"string\">&#x27;J-userName&#x27;</span>)</span><br><span class=\"line\">password_input = bro.find_element(By.ID, <span class=\"string\">&#x27;J-password&#x27;</span>)</span><br><span class=\"line\">username_input.send_keys(<span class=\"string\">&#x27;用户名xxxxx&#x27;</span>)</span><br><span class=\"line\">password_input.send_keys(<span class=\"string\">&#x27;密码xxxxx&#x27;</span>)</span><br><span class=\"line\">login_btn = bro.find_element(By.ID, <span class=\"string\">&#x27;J-login&#x27;</span>)</span><br><span class=\"line\">login_btn.click()</span><br><span class=\"line\">slide_modal = bro.find_element(By.ID, <span class=\"string\">&#x27;modal&#x27;</span>)</span><br><span class=\"line\">bro.execute_script(<span class=\"string\">&#x27;document.title =&quot;测试&quot;&#x27;</span>)</span><br><span class=\"line\">bro.execute_script(<span class=\"string\">&#x27;document.body.appendChild(document.createElement(\\&#x27;div\\&#x27;))&#x27;</span>)</span><br><span class=\"line\">time.sleep(<span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(bro.execute_script(js))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;./login.html&#x27;</span>, <span class=\"string\">&#x27;w&#x27;</span>, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>) <span class=\"keyword\">as</span> fp:</span><br><span class=\"line\">    fp.write(bro.page_source)</span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\">        action = webdriver.ActionChains(bro)  <span class=\"comment\"># 利用行为链，持续按住并拖拽</span></span><br><span class=\"line\">        span = bro.find_element(By.ID, <span class=\"string\">&#x27;nc_1_n1z&#x27;</span>)  <span class=\"comment\"># 获取滑块</span></span><br><span class=\"line\">        action.drag_and_drop_by_offset(span, <span class=\"number\">330</span>, <span class=\"number\">0</span>).perform()  <span class=\"comment\"># 按住并拖动 &gt;300px即可，选用330绰绰有余</span></span><br><span class=\"line\">        <span class=\"comment\"># action.click_and_hold(span).perform()</span></span><br><span class=\"line\">        <span class=\"comment\"># action.move_by_offset(xoffset=300,yoffset=0).perform() 另一张拖动</span></span><br><span class=\"line\">        action.release()  <span class=\"comment\"># 释放</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(bro.execute_script(js))</span><br><span class=\"line\">        time.sleep(<span class=\"number\">2</span>)</span><br><span class=\"line\">        a = bro.find_element(By.ID, <span class=\"string\">&#x27;nc_1_refresh1&#x27;</span>)  <span class=\"comment\"># 查找刷新按钮，如果没有说明登录成功，执行except跳出循环</span></span><br><span class=\"line\">        a.click()  <span class=\"comment\"># 如果刚刚滑动失败，则点击刷新，重新滑动</span></span><br><span class=\"line\">        time.sleep(<span class=\"number\">4</span>)</span><br><span class=\"line\">    <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(e)</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>"},{"title":"vue-双向数据绑定","date":"2022-05-04T17:49:19.000Z","updated":"2022-05-04T17:49:19.000Z","toc":true,"cover":"/images/12138.jpg","_content":"> 参考B站up蛋老师是的视频学习了一下vue的双向数据绑定以及模板解析的操作，实在是太巧妙了！[视频地址](https://www.bilibili.com/video/BV1934y1a7MN?share_source=copy_web)\n\n&emsp;&emsp;直接放代码，前端部分，参考vue的写法，这里的data是一个普通的对象，vue官网的data是一个函数，官方的写法应该是为了数据绑定做出的优化，但是没有了解过相关原理，所有暂时还不太理解二者的区别。\n``` HTML\n<body>\n    <div id=\"app\">\n        <label>用户名：\n            <input v-model=\"name\" type=\"text\" name=\"username\" id=\"username\">\n        </label><br>\n        <label>年&emsp;龄：\n            <input v-model=\"info.age\" type=\"text\" name=\"age\" id=\"age\">\n        </label><br>\n        <label>身&emsp;高：\n            <input v-model=\"info.height\" type=\"text\" name=\"height\" id=\"height\">\n        </label>\n        <p> 用户名： {{ name }} </p>\n        <p>年龄： {{info.age}}</p>\n        <p>身高： {{info.height}}cm</p>\n    </div>\n</body>\n<script src=\"./vue.js\"></script>\n<script>\n    const vm = new Vue({\n        el: \"#app\",\n        data: {\n            name: \"啦啦啦种太阳\",\n            info: {\n                age: 18,\n                height: 170\n            }\n        }\n    })\n</script>\n```\n**HTML部分参考官方的写法，本次的demo主要实现文本渲染、输入框的v-model监听，以及数据绑定**\n\nJS部分\n``` JavaScript\n// vue.js\nclass Vue {\n    constructor({el, data}) {\n        this.$el = el\n        this.$data = data\n        Observer(this.$data)\n        Compile(el, this)\n    }\n}\n\n// 为数据绑定监听者\nfunction Observer(data_instance) {\n    if(!data_instance || typeof data_instance !==  'object') return;\n    const dependency = new Dependency();\n    Object.keys(data_instance).forEach(key => {\n        let value = data_instance[key]\n        Observer(value)\n        Object.defineProperty(data_instance, key, {\n            enumerable: true,\n            configurable: true,\n            get() {\n                console.log(`访问了属性：${key} -> 值 ${value}`)\n                Dependency.temp && dependency.addSub(Dependency.temp)\n                if(Dependency.temp) console.log(Dependency.temp)\n                return value;\n            },\n            set(newValue) {\n                console.log(`属性${key}的值\"${value}\"修改为 -> \"${newValue}\"`)\n                value = newValue\n                Observer(newValue)\n                dependency.notify()\n            }\n        })\n    })\n}\n\n// 模板解析\nfunction Compile(element, vm) {\n    vm.$el = document.querySelector(element);\n    const fragment = document.createDocumentFragment();\n    let child;\n    while(child = vm.$el.firstChild) {\n        fragment.append(child)\n    }\n    fragment_compile(fragment)\n    function fragment_compile(node) {\n        const pattern = /\\{\\{\\s*(\\S+)\\s*\\}\\}/\n        if(node.nodeType === 3) {\n            const xxx = node.nodeValue\n            const result = pattern.exec( node.nodeValue)\n            if(result) {\n                const arr = result[1].split(\".\")\n                const value = arr.reduce((total, current) => total[current], vm.$data)\n                node.nodeValue = xxx.replace(pattern, value)\n                new Watcher(vm, result[1], newValue => {\n                    node.nodeValue = xxx.replace(pattern, newValue)\n                })\n            }\n            return \n        } \n        // 实现input框的v-model属性绑定\n        if(node.nodeType === 1 && node.nodeName === \"INPUT\") {\n            const attr = Array.from(node.attributes)\n            attr.forEach(i => {\n                if(i.nodeName === 'v-model') {\n                    const value = i.nodeValue.split(\".\").reduce(\n                        (total, current) => total[current], vm.$data\n                    )\n                    node.value = value\n                    new Watcher(vm, i.nodeValue, newValue => {\n                        node.value = newValue\n                    })\n                    node.addEventListener('input', e => {\n                        let name = i.nodeValue.split(\".\");\n                        const final = name.slice(0, name.length - 1).reduce(\n                            (total, current) => total[current], vm.$data\n                        )\n                        final[name[name.length - 1]] = e.target.value\n                    })\n                }\n            })\n        }\n        node.childNodes.forEach(child => fragment_compile(child))\n    }\n    vm.$el.append(fragment)\n}\n\n/**发布订阅模式 */\nclass Dependency {\n    temp = null\n    constructor() {\n        this.subscriber = []\n    }\n    addSub(sub) {\n        this.subscriber.push(sub)\n    }\n    notify() {\n        this.subscriber.forEach(sub => sub.update())\n    }\n}\n\n// 观察者\nclass Watcher {\n    constructor(vm, key, callback) {\n        this.vm = vm\n        this.key = key\n        this.callback = callback\n        // 临时属性 触发getter\n        Dependency.temp = this\n        console.log(`用属性${key}创建了订阅者`)\n        key.split(\".\").reduce((total, current) => total[current], vm.$data) // 触发属性的getter\n        Dependency.temp = null\n    }\n    update() {\n        const value = this.key.split(\".\").reduce((total, current) => total[current], this.vm.$data)\n        this.callback(value)\n    }\n}\n```\n\n&emsp;&emsp;视频看了两遍，全程跟着敲，第一遍还不太理解Watcher类是如何绑定对于数据的监听的，而且不太理解getter和setter的触发的巧妙之处。\n&emsp;&emsp;Watcher其实就是在虚拟dom添加至页面的时候，将每一个在页面中要被渲染的值进行监听。监听的本质就是将data中的一个值于Watcher的一个实例对象所提供的callback函数绑定在一起，每当setter函数被触发，及data中的值发生了改变，则调用callback函数。Dependency类中存储了所有的Watcher实例，此处demo中对于通知Watcher进行更新的方法是，一旦setter被触发就通知Dependency.subscriber中的所有watcher进行更新，Watcher实例自带的update函方法可以找到自己正在监听的数据，并从根实例vm中获取最新的数据值并调用自身的callback函数。callback是在解析数据的同时对Watcher实例化的时候传入的，所以callback可以直接访问到数据要解析的目标dom，当Watcher接收到了新的值，就可以直接对dom进行重新渲染，也就实现了所谓的“双向绑定”。","source":"_posts/vue-双向数据绑定.md","raw":"---\ntitle: vue-双向数据绑定\ndate: 2022-05-04 17:49:19\nupdated: 2022-05-04 17:49:19\ncategories: 前端\ntags: [前端, vue]\ntoc: true\ncover: /images/12138.jpg\n---\n> 参考B站up蛋老师是的视频学习了一下vue的双向数据绑定以及模板解析的操作，实在是太巧妙了！[视频地址](https://www.bilibili.com/video/BV1934y1a7MN?share_source=copy_web)\n\n&emsp;&emsp;直接放代码，前端部分，参考vue的写法，这里的data是一个普通的对象，vue官网的data是一个函数，官方的写法应该是为了数据绑定做出的优化，但是没有了解过相关原理，所有暂时还不太理解二者的区别。\n``` HTML\n<body>\n    <div id=\"app\">\n        <label>用户名：\n            <input v-model=\"name\" type=\"text\" name=\"username\" id=\"username\">\n        </label><br>\n        <label>年&emsp;龄：\n            <input v-model=\"info.age\" type=\"text\" name=\"age\" id=\"age\">\n        </label><br>\n        <label>身&emsp;高：\n            <input v-model=\"info.height\" type=\"text\" name=\"height\" id=\"height\">\n        </label>\n        <p> 用户名： {{ name }} </p>\n        <p>年龄： {{info.age}}</p>\n        <p>身高： {{info.height}}cm</p>\n    </div>\n</body>\n<script src=\"./vue.js\"></script>\n<script>\n    const vm = new Vue({\n        el: \"#app\",\n        data: {\n            name: \"啦啦啦种太阳\",\n            info: {\n                age: 18,\n                height: 170\n            }\n        }\n    })\n</script>\n```\n**HTML部分参考官方的写法，本次的demo主要实现文本渲染、输入框的v-model监听，以及数据绑定**\n\nJS部分\n``` JavaScript\n// vue.js\nclass Vue {\n    constructor({el, data}) {\n        this.$el = el\n        this.$data = data\n        Observer(this.$data)\n        Compile(el, this)\n    }\n}\n\n// 为数据绑定监听者\nfunction Observer(data_instance) {\n    if(!data_instance || typeof data_instance !==  'object') return;\n    const dependency = new Dependency();\n    Object.keys(data_instance).forEach(key => {\n        let value = data_instance[key]\n        Observer(value)\n        Object.defineProperty(data_instance, key, {\n            enumerable: true,\n            configurable: true,\n            get() {\n                console.log(`访问了属性：${key} -> 值 ${value}`)\n                Dependency.temp && dependency.addSub(Dependency.temp)\n                if(Dependency.temp) console.log(Dependency.temp)\n                return value;\n            },\n            set(newValue) {\n                console.log(`属性${key}的值\"${value}\"修改为 -> \"${newValue}\"`)\n                value = newValue\n                Observer(newValue)\n                dependency.notify()\n            }\n        })\n    })\n}\n\n// 模板解析\nfunction Compile(element, vm) {\n    vm.$el = document.querySelector(element);\n    const fragment = document.createDocumentFragment();\n    let child;\n    while(child = vm.$el.firstChild) {\n        fragment.append(child)\n    }\n    fragment_compile(fragment)\n    function fragment_compile(node) {\n        const pattern = /\\{\\{\\s*(\\S+)\\s*\\}\\}/\n        if(node.nodeType === 3) {\n            const xxx = node.nodeValue\n            const result = pattern.exec( node.nodeValue)\n            if(result) {\n                const arr = result[1].split(\".\")\n                const value = arr.reduce((total, current) => total[current], vm.$data)\n                node.nodeValue = xxx.replace(pattern, value)\n                new Watcher(vm, result[1], newValue => {\n                    node.nodeValue = xxx.replace(pattern, newValue)\n                })\n            }\n            return \n        } \n        // 实现input框的v-model属性绑定\n        if(node.nodeType === 1 && node.nodeName === \"INPUT\") {\n            const attr = Array.from(node.attributes)\n            attr.forEach(i => {\n                if(i.nodeName === 'v-model') {\n                    const value = i.nodeValue.split(\".\").reduce(\n                        (total, current) => total[current], vm.$data\n                    )\n                    node.value = value\n                    new Watcher(vm, i.nodeValue, newValue => {\n                        node.value = newValue\n                    })\n                    node.addEventListener('input', e => {\n                        let name = i.nodeValue.split(\".\");\n                        const final = name.slice(0, name.length - 1).reduce(\n                            (total, current) => total[current], vm.$data\n                        )\n                        final[name[name.length - 1]] = e.target.value\n                    })\n                }\n            })\n        }\n        node.childNodes.forEach(child => fragment_compile(child))\n    }\n    vm.$el.append(fragment)\n}\n\n/**发布订阅模式 */\nclass Dependency {\n    temp = null\n    constructor() {\n        this.subscriber = []\n    }\n    addSub(sub) {\n        this.subscriber.push(sub)\n    }\n    notify() {\n        this.subscriber.forEach(sub => sub.update())\n    }\n}\n\n// 观察者\nclass Watcher {\n    constructor(vm, key, callback) {\n        this.vm = vm\n        this.key = key\n        this.callback = callback\n        // 临时属性 触发getter\n        Dependency.temp = this\n        console.log(`用属性${key}创建了订阅者`)\n        key.split(\".\").reduce((total, current) => total[current], vm.$data) // 触发属性的getter\n        Dependency.temp = null\n    }\n    update() {\n        const value = this.key.split(\".\").reduce((total, current) => total[current], this.vm.$data)\n        this.callback(value)\n    }\n}\n```\n\n&emsp;&emsp;视频看了两遍，全程跟着敲，第一遍还不太理解Watcher类是如何绑定对于数据的监听的，而且不太理解getter和setter的触发的巧妙之处。\n&emsp;&emsp;Watcher其实就是在虚拟dom添加至页面的时候，将每一个在页面中要被渲染的值进行监听。监听的本质就是将data中的一个值于Watcher的一个实例对象所提供的callback函数绑定在一起，每当setter函数被触发，及data中的值发生了改变，则调用callback函数。Dependency类中存储了所有的Watcher实例，此处demo中对于通知Watcher进行更新的方法是，一旦setter被触发就通知Dependency.subscriber中的所有watcher进行更新，Watcher实例自带的update函方法可以找到自己正在监听的数据，并从根实例vm中获取最新的数据值并调用自身的callback函数。callback是在解析数据的同时对Watcher实例化的时候传入的，所以callback可以直接访问到数据要解析的目标dom，当Watcher接收到了新的值，就可以直接对dom进行重新渲染，也就实现了所谓的“双向绑定”。","slug":"vue-双向数据绑定","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"clofkwp1l000eqxgi188cejdh","content":"<blockquote>\n<p>参考B站up蛋老师是的视频学习了一下vue的双向数据绑定以及模板解析的操作，实在是太巧妙了！<a href=\"https://www.bilibili.com/video/BV1934y1a7MN?share_source=copy_web\">视频地址</a></p>\n</blockquote>\n<p>&emsp;&emsp;直接放代码，前端部分，参考vue的写法，这里的data是一个普通的对象，vue官网的data是一个函数，官方的写法应该是为了数据绑定做出的优化，但是没有了解过相关原理，所有暂时还不太理解二者的区别。</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">&quot;app&quot;</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">label</span>&gt;</span>用户名：</span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">v-model</span>=<span class=\"string\">&quot;name&quot;</span> <span class=\"attr\">type</span>=<span class=\"string\">&quot;text&quot;</span> <span class=\"attr\">name</span>=<span class=\"string\">&quot;username&quot;</span> <span class=\"attr\">id</span>=<span class=\"string\">&quot;username&quot;</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">label</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">label</span>&gt;</span>年<span class=\"symbol\">&amp;emsp;</span>龄：</span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">v-model</span>=<span class=\"string\">&quot;info.age&quot;</span> <span class=\"attr\">type</span>=<span class=\"string\">&quot;text&quot;</span> <span class=\"attr\">name</span>=<span class=\"string\">&quot;age&quot;</span> <span class=\"attr\">id</span>=<span class=\"string\">&quot;age&quot;</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">label</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">label</span>&gt;</span>身<span class=\"symbol\">&amp;emsp;</span>高：</span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">v-model</span>=<span class=\"string\">&quot;info.height&quot;</span> <span class=\"attr\">type</span>=<span class=\"string\">&quot;text&quot;</span> <span class=\"attr\">name</span>=<span class=\"string\">&quot;height&quot;</span> <span class=\"attr\">id</span>=<span class=\"string\">&quot;height&quot;</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">label</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span> 用户名： &#123;&#123; name &#125;&#125; <span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>年龄： &#123;&#123;info.age&#125;&#125;<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>身高： &#123;&#123;info.height&#125;&#125;cm<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">src</span>=<span class=\"string\">&quot;./vue.js&quot;</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span>&gt;</span><span class=\"javascript\"></span></span><br><span class=\"line\"><span class=\"javascript\">    <span class=\"keyword\">const</span> vm = <span class=\"keyword\">new</span> Vue(&#123;</span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"attr\">el</span>: <span class=\"string\">&quot;#app&quot;</span>,</span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"attr\">data</span>: &#123;</span></span><br><span class=\"line\"><span class=\"javascript\">            <span class=\"attr\">name</span>: <span class=\"string\">&quot;啦啦啦种太阳&quot;</span>,</span></span><br><span class=\"line\"><span class=\"javascript\">            <span class=\"attr\">info</span>: &#123;</span></span><br><span class=\"line\"><span class=\"javascript\">                <span class=\"attr\">age</span>: <span class=\"number\">18</span>,</span></span><br><span class=\"line\"><span class=\"javascript\">                <span class=\"attr\">height</span>: <span class=\"number\">170</span></span></span><br><span class=\"line\"><span class=\"javascript\">            &#125;</span></span><br><span class=\"line\"><span class=\"javascript\">        &#125;</span></span><br><span class=\"line\"><span class=\"javascript\">    &#125;)</span></span><br><span class=\"line\"><span class=\"javascript\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p><strong>HTML部分参考官方的写法，本次的demo主要实现文本渲染、输入框的v-model监听，以及数据绑定</strong></p>\n<p>JS部分</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// vue.js</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Vue</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"title\">constructor</span>(<span class=\"params\">&#123;el, data&#125;</span>)</span> &#123;</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.$el = el</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.$data = data</span><br><span class=\"line\">        Observer(<span class=\"built_in\">this</span>.$data)</span><br><span class=\"line\">        Compile(el, <span class=\"built_in\">this</span>)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 为数据绑定监听者</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">Observer</span>(<span class=\"params\">data_instance</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!data_instance || <span class=\"keyword\">typeof</span> data_instance !==  <span class=\"string\">&#x27;object&#x27;</span>) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> dependency = <span class=\"keyword\">new</span> Dependency();</span><br><span class=\"line\">    <span class=\"built_in\">Object</span>.keys(data_instance).forEach(<span class=\"function\"><span class=\"params\">key</span> =&gt;</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">let</span> value = data_instance[key]</span><br><span class=\"line\">        Observer(value)</span><br><span class=\"line\">        <span class=\"built_in\">Object</span>.defineProperty(data_instance, key, &#123;</span><br><span class=\"line\">            <span class=\"attr\">enumerable</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">            <span class=\"attr\">configurable</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">            <span class=\"function\"><span class=\"title\">get</span>(<span class=\"params\"></span>)</span> &#123;</span><br><span class=\"line\">                <span class=\"built_in\">console</span>.log(<span class=\"string\">`访问了属性：<span class=\"subst\">$&#123;key&#125;</span> -&gt; 值 <span class=\"subst\">$&#123;value&#125;</span>`</span>)</span><br><span class=\"line\">                Dependency.temp &amp;&amp; dependency.addSub(Dependency.temp)</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(Dependency.temp) <span class=\"built_in\">console</span>.log(Dependency.temp)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> value;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            <span class=\"function\"><span class=\"title\">set</span>(<span class=\"params\">newValue</span>)</span> &#123;</span><br><span class=\"line\">                <span class=\"built_in\">console</span>.log(<span class=\"string\">`属性<span class=\"subst\">$&#123;key&#125;</span>的值&quot;<span class=\"subst\">$&#123;value&#125;</span>&quot;修改为 -&gt; &quot;<span class=\"subst\">$&#123;newValue&#125;</span>&quot;`</span>)</span><br><span class=\"line\">                value = newValue</span><br><span class=\"line\">                Observer(newValue)</span><br><span class=\"line\">                dependency.notify()</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;)</span><br><span class=\"line\">    &#125;)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 模板解析</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">Compile</span>(<span class=\"params\">element, vm</span>) </span>&#123;</span><br><span class=\"line\">    vm.$el = <span class=\"built_in\">document</span>.querySelector(element);</span><br><span class=\"line\">    <span class=\"keyword\">const</span> fragment = <span class=\"built_in\">document</span>.createDocumentFragment();</span><br><span class=\"line\">    <span class=\"keyword\">let</span> child;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(child = vm.$el.firstChild) &#123;</span><br><span class=\"line\">        fragment.append(child)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    fragment_compile(fragment)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">fragment_compile</span>(<span class=\"params\">node</span>) </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">const</span> pattern = <span class=\"regexp\">/\\&#123;\\&#123;\\s*(\\S+)\\s*\\&#125;\\&#125;/</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(node.nodeType === <span class=\"number\">3</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">const</span> xxx = node.nodeValue</span><br><span class=\"line\">            <span class=\"keyword\">const</span> result = pattern.exec( node.nodeValue)</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(result) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">const</span> arr = result[<span class=\"number\">1</span>].split(<span class=\"string\">&quot;.&quot;</span>)</span><br><span class=\"line\">                <span class=\"keyword\">const</span> value = arr.reduce(<span class=\"function\">(<span class=\"params\">total, current</span>) =&gt;</span> total[current], vm.$data)</span><br><span class=\"line\">                node.nodeValue = xxx.replace(pattern, value)</span><br><span class=\"line\">                <span class=\"keyword\">new</span> Watcher(vm, result[<span class=\"number\">1</span>], <span class=\"function\"><span class=\"params\">newValue</span> =&gt;</span> &#123;</span><br><span class=\"line\">                    node.nodeValue = xxx.replace(pattern, newValue)</span><br><span class=\"line\">                &#125;)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> </span><br><span class=\"line\">        &#125; </span><br><span class=\"line\">        <span class=\"comment\">// 实现input框的v-model属性绑定</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(node.nodeType === <span class=\"number\">1</span> &amp;&amp; node.nodeName === <span class=\"string\">&quot;INPUT&quot;</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">const</span> attr = <span class=\"built_in\">Array</span>.from(node.attributes)</span><br><span class=\"line\">            attr.forEach(<span class=\"function\"><span class=\"params\">i</span> =&gt;</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(i.nodeName === <span class=\"string\">&#x27;v-model&#x27;</span>) &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">const</span> value = i.nodeValue.split(<span class=\"string\">&quot;.&quot;</span>).reduce(</span><br><span class=\"line\">                        <span class=\"function\">(<span class=\"params\">total, current</span>) =&gt;</span> total[current], vm.$data</span><br><span class=\"line\">                    )</span><br><span class=\"line\">                    node.value = value</span><br><span class=\"line\">                    <span class=\"keyword\">new</span> Watcher(vm, i.nodeValue, <span class=\"function\"><span class=\"params\">newValue</span> =&gt;</span> &#123;</span><br><span class=\"line\">                        node.value = newValue</span><br><span class=\"line\">                    &#125;)</span><br><span class=\"line\">                    node.addEventListener(<span class=\"string\">&#x27;input&#x27;</span>, <span class=\"function\"><span class=\"params\">e</span> =&gt;</span> &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">let</span> name = i.nodeValue.split(<span class=\"string\">&quot;.&quot;</span>);</span><br><span class=\"line\">                        <span class=\"keyword\">const</span> final = name.slice(<span class=\"number\">0</span>, name.length - <span class=\"number\">1</span>).reduce(</span><br><span class=\"line\">                            <span class=\"function\">(<span class=\"params\">total, current</span>) =&gt;</span> total[current], vm.$data</span><br><span class=\"line\">                        )</span><br><span class=\"line\">                        final[name[name.length - <span class=\"number\">1</span>]] = e.target.value</span><br><span class=\"line\">                    &#125;)</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        node.childNodes.forEach(<span class=\"function\"><span class=\"params\">child</span> =&gt;</span> fragment_compile(child))</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    vm.$el.append(fragment)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**发布订阅模式 */</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Dependency</span> </span>&#123;</span><br><span class=\"line\">    temp = <span class=\"literal\">null</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"title\">constructor</span>(<span class=\"params\"></span>)</span> &#123;</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.subscriber = []</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"title\">addSub</span>(<span class=\"params\">sub</span>)</span> &#123;</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.subscriber.push(sub)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"title\">notify</span>(<span class=\"params\"></span>)</span> &#123;</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.subscriber.forEach(<span class=\"function\"><span class=\"params\">sub</span> =&gt;</span> sub.update())</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 观察者</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Watcher</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"title\">constructor</span>(<span class=\"params\">vm, key, callback</span>)</span> &#123;</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.vm = vm</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.key = key</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.callback = callback</span><br><span class=\"line\">        <span class=\"comment\">// 临时属性 触发getter</span></span><br><span class=\"line\">        Dependency.temp = <span class=\"built_in\">this</span></span><br><span class=\"line\">        <span class=\"built_in\">console</span>.log(<span class=\"string\">`用属性<span class=\"subst\">$&#123;key&#125;</span>创建了订阅者`</span>)</span><br><span class=\"line\">        key.split(<span class=\"string\">&quot;.&quot;</span>).reduce(<span class=\"function\">(<span class=\"params\">total, current</span>) =&gt;</span> total[current], vm.$data) <span class=\"comment\">// 触发属性的getter</span></span><br><span class=\"line\">        Dependency.temp = <span class=\"literal\">null</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"title\">update</span>(<span class=\"params\"></span>)</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">const</span> value = <span class=\"built_in\">this</span>.key.split(<span class=\"string\">&quot;.&quot;</span>).reduce(<span class=\"function\">(<span class=\"params\">total, current</span>) =&gt;</span> total[current], <span class=\"built_in\">this</span>.vm.$data)</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.callback(value)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>&emsp;&emsp;视频看了两遍，全程跟着敲，第一遍还不太理解Watcher类是如何绑定对于数据的监听的，而且不太理解getter和setter的触发的巧妙之处。<br>&emsp;&emsp;Watcher其实就是在虚拟dom添加至页面的时候，将每一个在页面中要被渲染的值进行监听。监听的本质就是将data中的一个值于Watcher的一个实例对象所提供的callback函数绑定在一起，每当setter函数被触发，及data中的值发生了改变，则调用callback函数。Dependency类中存储了所有的Watcher实例，此处demo中对于通知Watcher进行更新的方法是，一旦setter被触发就通知Dependency.subscriber中的所有watcher进行更新，Watcher实例自带的update函方法可以找到自己正在监听的数据，并从根实例vm中获取最新的数据值并调用自身的callback函数。callback是在解析数据的同时对Watcher实例化的时候传入的，所以callback可以直接访问到数据要解析的目标dom，当Watcher接收到了新的值，就可以直接对dom进行重新渲染，也就实现了所谓的“双向绑定”。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>参考B站up蛋老师是的视频学习了一下vue的双向数据绑定以及模板解析的操作，实在是太巧妙了！<a href=\"https://www.bilibili.com/video/BV1934y1a7MN?share_source=copy_web\">视频地址</a></p>\n</blockquote>\n<p>&emsp;&emsp;直接放代码，前端部分，参考vue的写法，这里的data是一个普通的对象，vue官网的data是一个函数，官方的写法应该是为了数据绑定做出的优化，但是没有了解过相关原理，所有暂时还不太理解二者的区别。</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">id</span>=<span class=\"string\">&quot;app&quot;</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">label</span>&gt;</span>用户名：</span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">v-model</span>=<span class=\"string\">&quot;name&quot;</span> <span class=\"attr\">type</span>=<span class=\"string\">&quot;text&quot;</span> <span class=\"attr\">name</span>=<span class=\"string\">&quot;username&quot;</span> <span class=\"attr\">id</span>=<span class=\"string\">&quot;username&quot;</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">label</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">label</span>&gt;</span>年<span class=\"symbol\">&amp;emsp;</span>龄：</span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">v-model</span>=<span class=\"string\">&quot;info.age&quot;</span> <span class=\"attr\">type</span>=<span class=\"string\">&quot;text&quot;</span> <span class=\"attr\">name</span>=<span class=\"string\">&quot;age&quot;</span> <span class=\"attr\">id</span>=<span class=\"string\">&quot;age&quot;</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">label</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">br</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">label</span>&gt;</span>身<span class=\"symbol\">&amp;emsp;</span>高：</span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">v-model</span>=<span class=\"string\">&quot;info.height&quot;</span> <span class=\"attr\">type</span>=<span class=\"string\">&quot;text&quot;</span> <span class=\"attr\">name</span>=<span class=\"string\">&quot;height&quot;</span> <span class=\"attr\">id</span>=<span class=\"string\">&quot;height&quot;</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">label</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span> 用户名： &#123;&#123; name &#125;&#125; <span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>年龄： &#123;&#123;info.age&#125;&#125;<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">p</span>&gt;</span>身高： &#123;&#123;info.height&#125;&#125;cm<span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">src</span>=<span class=\"string\">&quot;./vue.js&quot;</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span>&gt;</span><span class=\"javascript\"></span></span><br><span class=\"line\"><span class=\"javascript\">    <span class=\"keyword\">const</span> vm = <span class=\"keyword\">new</span> Vue(&#123;</span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"attr\">el</span>: <span class=\"string\">&quot;#app&quot;</span>,</span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"attr\">data</span>: &#123;</span></span><br><span class=\"line\"><span class=\"javascript\">            <span class=\"attr\">name</span>: <span class=\"string\">&quot;啦啦啦种太阳&quot;</span>,</span></span><br><span class=\"line\"><span class=\"javascript\">            <span class=\"attr\">info</span>: &#123;</span></span><br><span class=\"line\"><span class=\"javascript\">                <span class=\"attr\">age</span>: <span class=\"number\">18</span>,</span></span><br><span class=\"line\"><span class=\"javascript\">                <span class=\"attr\">height</span>: <span class=\"number\">170</span></span></span><br><span class=\"line\"><span class=\"javascript\">            &#125;</span></span><br><span class=\"line\"><span class=\"javascript\">        &#125;</span></span><br><span class=\"line\"><span class=\"javascript\">    &#125;)</span></span><br><span class=\"line\"><span class=\"javascript\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p><strong>HTML部分参考官方的写法，本次的demo主要实现文本渲染、输入框的v-model监听，以及数据绑定</strong></p>\n<p>JS部分</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// vue.js</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Vue</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"title\">constructor</span>(<span class=\"params\">&#123;el, data&#125;</span>)</span> &#123;</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.$el = el</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.$data = data</span><br><span class=\"line\">        Observer(<span class=\"built_in\">this</span>.$data)</span><br><span class=\"line\">        Compile(el, <span class=\"built_in\">this</span>)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 为数据绑定监听者</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">Observer</span>(<span class=\"params\">data_instance</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!data_instance || <span class=\"keyword\">typeof</span> data_instance !==  <span class=\"string\">&#x27;object&#x27;</span>) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> dependency = <span class=\"keyword\">new</span> Dependency();</span><br><span class=\"line\">    <span class=\"built_in\">Object</span>.keys(data_instance).forEach(<span class=\"function\"><span class=\"params\">key</span> =&gt;</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">let</span> value = data_instance[key]</span><br><span class=\"line\">        Observer(value)</span><br><span class=\"line\">        <span class=\"built_in\">Object</span>.defineProperty(data_instance, key, &#123;</span><br><span class=\"line\">            <span class=\"attr\">enumerable</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">            <span class=\"attr\">configurable</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">            <span class=\"function\"><span class=\"title\">get</span>(<span class=\"params\"></span>)</span> &#123;</span><br><span class=\"line\">                <span class=\"built_in\">console</span>.log(<span class=\"string\">`访问了属性：<span class=\"subst\">$&#123;key&#125;</span> -&gt; 值 <span class=\"subst\">$&#123;value&#125;</span>`</span>)</span><br><span class=\"line\">                Dependency.temp &amp;&amp; dependency.addSub(Dependency.temp)</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(Dependency.temp) <span class=\"built_in\">console</span>.log(Dependency.temp)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> value;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            <span class=\"function\"><span class=\"title\">set</span>(<span class=\"params\">newValue</span>)</span> &#123;</span><br><span class=\"line\">                <span class=\"built_in\">console</span>.log(<span class=\"string\">`属性<span class=\"subst\">$&#123;key&#125;</span>的值&quot;<span class=\"subst\">$&#123;value&#125;</span>&quot;修改为 -&gt; &quot;<span class=\"subst\">$&#123;newValue&#125;</span>&quot;`</span>)</span><br><span class=\"line\">                value = newValue</span><br><span class=\"line\">                Observer(newValue)</span><br><span class=\"line\">                dependency.notify()</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;)</span><br><span class=\"line\">    &#125;)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 模板解析</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">Compile</span>(<span class=\"params\">element, vm</span>) </span>&#123;</span><br><span class=\"line\">    vm.$el = <span class=\"built_in\">document</span>.querySelector(element);</span><br><span class=\"line\">    <span class=\"keyword\">const</span> fragment = <span class=\"built_in\">document</span>.createDocumentFragment();</span><br><span class=\"line\">    <span class=\"keyword\">let</span> child;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(child = vm.$el.firstChild) &#123;</span><br><span class=\"line\">        fragment.append(child)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    fragment_compile(fragment)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">fragment_compile</span>(<span class=\"params\">node</span>) </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">const</span> pattern = <span class=\"regexp\">/\\&#123;\\&#123;\\s*(\\S+)\\s*\\&#125;\\&#125;/</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(node.nodeType === <span class=\"number\">3</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">const</span> xxx = node.nodeValue</span><br><span class=\"line\">            <span class=\"keyword\">const</span> result = pattern.exec( node.nodeValue)</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(result) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">const</span> arr = result[<span class=\"number\">1</span>].split(<span class=\"string\">&quot;.&quot;</span>)</span><br><span class=\"line\">                <span class=\"keyword\">const</span> value = arr.reduce(<span class=\"function\">(<span class=\"params\">total, current</span>) =&gt;</span> total[current], vm.$data)</span><br><span class=\"line\">                node.nodeValue = xxx.replace(pattern, value)</span><br><span class=\"line\">                <span class=\"keyword\">new</span> Watcher(vm, result[<span class=\"number\">1</span>], <span class=\"function\"><span class=\"params\">newValue</span> =&gt;</span> &#123;</span><br><span class=\"line\">                    node.nodeValue = xxx.replace(pattern, newValue)</span><br><span class=\"line\">                &#125;)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> </span><br><span class=\"line\">        &#125; </span><br><span class=\"line\">        <span class=\"comment\">// 实现input框的v-model属性绑定</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(node.nodeType === <span class=\"number\">1</span> &amp;&amp; node.nodeName === <span class=\"string\">&quot;INPUT&quot;</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">const</span> attr = <span class=\"built_in\">Array</span>.from(node.attributes)</span><br><span class=\"line\">            attr.forEach(<span class=\"function\"><span class=\"params\">i</span> =&gt;</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(i.nodeName === <span class=\"string\">&#x27;v-model&#x27;</span>) &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">const</span> value = i.nodeValue.split(<span class=\"string\">&quot;.&quot;</span>).reduce(</span><br><span class=\"line\">                        <span class=\"function\">(<span class=\"params\">total, current</span>) =&gt;</span> total[current], vm.$data</span><br><span class=\"line\">                    )</span><br><span class=\"line\">                    node.value = value</span><br><span class=\"line\">                    <span class=\"keyword\">new</span> Watcher(vm, i.nodeValue, <span class=\"function\"><span class=\"params\">newValue</span> =&gt;</span> &#123;</span><br><span class=\"line\">                        node.value = newValue</span><br><span class=\"line\">                    &#125;)</span><br><span class=\"line\">                    node.addEventListener(<span class=\"string\">&#x27;input&#x27;</span>, <span class=\"function\"><span class=\"params\">e</span> =&gt;</span> &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">let</span> name = i.nodeValue.split(<span class=\"string\">&quot;.&quot;</span>);</span><br><span class=\"line\">                        <span class=\"keyword\">const</span> final = name.slice(<span class=\"number\">0</span>, name.length - <span class=\"number\">1</span>).reduce(</span><br><span class=\"line\">                            <span class=\"function\">(<span class=\"params\">total, current</span>) =&gt;</span> total[current], vm.$data</span><br><span class=\"line\">                        )</span><br><span class=\"line\">                        final[name[name.length - <span class=\"number\">1</span>]] = e.target.value</span><br><span class=\"line\">                    &#125;)</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        node.childNodes.forEach(<span class=\"function\"><span class=\"params\">child</span> =&gt;</span> fragment_compile(child))</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    vm.$el.append(fragment)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**发布订阅模式 */</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Dependency</span> </span>&#123;</span><br><span class=\"line\">    temp = <span class=\"literal\">null</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"title\">constructor</span>(<span class=\"params\"></span>)</span> &#123;</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.subscriber = []</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"title\">addSub</span>(<span class=\"params\">sub</span>)</span> &#123;</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.subscriber.push(sub)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"title\">notify</span>(<span class=\"params\"></span>)</span> &#123;</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.subscriber.forEach(<span class=\"function\"><span class=\"params\">sub</span> =&gt;</span> sub.update())</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 观察者</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Watcher</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"title\">constructor</span>(<span class=\"params\">vm, key, callback</span>)</span> &#123;</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.vm = vm</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.key = key</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.callback = callback</span><br><span class=\"line\">        <span class=\"comment\">// 临时属性 触发getter</span></span><br><span class=\"line\">        Dependency.temp = <span class=\"built_in\">this</span></span><br><span class=\"line\">        <span class=\"built_in\">console</span>.log(<span class=\"string\">`用属性<span class=\"subst\">$&#123;key&#125;</span>创建了订阅者`</span>)</span><br><span class=\"line\">        key.split(<span class=\"string\">&quot;.&quot;</span>).reduce(<span class=\"function\">(<span class=\"params\">total, current</span>) =&gt;</span> total[current], vm.$data) <span class=\"comment\">// 触发属性的getter</span></span><br><span class=\"line\">        Dependency.temp = <span class=\"literal\">null</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"title\">update</span>(<span class=\"params\"></span>)</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">const</span> value = <span class=\"built_in\">this</span>.key.split(<span class=\"string\">&quot;.&quot;</span>).reduce(<span class=\"function\">(<span class=\"params\">total, current</span>) =&gt;</span> total[current], <span class=\"built_in\">this</span>.vm.$data)</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.callback(value)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>&emsp;&emsp;视频看了两遍，全程跟着敲，第一遍还不太理解Watcher类是如何绑定对于数据的监听的，而且不太理解getter和setter的触发的巧妙之处。<br>&emsp;&emsp;Watcher其实就是在虚拟dom添加至页面的时候，将每一个在页面中要被渲染的值进行监听。监听的本质就是将data中的一个值于Watcher的一个实例对象所提供的callback函数绑定在一起，每当setter函数被触发，及data中的值发生了改变，则调用callback函数。Dependency类中存储了所有的Watcher实例，此处demo中对于通知Watcher进行更新的方法是，一旦setter被触发就通知Dependency.subscriber中的所有watcher进行更新，Watcher实例自带的update函方法可以找到自己正在监听的数据，并从根实例vm中获取最新的数据值并调用自身的callback函数。callback是在解析数据的同时对Watcher实例化的时候传入的，所以callback可以直接访问到数据要解析的目标dom，当Watcher接收到了新的值，就可以直接对dom进行重新渲染，也就实现了所谓的“双向绑定”。</p>\n"},{"layout":"poetry","title":"临江仙·夜饮东坡醒复醉 苏轼","date":"2022-01-25T23:57:01.000Z","_content":"\n夜饮东坡醒复醉，归来仿佛三更。家童鼻息已雷鸣。敲门都不应，倚杖听江声。\n\n长恨此身非我有，何时忘却营营。夜阑风静縠纹平。小舟从此逝，江海寄余生。","source":"_posts/临江仙·夜饮东坡醒复醉.md","raw":"---\nlayout: poetry\ntitle: 临江仙·夜饮东坡醒复醉 苏轼\ndate: 2022-01-25 23:57:01\ntags: [诗词]\n---\n\n夜饮东坡醒复醉，归来仿佛三更。家童鼻息已雷鸣。敲门都不应，倚杖听江声。\n\n长恨此身非我有，何时忘却营营。夜阑风静縠纹平。小舟从此逝，江海寄余生。","slug":"临江仙·夜饮东坡醒复醉","published":1,"updated":"2023-11-01T09:50:42.362Z","comments":1,"photos":[],"link":"","_id":"clofkwp1l000iqxgi2l6e88lq","content":"<p>夜饮东坡醒复醉，归来仿佛三更。家童鼻息已雷鸣。敲门都不应，倚杖听江声。</p>\n<p>长恨此身非我有，何时忘却营营。夜阑风静縠纹平。小舟从此逝，江海寄余生。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>夜饮东坡醒复醉，归来仿佛三更。家童鼻息已雷鸣。敲门都不应，倚杖听江声。</p>\n<p>长恨此身非我有，何时忘却营营。夜阑风静縠纹平。小舟从此逝，江海寄余生。</p>\n"},{"title":"我喜欢过两个女孩，一个是你，另一个也是你","date":"2020-08-05T09:54:35.000Z","_content":"\n<p style=\"font-size: 2rem;font-family: 楷体\">遗憾没有早早遇见，与你之间错过了许多年。</p>\n\n> <p style=\"font-family: 楷体\">小时候不懂鲁迅所说的：“我们家有两棵树，一颗是枣树，另一颗也是枣树。”直到经历了一些事情，才渐渐地明白了此中的深意。</p>\n\n<p style=\"font-family: 楷体\">煙雨行舟卻不知舟在何處</p>\n\n<p style=\"font-family: 楷体\">唱着年少有爲的人終究是負了佳人</p>\n\n<p style=\"font-family: 楷体\">“誰能憑愛意要富士山私有”</p>\n\n<p style=\"font-family: 楷体\">本就無法打動的人</p>\n\n<p style=\"font-family: 楷体\">憑你再用盡心機又如何</p>\n\n<p style=\"font-family: 楷体\">我的愛像塵埃</p>\n\n<p style=\"font-family: 楷体\">何謂小恩 何謂小惠</p>\n\n<p style=\"font-family: 楷体\">何謂大恩 何謂大德</p>\n\n<p style=\"font-family: 楷体\">再微不得到的小惠也能變成大恩</p>\n\n<p style=\"font-family: 楷体\">只是你放下了手裡的放大鏡</p>\n\n<p style=\"font-family: 楷体\">沒有誰對誰錯 只有愛與不愛</p>\n\n<p style=\"font-family: 楷体\">這世界還是一片光亮</p>\n\n<p style=\"font-family: 楷体\">我要帶你到處去飛翔</p>\n\n<p style=\"font-family: 楷体\">你不再是我的專屬</p>\n\n<p style=\"font-family: 楷体\">你的裙擺 你的衣角</p>\n\n<p style=\"font-family: 楷体\">你的薄脣 你的眉眼</p>\n\n<p style=\"font-family: 楷体\">看着都有種別樣的心酸</p>\n\n<p style=\"font-family: 楷体\">不過還好 慢慢地放下</p>\n\n<p style=\"font-family: 楷体\">舊的總要走 新的總要來</p>\n\n<p style=\"font-family: 楷体\">不過我是個深情的人</p>\n\n<p style=\"font-family: 楷体\">枯死的還能張處新芽</p>\n\n<p style=\"font-family: 楷体\">我靜靜地蹲在花盆前爲枯死的小花澆水</p>\n\n<p style=\"font-family: 楷体\">我想象着小花復甦後我欣喜若狂的樣子</p>\n\n<p style=\"font-family: 楷体\">有人勸我不如再摘一株小花</p>\n\n<p style=\"font-family: 楷体\">一樣美麗 一樣芬芳</p>\n\n<p style=\"font-family: 楷体\">但</p>\n\n\n\n<p style=\"font-family: 楷体\">總歸不是這一株小花</p>\n\n<p style=\"font-family: 楷体\">我也早已失去了種花的本事</p>\n","source":"_posts/我喜欢过两个女孩，一个是你，另一个也是你.md","raw":"---\ntitle: 我喜欢过两个女孩，一个是你，另一个也是你\ndate: 2020-08-05 09:54:35\ntags: [Heart]\n---\n\n<p style=\"font-size: 2rem;font-family: 楷体\">遗憾没有早早遇见，与你之间错过了许多年。</p>\n\n> <p style=\"font-family: 楷体\">小时候不懂鲁迅所说的：“我们家有两棵树，一颗是枣树，另一颗也是枣树。”直到经历了一些事情，才渐渐地明白了此中的深意。</p>\n\n<p style=\"font-family: 楷体\">煙雨行舟卻不知舟在何處</p>\n\n<p style=\"font-family: 楷体\">唱着年少有爲的人終究是負了佳人</p>\n\n<p style=\"font-family: 楷体\">“誰能憑愛意要富士山私有”</p>\n\n<p style=\"font-family: 楷体\">本就無法打動的人</p>\n\n<p style=\"font-family: 楷体\">憑你再用盡心機又如何</p>\n\n<p style=\"font-family: 楷体\">我的愛像塵埃</p>\n\n<p style=\"font-family: 楷体\">何謂小恩 何謂小惠</p>\n\n<p style=\"font-family: 楷体\">何謂大恩 何謂大德</p>\n\n<p style=\"font-family: 楷体\">再微不得到的小惠也能變成大恩</p>\n\n<p style=\"font-family: 楷体\">只是你放下了手裡的放大鏡</p>\n\n<p style=\"font-family: 楷体\">沒有誰對誰錯 只有愛與不愛</p>\n\n<p style=\"font-family: 楷体\">這世界還是一片光亮</p>\n\n<p style=\"font-family: 楷体\">我要帶你到處去飛翔</p>\n\n<p style=\"font-family: 楷体\">你不再是我的專屬</p>\n\n<p style=\"font-family: 楷体\">你的裙擺 你的衣角</p>\n\n<p style=\"font-family: 楷体\">你的薄脣 你的眉眼</p>\n\n<p style=\"font-family: 楷体\">看着都有種別樣的心酸</p>\n\n<p style=\"font-family: 楷体\">不過還好 慢慢地放下</p>\n\n<p style=\"font-family: 楷体\">舊的總要走 新的總要來</p>\n\n<p style=\"font-family: 楷体\">不過我是個深情的人</p>\n\n<p style=\"font-family: 楷体\">枯死的還能張處新芽</p>\n\n<p style=\"font-family: 楷体\">我靜靜地蹲在花盆前爲枯死的小花澆水</p>\n\n<p style=\"font-family: 楷体\">我想象着小花復甦後我欣喜若狂的樣子</p>\n\n<p style=\"font-family: 楷体\">有人勸我不如再摘一株小花</p>\n\n<p style=\"font-family: 楷体\">一樣美麗 一樣芬芳</p>\n\n<p style=\"font-family: 楷体\">但</p>\n\n\n\n<p style=\"font-family: 楷体\">總歸不是這一株小花</p>\n\n<p style=\"font-family: 楷体\">我也早已失去了種花的本事</p>\n","slug":"我喜欢过两个女孩，一个是你，另一个也是你","published":1,"updated":"2023-11-01T09:50:42.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clofkwp1m000jqxgi19odhhj6","content":"<p style=\"font-size: 2rem;font-family: 楷体\">遗憾没有早早遇见，与你之间错过了许多年。</p>\n\n<blockquote>\n<p style=\"font-family: 楷体\">小时候不懂鲁迅所说的：“我们家有两棵树，一颗是枣树，另一颗也是枣树。”直到经历了一些事情，才渐渐地明白了此中的深意。</p>\n</blockquote>\n<p style=\"font-family: 楷体\">煙雨行舟卻不知舟在何處</p>\n\n<p style=\"font-family: 楷体\">唱着年少有爲的人終究是負了佳人</p>\n\n<p style=\"font-family: 楷体\">“誰能憑愛意要富士山私有”</p>\n\n<p style=\"font-family: 楷体\">本就無法打動的人</p>\n\n<p style=\"font-family: 楷体\">憑你再用盡心機又如何</p>\n\n<p style=\"font-family: 楷体\">我的愛像塵埃</p>\n\n<p style=\"font-family: 楷体\">何謂小恩 何謂小惠</p>\n\n<p style=\"font-family: 楷体\">何謂大恩 何謂大德</p>\n\n<p style=\"font-family: 楷体\">再微不得到的小惠也能變成大恩</p>\n\n<p style=\"font-family: 楷体\">只是你放下了手裡的放大鏡</p>\n\n<p style=\"font-family: 楷体\">沒有誰對誰錯 只有愛與不愛</p>\n\n<p style=\"font-family: 楷体\">這世界還是一片光亮</p>\n\n<p style=\"font-family: 楷体\">我要帶你到處去飛翔</p>\n\n<p style=\"font-family: 楷体\">你不再是我的專屬</p>\n\n<p style=\"font-family: 楷体\">你的裙擺 你的衣角</p>\n\n<p style=\"font-family: 楷体\">你的薄脣 你的眉眼</p>\n\n<p style=\"font-family: 楷体\">看着都有種別樣的心酸</p>\n\n<p style=\"font-family: 楷体\">不過還好 慢慢地放下</p>\n\n<p style=\"font-family: 楷体\">舊的總要走 新的總要來</p>\n\n<p style=\"font-family: 楷体\">不過我是個深情的人</p>\n\n<p style=\"font-family: 楷体\">枯死的還能張處新芽</p>\n\n<p style=\"font-family: 楷体\">我靜靜地蹲在花盆前爲枯死的小花澆水</p>\n\n<p style=\"font-family: 楷体\">我想象着小花復甦後我欣喜若狂的樣子</p>\n\n<p style=\"font-family: 楷体\">有人勸我不如再摘一株小花</p>\n\n<p style=\"font-family: 楷体\">一樣美麗 一樣芬芳</p>\n\n<p style=\"font-family: 楷体\">但</p>\n\n\n\n<p style=\"font-family: 楷体\">總歸不是這一株小花</p>\n\n<p style=\"font-family: 楷体\">我也早已失去了種花的本事</p>\n","site":{"data":{}},"excerpt":"","more":"<p style=\"font-size: 2rem;font-family: 楷体\">遗憾没有早早遇见，与你之间错过了许多年。</p>\n\n<blockquote>\n<p style=\"font-family: 楷体\">小时候不懂鲁迅所说的：“我们家有两棵树，一颗是枣树，另一颗也是枣树。”直到经历了一些事情，才渐渐地明白了此中的深意。</p>\n</blockquote>\n<p style=\"font-family: 楷体\">煙雨行舟卻不知舟在何處</p>\n\n<p style=\"font-family: 楷体\">唱着年少有爲的人終究是負了佳人</p>\n\n<p style=\"font-family: 楷体\">“誰能憑愛意要富士山私有”</p>\n\n<p style=\"font-family: 楷体\">本就無法打動的人</p>\n\n<p style=\"font-family: 楷体\">憑你再用盡心機又如何</p>\n\n<p style=\"font-family: 楷体\">我的愛像塵埃</p>\n\n<p style=\"font-family: 楷体\">何謂小恩 何謂小惠</p>\n\n<p style=\"font-family: 楷体\">何謂大恩 何謂大德</p>\n\n<p style=\"font-family: 楷体\">再微不得到的小惠也能變成大恩</p>\n\n<p style=\"font-family: 楷体\">只是你放下了手裡的放大鏡</p>\n\n<p style=\"font-family: 楷体\">沒有誰對誰錯 只有愛與不愛</p>\n\n<p style=\"font-family: 楷体\">這世界還是一片光亮</p>\n\n<p style=\"font-family: 楷体\">我要帶你到處去飛翔</p>\n\n<p style=\"font-family: 楷体\">你不再是我的專屬</p>\n\n<p style=\"font-family: 楷体\">你的裙擺 你的衣角</p>\n\n<p style=\"font-family: 楷体\">你的薄脣 你的眉眼</p>\n\n<p style=\"font-family: 楷体\">看着都有種別樣的心酸</p>\n\n<p style=\"font-family: 楷体\">不過還好 慢慢地放下</p>\n\n<p style=\"font-family: 楷体\">舊的總要走 新的總要來</p>\n\n<p style=\"font-family: 楷体\">不過我是個深情的人</p>\n\n<p style=\"font-family: 楷体\">枯死的還能張處新芽</p>\n\n<p style=\"font-family: 楷体\">我靜靜地蹲在花盆前爲枯死的小花澆水</p>\n\n<p style=\"font-family: 楷体\">我想象着小花復甦後我欣喜若狂的樣子</p>\n\n<p style=\"font-family: 楷体\">有人勸我不如再摘一株小花</p>\n\n<p style=\"font-family: 楷体\">一樣美麗 一樣芬芳</p>\n\n<p style=\"font-family: 楷体\">但</p>\n\n\n\n<p style=\"font-family: 楷体\">總歸不是這一株小花</p>\n\n<p style=\"font-family: 楷体\">我也早已失去了種花的本事</p>\n"},{"title":"洗牌算法","date":"2021-12-29T11:14:12.000Z","toc":true,"_content":"## 基本原理\n>   洗牌算法是一种将一组数据随机排列的算法，保证每一个元素重新被分配到任何一个位置上的几率都是均等的，是保证随机程度的关键。\t\n\n每次随机选取一个数，然后将该数与数组中最后(或最前)的元素相交换(如果随机选中的是最后/最前的元素，则相当于没有发生交换)；然后缩小选取数组的范围，去掉最后的元素,即之前随机抽取出的数。重复上面的过程，直到剩余数组的大小为1，即只有一个元素时结束。\n## 完整代码\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>洗牌算法</title>\n</head>\n\n<body>\n    <script>\n        let arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n        document.writeln(arr)\n        document.writeln(\"<p>洗牌算法=></p>\")\n\n        function pockerAlgorithm(arr) {\n            let len = arr.length\n            arr.forEach((item, index) => {\n                let max = len - index - 1 // cal max position\n                let pos = Math.floor(Math.random() * (max + 1))\n                console.log(max + \"     \" + pos)\n\n                let temp = arr[pos]\n                arr[pos] = arr[max]\n                arr[max] = temp\n            })\n            return arr\n        }\n\n        document.writeln(pockerAlgorithm(arr) + \"<br>\")\n        document.writeln(pockerAlgorithm(arr) + \"<br>\")\n        document.writeln(pockerAlgorithm(arr) + \"<br>\")\n    </script>\n</body>\n\n</html>\n```","source":"_posts/洗牌算法.md","raw":"---\ntitle: 洗牌算法\ndate: 2021-12-29 11:14:12\ncategories: 学习\ntags: [算法,洗牌算法]\ntoc: true\n---\n## 基本原理\n>   洗牌算法是一种将一组数据随机排列的算法，保证每一个元素重新被分配到任何一个位置上的几率都是均等的，是保证随机程度的关键。\t\n\n每次随机选取一个数，然后将该数与数组中最后(或最前)的元素相交换(如果随机选中的是最后/最前的元素，则相当于没有发生交换)；然后缩小选取数组的范围，去掉最后的元素,即之前随机抽取出的数。重复上面的过程，直到剩余数组的大小为1，即只有一个元素时结束。\n## 完整代码\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>洗牌算法</title>\n</head>\n\n<body>\n    <script>\n        let arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n        document.writeln(arr)\n        document.writeln(\"<p>洗牌算法=></p>\")\n\n        function pockerAlgorithm(arr) {\n            let len = arr.length\n            arr.forEach((item, index) => {\n                let max = len - index - 1 // cal max position\n                let pos = Math.floor(Math.random() * (max + 1))\n                console.log(max + \"     \" + pos)\n\n                let temp = arr[pos]\n                arr[pos] = arr[max]\n                arr[max] = temp\n            })\n            return arr\n        }\n\n        document.writeln(pockerAlgorithm(arr) + \"<br>\")\n        document.writeln(pockerAlgorithm(arr) + \"<br>\")\n        document.writeln(pockerAlgorithm(arr) + \"<br>\")\n    </script>\n</body>\n\n</html>\n```","slug":"洗牌算法","published":1,"updated":"2023-11-01T09:50:42.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clofkwp1n000nqxgieqo47n1x","content":"<h2 id=\"基本原理\"><a href=\"#基本原理\" class=\"headerlink\" title=\"基本原理\"></a>基本原理</h2><blockquote>\n<p>  洗牌算法是一种将一组数据随机排列的算法，保证每一个元素重新被分配到任何一个位置上的几率都是均等的，是保证随机程度的关键。    </p>\n</blockquote>\n<p>每次随机选取一个数，然后将该数与数组中最后(或最前)的元素相交换(如果随机选中的是最后/最前的元素，则相当于没有发生交换)；然后缩小选取数组的范围，去掉最后的元素,即之前随机抽取出的数。重复上面的过程，直到剩余数组的大小为1，即只有一个元素时结束。</p>\n<h2 id=\"完整代码\"><a href=\"#完整代码\" class=\"headerlink\" title=\"完整代码\"></a>完整代码</h2><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;!DOCTYPE <span class=\"meta-keyword\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span> <span class=\"attr\">lang</span>=<span class=\"string\">&quot;en&quot;</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">charset</span>=<span class=\"string\">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">name</span>=<span class=\"string\">&quot;viewport&quot;</span> <span class=\"attr\">content</span>=<span class=\"string\">&quot;width=device-width, initial-scale=1.0&quot;</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>洗牌算法<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">script</span>&gt;</span><span class=\"javascript\"></span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"keyword\">let</span> arr = [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>]</span></span><br><span class=\"line\"><span class=\"javascript\"></span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"built_in\">document</span>.writeln(arr)</span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"built_in\">document</span>.writeln(<span class=\"string\">&quot;&lt;p&gt;洗牌算法=&gt;&lt;/p&gt;&quot;</span>)</span></span><br><span class=\"line\"><span class=\"javascript\"></span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">pockerAlgorithm</span>(<span class=\"params\">arr</span>) </span>&#123;</span></span><br><span class=\"line\"><span class=\"javascript\">            <span class=\"keyword\">let</span> len = arr.length</span></span><br><span class=\"line\"><span class=\"javascript\">            arr.forEach(<span class=\"function\">(<span class=\"params\">item, index</span>) =&gt;</span> &#123;</span></span><br><span class=\"line\"><span class=\"javascript\">                <span class=\"keyword\">let</span> max = len - index - <span class=\"number\">1</span> <span class=\"comment\">// cal max position</span></span></span><br><span class=\"line\"><span class=\"javascript\">                <span class=\"keyword\">let</span> pos = <span class=\"built_in\">Math</span>.floor(<span class=\"built_in\">Math</span>.random() * (max + <span class=\"number\">1</span>))</span></span><br><span class=\"line\"><span class=\"javascript\">                <span class=\"built_in\">console</span>.log(max + <span class=\"string\">&quot;     &quot;</span> + pos)</span></span><br><span class=\"line\"><span class=\"javascript\"></span></span><br><span class=\"line\"><span class=\"javascript\">                <span class=\"keyword\">let</span> temp = arr[pos]</span></span><br><span class=\"line\"><span class=\"javascript\">                arr[pos] = arr[max]</span></span><br><span class=\"line\"><span class=\"javascript\">                arr[max] = temp</span></span><br><span class=\"line\"><span class=\"javascript\">            &#125;)</span></span><br><span class=\"line\"><span class=\"javascript\">            <span class=\"keyword\">return</span> arr</span></span><br><span class=\"line\"><span class=\"javascript\">        &#125;</span></span><br><span class=\"line\"><span class=\"javascript\"></span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"built_in\">document</span>.writeln(pockerAlgorithm(arr) + <span class=\"string\">&quot;&lt;br&gt;&quot;</span>)</span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"built_in\">document</span>.writeln(pockerAlgorithm(arr) + <span class=\"string\">&quot;&lt;br&gt;&quot;</span>)</span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"built_in\">document</span>.writeln(pockerAlgorithm(arr) + <span class=\"string\">&quot;&lt;br&gt;&quot;</span>)</span></span><br><span class=\"line\"><span class=\"javascript\">    </span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"基本原理\"><a href=\"#基本原理\" class=\"headerlink\" title=\"基本原理\"></a>基本原理</h2><blockquote>\n<p>  洗牌算法是一种将一组数据随机排列的算法，保证每一个元素重新被分配到任何一个位置上的几率都是均等的，是保证随机程度的关键。    </p>\n</blockquote>\n<p>每次随机选取一个数，然后将该数与数组中最后(或最前)的元素相交换(如果随机选中的是最后/最前的元素，则相当于没有发生交换)；然后缩小选取数组的范围，去掉最后的元素,即之前随机抽取出的数。重复上面的过程，直到剩余数组的大小为1，即只有一个元素时结束。</p>\n<h2 id=\"完整代码\"><a href=\"#完整代码\" class=\"headerlink\" title=\"完整代码\"></a>完整代码</h2><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;!DOCTYPE <span class=\"meta-keyword\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span> <span class=\"attr\">lang</span>=<span class=\"string\">&quot;en&quot;</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">charset</span>=<span class=\"string\">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">name</span>=<span class=\"string\">&quot;viewport&quot;</span> <span class=\"attr\">content</span>=<span class=\"string\">&quot;width=device-width, initial-scale=1.0&quot;</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>洗牌算法<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">script</span>&gt;</span><span class=\"javascript\"></span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"keyword\">let</span> arr = [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>]</span></span><br><span class=\"line\"><span class=\"javascript\"></span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"built_in\">document</span>.writeln(arr)</span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"built_in\">document</span>.writeln(<span class=\"string\">&quot;&lt;p&gt;洗牌算法=&gt;&lt;/p&gt;&quot;</span>)</span></span><br><span class=\"line\"><span class=\"javascript\"></span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">pockerAlgorithm</span>(<span class=\"params\">arr</span>) </span>&#123;</span></span><br><span class=\"line\"><span class=\"javascript\">            <span class=\"keyword\">let</span> len = arr.length</span></span><br><span class=\"line\"><span class=\"javascript\">            arr.forEach(<span class=\"function\">(<span class=\"params\">item, index</span>) =&gt;</span> &#123;</span></span><br><span class=\"line\"><span class=\"javascript\">                <span class=\"keyword\">let</span> max = len - index - <span class=\"number\">1</span> <span class=\"comment\">// cal max position</span></span></span><br><span class=\"line\"><span class=\"javascript\">                <span class=\"keyword\">let</span> pos = <span class=\"built_in\">Math</span>.floor(<span class=\"built_in\">Math</span>.random() * (max + <span class=\"number\">1</span>))</span></span><br><span class=\"line\"><span class=\"javascript\">                <span class=\"built_in\">console</span>.log(max + <span class=\"string\">&quot;     &quot;</span> + pos)</span></span><br><span class=\"line\"><span class=\"javascript\"></span></span><br><span class=\"line\"><span class=\"javascript\">                <span class=\"keyword\">let</span> temp = arr[pos]</span></span><br><span class=\"line\"><span class=\"javascript\">                arr[pos] = arr[max]</span></span><br><span class=\"line\"><span class=\"javascript\">                arr[max] = temp</span></span><br><span class=\"line\"><span class=\"javascript\">            &#125;)</span></span><br><span class=\"line\"><span class=\"javascript\">            <span class=\"keyword\">return</span> arr</span></span><br><span class=\"line\"><span class=\"javascript\">        &#125;</span></span><br><span class=\"line\"><span class=\"javascript\"></span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"built_in\">document</span>.writeln(pockerAlgorithm(arr) + <span class=\"string\">&quot;&lt;br&gt;&quot;</span>)</span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"built_in\">document</span>.writeln(pockerAlgorithm(arr) + <span class=\"string\">&quot;&lt;br&gt;&quot;</span>)</span></span><br><span class=\"line\"><span class=\"javascript\">        <span class=\"built_in\">document</span>.writeln(pockerAlgorithm(arr) + <span class=\"string\">&quot;&lt;br&gt;&quot;</span>)</span></span><br><span class=\"line\"><span class=\"javascript\">    </span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure>"},{"layout":"2021/浮世三千","title":"浮世三千","date":"2020-07-25T10:29:44.000Z","_content":"\n**I love three things in the world**\n**The sun, The moon, and you**\n**Sun for the morning**\n**Moon for the night**\n**And you, forever**\n\n\n<p style=\"font-family: 楷体,隶书,宋体\">浮世三千 吾爱有三</p>\n<p>日， 月， 与卿</p>\n<p>日为朝</p>\n<p>月为暮</p>\n卿为朝朝暮暮\n\n","source":"_posts/浮世三千.md","raw":"---\nlayout: 2021/浮世三千\ntitle: 浮世三千\ndate: 2020-07-25 10:29:44\ncategories: 随笔\ntags: [Heart,Soul]\n---\n\n**I love three things in the world**\n**The sun, The moon, and you**\n**Sun for the morning**\n**Moon for the night**\n**And you, forever**\n\n\n<p style=\"font-family: 楷体,隶书,宋体\">浮世三千 吾爱有三</p>\n<p>日， 月， 与卿</p>\n<p>日为朝</p>\n<p>月为暮</p>\n卿为朝朝暮暮\n\n","slug":"浮世三千","published":1,"updated":"2023-11-01T09:50:42.362Z","comments":1,"photos":[],"link":"","_id":"clofkwp1n000pqxgic2mc86mf","content":"<p><strong>I love three things in the world</strong><br><strong>The sun, The moon, and you</strong><br><strong>Sun for the morning</strong><br><strong>Moon for the night</strong><br><strong>And you, forever</strong></p>\n<p style=\"font-family: 楷体,隶书,宋体\">浮世三千 吾爱有三</p>\n<p>日， 月， 与卿</p>\n<p>日为朝</p>\n<p>月为暮</p>\n卿为朝朝暮暮\n\n","site":{"data":{}},"excerpt":"","more":"<p><strong>I love three things in the world</strong><br><strong>The sun, The moon, and you</strong><br><strong>Sun for the morning</strong><br><strong>Moon for the night</strong><br><strong>And you, forever</strong></p>\n<p style=\"font-family: 楷体,隶书,宋体\">浮世三千 吾爱有三</p>\n<p>日， 月， 与卿</p>\n<p>日为朝</p>\n<p>月为暮</p>\n卿为朝朝暮暮\n\n"},{"title":"生与死","date":"2020-07-26T22:57:36.000Z","_content":"\n\n图书馆前的林荫路上有许多石凳\n\n我一个一个地坐过去\n\n每次坐下没过一会\n\n我都会忍不住看向下一个凳子\n\n总觉得下面的那一条才是我们那天坐的\n\n我大约是找到了那天的凳子\n\n也可能是弄丢了你-\n","source":"_posts/石凳.md","raw":"---\ntitle: 生与死\ndate: 2020-07-26 22:57:36\ntags: [人生 ,heart]\n---\n\n\n图书馆前的林荫路上有许多石凳\n\n我一个一个地坐过去\n\n每次坐下没过一会\n\n我都会忍不住看向下一个凳子\n\n总觉得下面的那一条才是我们那天坐的\n\n我大约是找到了那天的凳子\n\n也可能是弄丢了你-\n","slug":"石凳","published":1,"updated":"2023-11-01T09:50:42.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clofkwp1o000uqxgif1qmaly7","content":"<p>图书馆前的林荫路上有许多石凳</p>\n<p>我一个一个地坐过去</p>\n<p>每次坐下没过一会</p>\n<p>我都会忍不住看向下一个凳子</p>\n<p>总觉得下面的那一条才是我们那天坐的</p>\n<p>我大约是找到了那天的凳子</p>\n<p>也可能是弄丢了你-</p>\n","site":{"data":{}},"excerpt":"","more":"<p>图书馆前的林荫路上有许多石凳</p>\n<p>我一个一个地坐过去</p>\n<p>每次坐下没过一会</p>\n<p>我都会忍不住看向下一个凳子</p>\n<p>总觉得下面的那一条才是我们那天坐的</p>\n<p>我大约是找到了那天的凳子</p>\n<p>也可能是弄丢了你-</p>\n"},{"title":"罗老师百大发言","date":"2022-01-29T22:32:39.000Z","toc":true,"_content":"<p style=\"font-family: 楷体,隶书,宋体\">\n    &emsp;&emsp;我们注定无法生活在凡事都安排好的幻觉之中，人生中很多重要的时刻常常不期而至，所以人生唯一确定的也许就是不确定的人生。在英文中，“今天”也意外着礼物“present”，而在中文中，“今”与命令的“令”很相似，所以我把今天既看做礼物又看做命令，需要一点一点过好，完成每天的命令。当我们忠于每个今天的命令，我们就能从容面对每个神秘莫测的明天。明天并不可控，但我们可以选择乐观以待，让我们以感恩的心演好每个今天的剧本，超越我们有限的今生。\n</p>\n","source":"_posts/罗老师百大发言.md","raw":"---\ntitle: 罗老师百大发言\ndate: 2022-01-29 22:32:39\ncategories: 日常\ntags: [日常, Heart]\ntoc: true\n---\n<p style=\"font-family: 楷体,隶书,宋体\">\n    &emsp;&emsp;我们注定无法生活在凡事都安排好的幻觉之中，人生中很多重要的时刻常常不期而至，所以人生唯一确定的也许就是不确定的人生。在英文中，“今天”也意外着礼物“present”，而在中文中，“今”与命令的“令”很相似，所以我把今天既看做礼物又看做命令，需要一点一点过好，完成每天的命令。当我们忠于每个今天的命令，我们就能从容面对每个神秘莫测的明天。明天并不可控，但我们可以选择乐观以待，让我们以感恩的心演好每个今天的剧本，超越我们有限的今生。\n</p>\n","slug":"罗老师百大发言","published":1,"updated":"2023-11-01T09:50:42.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clofkwp1s0021qxgi1cpi406m","content":"<p style=\"font-family: 楷体,隶书,宋体\">\n    &emsp;&emsp;我们注定无法生活在凡事都安排好的幻觉之中，人生中很多重要的时刻常常不期而至，所以人生唯一确定的也许就是不确定的人生。在英文中，“今天”也意外着礼物“present”，而在中文中，“今”与命令的“令”很相似，所以我把今天既看做礼物又看做命令，需要一点一点过好，完成每天的命令。当我们忠于每个今天的命令，我们就能从容面对每个神秘莫测的明天。明天并不可控，但我们可以选择乐观以待，让我们以感恩的心演好每个今天的剧本，超越我们有限的今生。\n</p>\n","site":{"data":{}},"excerpt":"","more":"<p style=\"font-family: 楷体,隶书,宋体\">\n    &emsp;&emsp;我们注定无法生活在凡事都安排好的幻觉之中，人生中很多重要的时刻常常不期而至，所以人生唯一确定的也许就是不确定的人生。在英文中，“今天”也意外着礼物“present”，而在中文中，“今”与命令的“令”很相似，所以我把今天既看做礼物又看做命令，需要一点一点过好，完成每天的命令。当我们忠于每个今天的命令，我们就能从容面对每个神秘莫测的明天。明天并不可控，但我们可以选择乐观以待，让我们以感恩的心演好每个今天的剧本，超越我们有限的今生。\n</p>\n"},{"title":"老男孩","date":"2020-07-24T18:35:49.000Z","_content":"# 这辈子也不会这么迷茫了\n\n> “那是我日夜思念深深爱着的人呐，到底我该如何表达，她会接受我吗？”\n\n 最近尤其喜欢这首歌，大概是歌词里面凡是带“她”的我都喜欢吧。大学生涯以来最困扰我的问题竟然不是写不出好的程序，我也是奇了怪了。\n\n说再多的话也无济于事，可能这是我自己独有的属性，脑子里的想法就像波澜的海面，原本平静的海面不知何时就会泛起一阵涟漪。我的内心总是不平静的，嘴上总说着“没事没事，就是发会呆”，不过是不愿往深处想罢了，越往深处想，心里越堵得慌。曾经嘲笑别人输给了爱情，结果自己也陷了进去，无法自拔，不过是不愿往深处想罢了，越往深处想，心里越堵得慌。曾经嘲笑别人输给了爱情，结果自己也陷了进去，无法自拔。。\n","source":"_posts/老男孩.md","raw":"---\ntitle: 老男孩\ndate: 2020-07-24 18:35:49\ntags: [Soul, Heart, 人生]\n---\n# 这辈子也不会这么迷茫了\n\n> “那是我日夜思念深深爱着的人呐，到底我该如何表达，她会接受我吗？”\n\n 最近尤其喜欢这首歌，大概是歌词里面凡是带“她”的我都喜欢吧。大学生涯以来最困扰我的问题竟然不是写不出好的程序，我也是奇了怪了。\n\n说再多的话也无济于事，可能这是我自己独有的属性，脑子里的想法就像波澜的海面，原本平静的海面不知何时就会泛起一阵涟漪。我的内心总是不平静的，嘴上总说着“没事没事，就是发会呆”，不过是不愿往深处想罢了，越往深处想，心里越堵得慌。曾经嘲笑别人输给了爱情，结果自己也陷了进去，无法自拔，不过是不愿往深处想罢了，越往深处想，心里越堵得慌。曾经嘲笑别人输给了爱情，结果自己也陷了进去，无法自拔。。\n","slug":"老男孩","published":1,"updated":"2023-11-01T09:50:42.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clofkwp1s0022qxgicgwjbwuv","content":"<h1 id=\"这辈子也不会这么迷茫了\"><a href=\"#这辈子也不会这么迷茫了\" class=\"headerlink\" title=\"这辈子也不会这么迷茫了\"></a>这辈子也不会这么迷茫了</h1><blockquote>\n<p>“那是我日夜思念深深爱着的人呐，到底我该如何表达，她会接受我吗？”</p>\n</blockquote>\n<p> 最近尤其喜欢这首歌，大概是歌词里面凡是带“她”的我都喜欢吧。大学生涯以来最困扰我的问题竟然不是写不出好的程序，我也是奇了怪了。</p>\n<p>说再多的话也无济于事，可能这是我自己独有的属性，脑子里的想法就像波澜的海面，原本平静的海面不知何时就会泛起一阵涟漪。我的内心总是不平静的，嘴上总说着“没事没事，就是发会呆”，不过是不愿往深处想罢了，越往深处想，心里越堵得慌。曾经嘲笑别人输给了爱情，结果自己也陷了进去，无法自拔，不过是不愿往深处想罢了，越往深处想，心里越堵得慌。曾经嘲笑别人输给了爱情，结果自己也陷了进去，无法自拔。。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"这辈子也不会这么迷茫了\"><a href=\"#这辈子也不会这么迷茫了\" class=\"headerlink\" title=\"这辈子也不会这么迷茫了\"></a>这辈子也不会这么迷茫了</h1><blockquote>\n<p>“那是我日夜思念深深爱着的人呐，到底我该如何表达，她会接受我吗？”</p>\n</blockquote>\n<p> 最近尤其喜欢这首歌，大概是歌词里面凡是带“她”的我都喜欢吧。大学生涯以来最困扰我的问题竟然不是写不出好的程序，我也是奇了怪了。</p>\n<p>说再多的话也无济于事，可能这是我自己独有的属性，脑子里的想法就像波澜的海面，原本平静的海面不知何时就会泛起一阵涟漪。我的内心总是不平静的，嘴上总说着“没事没事，就是发会呆”，不过是不愿往深处想罢了，越往深处想，心里越堵得慌。曾经嘲笑别人输给了爱情，结果自己也陷了进去，无法自拔，不过是不愿往深处想罢了，越往深处想，心里越堵得慌。曾经嘲笑别人输给了爱情，结果自己也陷了进去，无法自拔。。</p>\n"},{"layout":"2021/裤子","title":"裤子","date":"2020-05-27T15:15:30.000Z","_content":"\n<!--那条裤子\n\n当时有点确实有点窄\n\n但是现在很合身\n\n可能是因为夏天来了 穿的薄了\n\n也可能\n\n是因为你走了-->\n略\n","source":"_posts/裤子.md","raw":"---\nlayout: 2021/裤子\ntitle: 裤子\ndate: 2020-05-27 15:15:30\ncategories: 随笔\ntags: [Soul]\n---\n\n<!--那条裤子\n\n当时有点确实有点窄\n\n但是现在很合身\n\n可能是因为夏天来了 穿的薄了\n\n也可能\n\n是因为你走了-->\n略\n","slug":"裤子","published":1,"updated":"2023-11-01T09:50:42.363Z","comments":1,"photos":[],"link":"","_id":"clofkwp1t0024qxgibyesho44","content":"<!--那条裤子\n\n当时有点确实有点窄\n\n但是现在很合身\n\n可能是因为夏天来了 穿的薄了\n\n也可能\n\n是因为你走了-->\n<p>略</p>\n","site":{"data":{}},"excerpt":"","more":"<!--那条裤子\n\n当时有点确实有点窄\n\n但是现在很合身\n\n可能是因为夏天来了 穿的薄了\n\n也可能\n\n是因为你走了-->\n<p>略</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"clofkwp1f0001qxgia10maxyb","category_id":"clofkwp1h0004qxgi0yeyfblh","_id":"clofkwp1l000fqxgidyrggupo"},{"post_id":"clofkwp1h0003qxgi78si0gsl","category_id":"clofkwp1k000bqxgi69h42vme","_id":"clofkwp1m000kqxgi0f21505w"},{"post_id":"clofkwp1j0009qxgi8yax4vao","category_id":"clofkwp1l000gqxgi7xiuhpd5","_id":"clofkwp1o000sqxgih4mf2y0d"},{"post_id":"clofkwp1n000nqxgieqo47n1x","category_id":"clofkwp1l000gqxgi7xiuhpd5","_id":"clofkwp1o000wqxgidu2ld1ru"},{"post_id":"clofkwp1j000aqxgifqqk7lj0","category_id":"clofkwp1l000gqxgi7xiuhpd5","_id":"clofkwp1p0010qxgihve5awp9"},{"post_id":"clofkwp1l000eqxgi188cejdh","category_id":"clofkwp1o000rqxgi3obpaomt","_id":"clofkwp1p0013qxgi9nlz1zd8"},{"post_id":"clofkwp1n000pqxgic2mc86mf","category_id":"clofkwp1o000yqxgi3i6i7bd7","_id":"clofkwp1q0017qxgiheq712rb"},{"post_id":"clofkwp1s0021qxgi1cpi406m","category_id":"clofkwp1k000bqxgi69h42vme","_id":"clofkwp1t0026qxgicdr6hgq8"},{"post_id":"clofkwp1t0024qxgibyesho44","category_id":"clofkwp1o000yqxgi3i6i7bd7","_id":"clofkwp1t0029qxgiamch7r8e"}],"PostTag":[{"post_id":"clofkwp1f0001qxgia10maxyb","tag_id":"clofkwp1i0005qxgi4vmb6b0h","_id":"clofkwp1n000oqxgi0pks51p8"},{"post_id":"clofkwp1f0001qxgia10maxyb","tag_id":"clofkwp1k000cqxgi022v0iq1","_id":"clofkwp1o000qqxgictobh8dp"},{"post_id":"clofkwp1f0001qxgia10maxyb","tag_id":"clofkwp1l000hqxgi5gk9ffx6","_id":"clofkwp1o000vqxgi6irj7bpu"},{"post_id":"clofkwp1m000jqxgi19odhhj6","tag_id":"clofkwp1i0005qxgi4vmb6b0h","_id":"clofkwp1o000xqxgi9n7r0hzp"},{"post_id":"clofkwp1h0003qxgi78si0gsl","tag_id":"clofkwp1i0005qxgi4vmb6b0h","_id":"clofkwp1p0011qxgiciog5ty0"},{"post_id":"clofkwp1n000pqxgic2mc86mf","tag_id":"clofkwp1i0005qxgi4vmb6b0h","_id":"clofkwp1p0012qxgidjlqby1x"},{"post_id":"clofkwp1n000pqxgic2mc86mf","tag_id":"clofkwp1k000cqxgi022v0iq1","_id":"clofkwp1q0015qxgi9picdkqy"},{"post_id":"clofkwp1i0007qxgi7rtegwke","tag_id":"clofkwp1o000tqxgiap0chaob","_id":"clofkwp1q0016qxgi1ybu25qz"},{"post_id":"clofkwp1j0009qxgi8yax4vao","tag_id":"clofkwp1o000zqxgi95txcno2","_id":"clofkwp1q001bqxgichip9oz2"},{"post_id":"clofkwp1j0009qxgi8yax4vao","tag_id":"clofkwp1q0014qxgi3erd94ce","_id":"clofkwp1q001cqxgieacsgz4h"},{"post_id":"clofkwp1j0009qxgi8yax4vao","tag_id":"clofkwp1q0018qxgihwppal9r","_id":"clofkwp1q001eqxgi7r2988ud"},{"post_id":"clofkwp1j0009qxgi8yax4vao","tag_id":"clofkwp1q0019qxgihhcxa1ta","_id":"clofkwp1q001fqxgie5mk3rec"},{"post_id":"clofkwp1j000aqxgifqqk7lj0","tag_id":"clofkwp1o000zqxgi95txcno2","_id":"clofkwp1q001iqxgi7jgsdrer"},{"post_id":"clofkwp1j000aqxgifqqk7lj0","tag_id":"clofkwp1q0014qxgi3erd94ce","_id":"clofkwp1q001jqxgi852og1bw"},{"post_id":"clofkwp1j000aqxgifqqk7lj0","tag_id":"clofkwp1q001gqxgi4yky1416","_id":"clofkwp1q001lqxgi65184e5j"},{"post_id":"clofkwp1l000dqxgi0lim7l71","tag_id":"clofkwp1q001hqxgi4t7e7zk3","_id":"clofkwp1q001nqxgi6nzk0duj"},{"post_id":"clofkwp1l000dqxgi0lim7l71","tag_id":"clofkwp1q0018qxgihwppal9r","_id":"clofkwp1q001oqxgiayai9ugo"},{"post_id":"clofkwp1l000eqxgi188cejdh","tag_id":"clofkwp1q001mqxgi89wh6p30","_id":"clofkwp1r001rqxgi5qin16wy"},{"post_id":"clofkwp1l000eqxgi188cejdh","tag_id":"clofkwp1r001pqxgi0fgn5nxn","_id":"clofkwp1r001sqxgi6jpwdeyd"},{"post_id":"clofkwp1l000iqxgi2l6e88lq","tag_id":"clofkwp1r001qqxgi3gcmdfs0","_id":"clofkwp1r001uqxgi3b6e7i0q"},{"post_id":"clofkwp1n000nqxgieqo47n1x","tag_id":"clofkwp1r001tqxgigsjtaaei","_id":"clofkwp1r001xqxgi6s1k3orc"},{"post_id":"clofkwp1n000nqxgieqo47n1x","tag_id":"clofkwp1r001vqxgi56jrep83","_id":"clofkwp1r001yqxgify4w34iu"},{"post_id":"clofkwp1o000uqxgif1qmaly7","tag_id":"clofkwp1l000hqxgi5gk9ffx6","_id":"clofkwp1r001zqxgi8vrgerkh"},{"post_id":"clofkwp1o000uqxgif1qmaly7","tag_id":"clofkwp1r001wqxgi5et0by7g","_id":"clofkwp1r0020qxgi8ezy7f33"},{"post_id":"clofkwp1s0021qxgi1cpi406m","tag_id":"clofkwp1o000tqxgiap0chaob","_id":"clofkwp1t0023qxgi6tma5f3w"},{"post_id":"clofkwp1s0021qxgi1cpi406m","tag_id":"clofkwp1i0005qxgi4vmb6b0h","_id":"clofkwp1t0025qxgi1n5u3g0n"},{"post_id":"clofkwp1s0022qxgicgwjbwuv","tag_id":"clofkwp1k000cqxgi022v0iq1","_id":"clofkwp1t0027qxgic5fg17ka"},{"post_id":"clofkwp1s0022qxgicgwjbwuv","tag_id":"clofkwp1i0005qxgi4vmb6b0h","_id":"clofkwp1t0028qxgi8okzel00"},{"post_id":"clofkwp1s0022qxgicgwjbwuv","tag_id":"clofkwp1l000hqxgi5gk9ffx6","_id":"clofkwp1u002aqxgievfz0c7d"},{"post_id":"clofkwp1t0024qxgibyesho44","tag_id":"clofkwp1k000cqxgi022v0iq1","_id":"clofkwp1u002bqxgibxlzdv48"}],"Tag":[{"name":"Heart","_id":"clofkwp1i0005qxgi4vmb6b0h"},{"name":"Soul","_id":"clofkwp1k000cqxgi022v0iq1"},{"name":"人生","_id":"clofkwp1l000hqxgi5gk9ffx6"},{"name":"日常","_id":"clofkwp1o000tqxgiap0chaob"},{"name":"scrapy","_id":"clofkwp1o000zqxgi95txcno2"},{"name":"爬虫","_id":"clofkwp1q0014qxgi3erd94ce"},{"name":"python","_id":"clofkwp1q0018qxgihwppal9r"},{"name":"框架","_id":"clofkwp1q0019qxgihhcxa1ta"},{"name":"网易新闻","_id":"clofkwp1q001gqxgi4yky1416"},{"name":"selenium","_id":"clofkwp1q001hqxgi4t7e7zk3"},{"name":"前端","_id":"clofkwp1q001mqxgi89wh6p30"},{"name":"vue","_id":"clofkwp1r001pqxgi0fgn5nxn"},{"name":"诗词","_id":"clofkwp1r001qqxgi3gcmdfs0"},{"name":"算法","_id":"clofkwp1r001tqxgigsjtaaei"},{"name":"洗牌算法","_id":"clofkwp1r001vqxgi56jrep83"},{"name":"heart","_id":"clofkwp1r001wqxgi5et0by7g"}]}}